{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"readings","text":"2019年Non-Tech 《你的生命有什么可能》古典 2019.07 《最好的我们》八月长安 2019.06 《小狗钱钱2》博多·舍费尔 2019.06 《小狗钱钱》博多·舍费尔 2019.05 《写给大家看的设计书》罗宾·威廉 2019.05 《晨间日记的奇迹》佐藤传 2019.04 《把时间当做朋友》李笑来 2019.04 《万历十五年》黄仁宇 2019.03 《简单冥想术》安迪·普迪科姆 2019.02 《人人都是产品经理》苏杰 2019.01 Tech 《代码的未来》松本行弘 2019.06 《白帽子谈Web安全》吴翰清 2019.06 《图解密码技术》结城浩 2019.06 2018年 《腾讯传》 吴秀波 2018.12 《一个人去旅行①》 高木直子 2018.12 《一个人住的每一天》高木直子 2018.11 《一个人住的第五年》高木直子 2018.11 《月亮与六便士》威廉· 萨默赛特·毛姆 2018.11 《小王子》安东尼·德·圣埃克苏佩 2018.11 《工作前五年，决定你一生的财富》三公子 2019.10 《奇特的一生》格拉宁 2018.09 《小岛经济学》彼得·希夫与安德鲁·希夫 2018.07 《杜拉拉升职记四部曲》李可 2018.03","link":"/readings/index.html"},{"title":"about","text":"关于博客以前也写过一些博客，不过主要都是学习的笔记，大部分没有太多的参考价值，尤其是后来看了一些大牛的博客之后，越发觉得自己写的东西太过于简单了，意义不大，于是就很久很久没有写博客(其实主要还是懒) 后来开始工作了，碰到一些场景需要学习新的知识，在网络上找了很多材料，发现大部分都是相互借鉴的，或者都是一些入门的东西，不太成体系，自己也是吃了不少苦，在偶然的情况下，发现了很多大佬输出的专业性很强的文章，尤其是Javadoop大佬，拜读其源码分析文章，收益良多 在拜读大佬的博客的过程中，不断地萌生这样的想法，我是否很弱？这个毋庸置疑，我很弱，懂的东西很少，经验也很缺乏，智商也不高，掌握新知识也很慢。 那我是否有必要接着分享一些文章(非笔记类型的)，经过一番纠结之后，我觉得还是有必要的，虽然不能像大牛一样，输出专业性很强的文章，但至少我能保证输出的每篇文章都是经过自己整理，分析，思考，总结之后的文章，而不只是盲目地借鉴其他人的文章。 我输出的文章可能对于高阶玩家来说，用处不大，意义不大，不过，对于像我这样，需要掌握某个知识，而又找不到合适切入点的人来说，还是能起到一定的帮助，所以，本着这样的一个目的，我决定从零开始写博客，分享我的所思所得，为此，本博客将坚持以下的原则 所有输出的文章均经过本人思考(参考、整合)，须亲自完成，或者经过原作者同意的转载 所有输出的文章必须保证思路清晰，逻辑清晰，循序渐进，能给像我这样的新手一定帮助 希望本博客能对你有所帮助 2019-10-23 于深圳 关于我我是大黄蜂，目前在深圳工作，主要使用的语言是Java，偶尔也会使用其他的语言 热爱技术，崇尚科技改善生活 喜欢跟有趣的小伙伴交流，分享","link":"/about/index.html"},{"title":"","text":"{\"name\":\"App\",\"icons\":[{\"src\":\"/android-icon-36x36.png\",\"sizes\":\"36x36\",\"type\":\"image/png\",\"density\":\"0.75\"},{\"src\":\"/android-icon-48x48.png\",\"sizes\":\"48x48\",\"type\":\"image/png\",\"density\":\"1.0\"},{\"src\":\"/android-icon-72x72.png\",\"sizes\":\"72x72\",\"type\":\"image/png\",\"density\":\"1.5\"},{\"src\":\"/android-icon-96x96.png\",\"sizes\":\"96x96\",\"type\":\"image/png\",\"density\":\"2.0\"},{\"src\":\"/android-icon-144x144.png\",\"sizes\":\"144x144\",\"type\":\"image/png\",\"density\":\"3.0\"},{\"src\":\"/android-icon-192x192.png\",\"sizes\":\"192x192\",\"type\":\"image/png\",\"density\":\"4.0\"}]}","link":"/images/manifest.json"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Docker学习笔记","text":"这篇文章主要是学习Docker过程的一个记录 Docker是新的容器化技术，相对于虚拟机技术，更加轻巧，更加易于移植，越来越受广大开发者的喜好。 Docker介绍及基本使用Docker介绍Docker特征 速度快 隔离机制 低消耗 Docker核心组件 Docker客户端和服务器 Docker是一个客户端-服务器(C/S)架构的应用程序 Docker提供了一个命令行工具以及完整的RESTful API 可以在同一个宿主机上运行Docker守护进程和客户端，也可以从本地Docker客户端连接到另一台宿主机上的Docker守护进程 Docker镜像 镜像是构建Docker世界的基石 用于基于镜像来运行自己的容器 镜像是基于联合文件系统的一种层式结构，由一系列指令一步步构建出来 镜像体积很小，易于分享、存储和更新 Registry(仓库) Docker用Registry来保存用户构建的镜像 Registry分为公共(如Docker Hub)和私有(自建仓库等) Docker容器 容器是基于镜像启动的 一个容器中可以运行一个或多个进程 每个容器包含一个软件镜像 可以简单地理解为容器就是运行起来的镜像 Docker应用场景 加速本地开发和构建流程(容器可以直接在不同的环境中运行) 能够让独立服务或应用程序在不同的环境中，得到相同的运行结果 使用Docker创建隔离的环境来进行测试 构建一个多用户的PaaS基础设施 为开发、测试提供一个轻量级的独立沙盒环境 提供SaaS应用程序 高性能、超大规模的宿主机部署 Docker安装这里演示使用的os是centos7 64位，需要使用root运行 Docker必备环境 运行64位CPU架构的计算机 运行Linux3.8及以上版本内核 上述内容可以通过uname -r命令进行查看 13.10.0-862.14.4.el7.x86_64 可以看到这里的内核版本是3.10，机器是64为，满足安装Docker的必备环境。 安装Docker，命令为yum install docker 依赖分析后的内容如下 12345678910111213141516171819202122232425262728293031323334353637383940414243Dependencies Resolved=============================================================================================== Package Arch Version Repository Size===============================================================================================Installing: docker x86_64 2:1.13.1-75.git8633870.el7.centos extras 16 MInstalling for dependencies: PyYAML x86_64 3.10-11.el7 base 153 k atomic-registries x86_64 1:1.22.1-25.git5a342e3.el7.centos extras 35 k audit-libs-python x86_64 2.8.1-3.el7_5.1 updates 75 k checkpolicy x86_64 2.5-6.el7 base 294 k container-selinux noarch 2:2.68-1.el7 extras 36 k container-storage-setup noarch 0.11.0-2.git5eaf76c.el7 extras 35 k device-mapper-event x86_64 7:1.02.146-4.el7 base 185 k device-mapper-event-libs x86_64 7:1.02.146-4.el7 base 184 k device-mapper-persistent-data x86_64 0.7.3-3.el7 base 405 k docker-client x86_64 2:1.13.1-75.git8633870.el7.centos extras 3.8 M docker-common x86_64 2:1.13.1-75.git8633870.el7.centos extras 93 k libcgroup x86_64 0.41-15.el7 base 65 k libsemanage-python x86_64 2.5-11.el7 base 112 k libyaml x86_64 0.1.4-11.el7_0 base 55 k lvm2 x86_64 7:2.02.177-4.el7 base 1.3 M lvm2-libs x86_64 7:2.02.177-4.el7 base 1.0 M oci-register-machine x86_64 1:0-6.git2b44233.el7 extras 1.1 M oci-systemd-hook x86_64 1:0.1.17-2.git83283a0.el7 extras 33 k oci-umount x86_64 2:2.3.3-3.gite3c9055.el7 extras 32 k policycoreutils-python x86_64 2.5-22.el7 base 454 k python-IPy noarch 0.75-6.el7 base 32 k python2-pytoml noarch 0.1.18-1.el7 epel 20 k setools-libs x86_64 3.3.8-2.el7 base 619 k skopeo-containers x86_64 1:0.1.31-1.dev.gitae64ff7.el7.centos extras 17 k subscription-manager-rhsm-certificates x86_64 1.20.11-1.el7.centos base 195 k yajl x86_64 2.0.4-4.el7 base 39 kTransaction Summary===============================================================================================Install 1 Package (+26 Dependent packages)Total download size: 27 MInstalled size: 87 MIs this ok [y/d/N]: 直接输入y即可 检查是否安装成功：docker --version，输入内容为 Docker version 1.13.1, build 8633870/1.13.1 启动docker服务：systemctl start docker 设置开机自启：systemctl enable docker 检查docker是否启动成功：docker info，输入内容如下，则表示启动成功 123456Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0... 关闭Docker：systemctl stop docker 重启Docker：systemctl restart docker Docker使用容器管理 部署容器(容器只有先部署才能启动跟使用，部署即从镜像到容器的过程) 命令：docker run --name INSTANCE_NAME -d DOCKER_IMAGE_NAME[:TAG] 演示案例 命令：docker run --name dkr_tomcat [-d] [-p LOCAL_PORT:CONTAINER:PORT] tomcat，没有指定tag则为最新 -d 表示以守护进程的形式启动(通常都是需要的) -p 指定本地以及容器的端口，也可以直接指定容器的端口 如果本地没有指定的镜像，则会先从docker hub中下载，如下所示 123456Unable to find image 'tomcat:latest' locallyTrying to pull repository docker.io/library/tomcat ...latest: Pulling from docker.io/library/tomcat...Status: Downloaded newer image for docker.io/tomcat:latest36322b0ba8389b058aa3bcb82442244931945ac2d91186615a0a4ed124053655 部署成功之后，会输出一段ID，如这里的36322b0ba8389b058aa3bcb82442244931945ac2d91186615a0a4ed124053655 查看运行的容器 命令：docker ps 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES36322b0ba838 tomcat &quot;catalina.sh run&quot; 3 minutes ago Up 3 minutes 8080/tcp dkr_tomcat 使用docker ps -a可以查看所有的容器 停止容器 命令：docker stop ID/NAME 启动容器 命令：docker start ID/NAME，该命令是运行一个已经停止的容器 重启容器 命令：docker restart ID/NAME 查看容器日志 命令：docker logs ID/NAME 可以使用-f选项来启动日志监控(直接在屏幕打印日志，没有则阻塞)，选项意义同tail命令，ctrl-c退出 查看容器内进程 命令：docker top ID/NAME 在容器内部运行进程 命令：docker exec [OPTION] ID/NAME COMMAND -d表示在后台执行该命令 -i 表示进入交互模式 -t 表示创建模拟tty 案例： 命令docker exec -it dkr_tomcat /bin/bash 表示指定/bin/bash命令并且进入交互模式，此时可以在容器中执行一些命令，如pwd，ls等 查看更多容器信息 命令：docker inspect ID/NAME 删除容器 命令：docker rm ID/NAME 运行中的容器需要先停止才能删除 镜像管理Docker镜像是由文件系统叠加而成，最底层是一个引导文件系统bootfs，当容器启动后，会被移到内存中，而引导文件系统则会被卸载 Docker镜像第二层是rootfs，位于引导文件系统之上，可以是一种或多种操作系统。 在Docker中，一个镜像可以放到另一个镜像的顶部，位于下面的镜像称为父镜像，最底部的镜像称为基础镜像，当从一个镜像中启动容器之后，Docker会在该镜像的最顶层加载一个读写文件系统 查看镜像 命令：docker images 本地镜像都保存在/var/lib/docker目录下(在具体的存储驱动目录下) 容器则存储在/var/lib/docker/containers目录下 拉取镜像 命令：docker pull IMAGE_NAME[:TAG]，不指定TAG则会拉取仓库内全部镜像 查找镜像 命令：docker search IMAGE_NAME 删除镜像 命令：docker rm IAMGE_NAME 构建镜像，一般通过Dockerfile以及docker build命令来构建镜像 Dockerfile由一系列指令和参数组成，每条指令必须大写，后面必须跟一个参数，如FROM 每条指令都会创建一个新的镜像层并对镜像进行提交 #开头为注释内容 Dockerfile的第一条指令必须为FROM，后续指令都将基于该镜像进行，该镜像也称为基础镜像 RUN指令用于在当前镜像中运行指定的命令，默认使用shell来执行，可以通过['cmd', 'arg', '...']来避免 EXPOSE指令用于指定容器使用的端口 案例 新建文件夹static_web 编辑Dockerfile Dockerfile 12345# Version 0.0.1# 命令大小FROM nginx:latestRUN echo &quot;Hi I am Xavier&quot; &gt;&gt; /usr/share/nginx/html/index.htmlEXPOSE 80 然后执行命令：docker build -t=&quot;xavier/static_web&quot; . -t用于指定仓库和名称 注意后面的.，指定当前目录(Dockerfile所在目录)，如果是在外面，需要注意目录的路径。 输出内容 12345678910111213Sending build context to Docker daemon 2.048 kBStep 1/3 : FROM nginx:latest---&gt; 62f816a209e6Step 2/3 : RUN echo &quot;Hi I am Xavier&quot; &gt;&gt; /usr/share/nginx/html/index.html---&gt; Running in 755840b827eb---&gt; c177cbb50afeRemoving intermediate container 755840b827ebStep 3/3 : EXPOSE 80---&gt; Running in 200168bc6cdf---&gt; 89dbc87994b6Removing intermediate container 200168bc6cdfSuccessfully built 89dbc87994b6 Dockerfile指令 ADD，将构建目录下指定文件添加到镜像中， ADD a.file /usr/local/share/a.file，如果是压缩文件，会自动解压 COPY， 仅仅复制，不会自动提取或解压 Docker容器互连默认情况下容器是无法被外界访问的，可以使用暴露端口的方式，但是该方式不推荐，更合适的方式是通过绑定机制来实现容器之间的互连，比如一个tomcat容器以及一个redis容器，可以将tomcat容器与redis容器进行绑定，绑定之后只有tomcat容器能访问到redis容器，其他的容器无法访问，当然，外界环境同样无法访问啦。 绑定的方式，只需要在部署容器的时候，指定一下所要绑定的容器即可，docker run --link TARGET_CONTAINER:ALIAS_NAME IMAGE，如docker run --link redis:redis-db tomcat，然后可以在tomcat容器中的/etc/hosts文件看到，直接绑定了172.17.0.3 redis-db d78523d89091 redis，可以通过在tomcat容器中执行ping redis-db检测两个容器之间的通信情况。 卷挂载由于Docker容器重启之后，容器中的数据会丢失，为了保存数据，Docker中提供了卷的概念，可以通过卷在外部文件和容器文件进行映射，从而达到共享数据或者持久化数据的目的。 在构建容器时，可以通过-v SOURCE_DIR:TARGET_DIR进行挂载。","link":"/2019/07/30/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Paxos学习笔记","text":"在理解Paxos的时候，一开始觉得很莫名其妙，看了挺多的资料的，但是一直没有理解到，最后还是回归到论文上，看了Leslie Lamport的论文：Paxos Made Simple之后，才恍然大悟 这篇文章主要记录的就是这个学习，思考的过程，根据论文，加上自己的理解总结而成 Paxos学习笔记一致性所谓的一致性，通俗地理解，就是数据的状态一直处理正常状态 而分布式一致性，自然就是在分布式环境下使得数据保持一致性了 一致性有不同的模型 强一致性 Paxos Raft ZAB … 弱一致性 最终一致性(本身属于弱一致性，不过比较突出，所以单独拎出来) DNS … 容错性容错性，可以通俗地理解为，当系统某个或者某几个部件出现故障的时候，系统依旧能保持正常地运行 后面的推导过程可以看到为啥子Paxos是具有高容错性的算法 Paxos在理解Paxos的时候，一开始觉得很莫名其妙，看了挺多的资料的，但是一直没有理解到，最后还是回归到论文上，看了Leslie Lamport的论文：Paxos Made Simple之后，才恍然大悟 下面详细介绍Paxos的推导过程，基本上是参考论文的思路来的，不过补充多一些这个过程的思考 Paxos是什么Paxos是由Leslie Lamport提出的一个分布式一致性算法(Consensus Algorithm) 特点：强一致性、容错性 为什么需要Paxos这里的标题可能不太合适，准确地来说，是为什么会出现不一致的情况，而Paxos刚刚好能解决这个问题，所以这里就以为什么需要Paxos作为小标题 一致性问题这个在单机环境下，可以通过事务等来控制，但是在分布式环境下，问题就很复杂了 通常情况下，分布式系统上的同一功能的节点会有多个，原因在于，单个节点如果挂了，那整个系统就将处于不可用状态了 引入多节点，保证了可用性，但是会出现不一致的情况，比如，某一个客户端修改某个节点，A，上存储的数据，之后A在同步给其他节点的时候，部分节点还没有同步到，A就挂了，那么此时就出现不一致了，此时该以谁为准呢 Paxos的出现，不是为了预防这种情况的发生，而是在出现这种情况的时候，系统如何快速地恢复到一致的情况，即使得不一致的数据快速地一致起来，让系统尽快地可用 基础信息网络不可靠：网络本身是不可靠的，这一点基本可以达成共识，网络存在延迟、乱序的情况，当然，也存在数据被干扰而损坏的情况，但在Paxos中，假定数据不会被篡改，即不存在拜占庭将军问题 var：这里为了简化问题，我们以一个变量var作为讨论的对象，出现的不一致即var出现了多个不同的值 安全性问题：所谓的安全性问题，就是保证不该出现的情况一定不会出现，有几个比较重要的情况 var的某个值只有在被提出来决策的时候，才有可能被选定，没有出现过的值不应该被选定 var的多个值中只有一个被选定 如果一个值被选定了，那就是真的被选定的 活性问题：与安全性相对，活性保证的是该出现的一定会出现，同样有几个重要的情况 所有提出来的var的值，最终一定有一个被选定 如果被选定了，其他人一定能够获取到该值 Paxos中的三大角色(Agent) Proposers，提出var值的人，也即需要确定var值的人 Acceptors，决策var值的人，也即确定var最终值的人 Learners，学习决策出来的var值的人，这篇文章应该只会出现这一次，囧…. 为什么需要这么多角色？ 首先，Proposer是必须的，就是因为Proposer数据出现不一致了，才会需要讨论的 其次，Acceptors是必须的(Acceptor同时可以是Proposer)，既然出现不一致，那总是需要有人来决定到底以谁为准 最后，Learners，这个确实是可有可无的 虽然Paxos中有三个角色，但是觉得跟实现的映射关系是比较随意的，如一个进程可以同时身兼多个角色 在Paxos中，由于Aagent需要记住自己已经选过的某个值，所以需要对该值进行持久化，防止重启/崩溃恢复之后丢失数据 提案：也可以称为提议，就是记录某一个变量的某一个值，由Proposer提出，交由Acceptor决策 大多数原则：也成为少数服从多数原则，在一个团体中，如果大部分的人都同意了，那么未同意的少部分人就只能放弃自己的想法，转成同意，最小的大部分是集体数量的一半+1 确定一个值确定一个值，其实也就是某个提案在集群中达到一致，这里计提案为：&lt;var, value&gt; 方案一：单个Acceptor有了上面的情况之后，接下来我们来讨论如何确定一个值，首先，最简单的方式就是，只通过一个Acceptor来决策，Acceptor只接受提交的第一个var值，之后的直接以第一个值为准即可，那就没啥好争的了，拼手速吧 这个方案是最简单的，但存在前面提到的单点问题，如果Acceptor挂了，那场面就很尴尬了 方案二：多个Acceptor既然一个Acceptor有问题，那就多个咯 多个Acceptor解决了单点的问题，但引入了其他的复杂问题 首先，前面活性问题提到了，被提出来提案的一定要能够决策出唯一一个出来，但是，如果每个Acceptor都选择不接受，那么被提出来的所有值都无法决策，所以需要Acceptor做出如下保证 P1：每个Acceptor必须同意接收到的第一个提案 这样子，活性的问题解决了吗？并没有，因为出现下面的情况 1234567891011# case 1P1 ---&gt; A1P2 ---&gt; A2P3 ---&gt; A3# case 2P1 ---&gt; A1 ---&gt; A2 A3(x)p2 ---&gt; A4 ---&gt; A5 虽然每个Acceptor都同意了自己收到的第一个提案，然后拒绝/忽略后续的，从而导致了上面的尴尬场景出现了，此时，提案虽然被决策出来了，但是违背了安全性 这也意味着P1其实不够完善，只要求接收第一个提案是不够的，既然不够，那继续加强完善就可以了，如何完善呢？ 为了保证一个提案被接受了，那就要求所有人都同意这个值的时候，才能同意这个提案，但是所有人太多了，Paxos中以大多数为准，也即一个提案，只有被大多数Acceptor接受了，这个提案才算被接受 上面的话，也即意味着一个Acceptor必须接受不止一个提案，如果只接受一个的话，大多数是很难达到的(上面的那两个例子)，那么问题又来了，一个Acceptor接受多个提案，那要怎么区分这些提案呢？ 简单，为每个提案分配一个ID就行了，这样子就能够区分开来了，此时，提案就变为：&lt;var, value, ID&gt;，ID只要全局单调递增即可 解决了提案无法区分的问题，那就意味着此时Acceptor能够区分开多个不同的提案了，那么原始问题解决了吗？ 并没有，因为此时Acceptor可以不停地接受ID更大的提案，并且不停地覆盖掉对应的值，从而导致一个值即使被选定了，也可能被覆盖掉 12345678P1 ---&gt; A1 &lt;var, v1, 1&gt;P1 ---&gt; A2 &lt;var, v1, 1&gt;P1 ---&gt; A3 &lt;var, v1, 1&gt; A4 A5----- 此时var的值已经选定了(大多数原则)，但是如果此时P2提了个新的提案&lt;var, v2, 2&gt;那么会导致被选定出来的值又被覆盖了，从而违背了安全性中的一个值被选定必定是被选定出来的 这说明上述的还是不够完善，需要继续完备，问题出在于，被选定的值依旧被后面的提案覆盖了，所以只需要保证这个就可以了 P2：如果一个提案&lt;var, v1, ID_1&gt;被接受了，那么被选中的所有编号比其高的提案的值，也必须是v1 为了保证P2成立，可以通过要求Acceptor碰到编号比自己已经批准过的提案编号还高的提案时，不要审批，来实现 P2a：如果一个提案&lt;var, v1, ID_1&gt;被接受了，那么所有其批准的所有编号比v1高的提案，其值必须是v1 可是，事实上P2a还是有问题 12345P1 ---&gt; A1 &lt;var, v1, 1&gt;P1 ---&gt; A2 &lt;var, v1, 1&gt;P1 ---&gt; A3 &lt;var, v1, 1&gt; A4 &lt;var, null, null&gt; A5 &lt;var, null, null&gt; 此时如果P2提出新的提案&lt;var, v2, 2&gt;，对于A4、A5而言，根据P1，是必须接受的，所以又出现了尴尬的场面，安全性又违背了 可是此时对于A4、A5来说，他们也是很无奈，根据约定，是必须要接受的，可是接受了，又说是错误的，从A4、A5的角度来说，已经无法处理这种情况了 解决问题的方式从来都不止一种，比如把提出问题的人解决了也是能够解决问题的，换句话说，既然对于Acceptor而言，已经无法应付这种情况了，那么只要提出问题的人不要乱提问题，那问题也是能得到解决的，也即 p2b：如果一个提案&lt;var, v1, ID_1&gt;已经被接受了，那么所有提出来的编号比其高的提案，其值必须是v1 那么问题又来了，对于P而言，如何知道当前提案是否已经被接受了呢？方法其实也是很简单，在提出提案之前，先问一下各位Acceptor，对于提案，是否已经接受过了，如果接受过了，请告诉我他的编号以及值是啥，然后，提案者再根据收集到的信息发起提案，那么万事就大吉了，当然，此时需要Acceptor做出承诺，不能再接受编号比我低的提案了 到了这里，Paxos算法也就推导出来了 Paxos算法Paxos算法分为两个阶段 第一阶段称为Prepare，目的是为了从Acceptor中获取当前提案的相关信息 第二阶段称为Accept，目的是为了决策出提案的值 第一阶段Proposer选择一个编号为ID_X的提案，向所有Acceptor发起Prepare请求 Acceptor可以做出如下反应 忽视/丢弃这个请求 将已经接受过的提案的编号以及其值返回给提案者(如果存在) 第二阶段如果Proposer收到大多数Acceptor返回的响应，则可以继续执行第二阶段 如果所有的响应的值都是null，则说明此时提案还没有被决策出来，那么自己可以选择一个值来发起Accept请求 如果某个响应已经包含了值，那么从所有响应中，选择编号最大的值，作为提案的值，发起Accept请求 此时Acceptor根据接受到的Accept请求，做出如下反应 如果accept请求的提案编号小于之前已经承诺过的编号，则返回错误或者忽略请求 如果编号等于承诺过的编号，则将值更改为对应的值(此时的值要么是没有任何人提出的，要么是已经决策出来的，所以不违反安全性要求) 由于Accept请求是在Prepare之后提出的，所以，不存在编号大于当前已经记录的最大编号这种情况 到这里，Paxos算法就推导完成了 关于Paxos的容错性，从这里可以看到，只要挂掉的Acceptor数量低于总体的一半，那么至少会有一个Acceptor记录了新的值，从而可以继续决策，并且维持这个值不变 活性问题上述的Paxos中存在一个问题，称为活锁 前面提到了，Paxos第一阶段提出的Prepare请求，会使得Accept拒绝所有编号比其低的请求，所以会有下面的情况存在 A1发起Prepare请求，编号为ID_1 发起Accept之前，A2发起了Prepare请求，编号为ID_2 A1发起Accept请求，此时，由于编号已经低于记录的最大编号，那么就拒绝了 A1重新发起Prepare请求，编号为ID_3 A2发起Accept请求，此时，由于编号已经低于记录的最大编号，那么就拒绝了 …..然后 ，就停不下来了 此时，陷入了死锁状态 在论文中，Leslie Lamport提出可以通过选举出一个主要的Proposal，所有的提案全部由Proposal提出即可 这里，由于能力有限，就没接着研究下去了…. 希望后面有能力继续专研一下，顺便看下其实现代码…","link":"/2019/12/22/Paxos%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"LockSupport使用及分析","text":"这篇文章主要是对LockSupport工具进行分析，LockSupport是提供给concurrent包中的其他工具使用的底层工具，主要是用于线程的阻塞以及唤醒 LockSupport使用及分析介绍 以下内容翻译自doc LockSupport一个基本的线程阻塞工具，主要用于其他同步工具中阻塞线程 每个使用LockSupport的线程会关联一个permit(有且只有一个)，当调用park时，如果permit不可用，则可能阻塞，调用unpark会是permit重新可用 LockSupport提供高效的，并且没有副作用(与Thread.suspend，Thread.resume对比)，不存在竞态条件，此外，当线程中断或者超时时，也会返回 使用时，需要注意，park方法随时可能返回，所以如果需要检查条件是否满足的情况下，需要将其放在循环中 park方法同时支持一个blocker参数，这个对象可以用于记录线程阻塞原因等信息 分析LockSupport大概是concurrent包下为数不多代码较少的类了，分析起来也比较容易，直接上代码吧 1234public class LockSupport { // 私有化 private LockSupport() {}} 从此处也可以看出，LockSupport本身是作为工具使用，因此禁止实例化 核心属性 123456789101112131415161718192021222324252627282930313233343536// unsafeprivate static final sun.misc.Unsafe UNSAFE;private static final long parkBlockerOffset;private static final long SEED;private static final long PROBE;private static final long SECONDARY;static { try { // 获取unsafe实例 UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; // 从thread对象中获取parkBlocker字段 // doc中说明用于LockSupport parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;parkBlocker&quot;)); // 从thread对象中获取threadLocalRandomSeed字段 // ThreadLocalRandom的当前种子 SEED = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSeed&quot;)); // 从thread对象中获取threadLocalRandomProbe字段 // hash值 PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomProbe&quot;)); // 从thread对象中获取threadLocalRandomSecondarySeed字段 // 第二个种子(与ThreadLocalRandom隔离) SECONDARY = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSecondarySeed&quot;)); } catch (Exception ex) { throw new Error(ex); }} 核心方法 1234private static void setBlocker(Thread t, Object arg) { // 通过unsafe为thread的parkBlocker赋值 UNSAFE.putObject(t, parkBlockerOffset, arg);} 123456// 从t中获取parkBlocker字段的值public static Object getBlocker(Thread t) { if (t == null) throw new NullPointerException(); return UNSAFE.getObjectVolatile(t, parkBlockerOffset);} 1234567891011121314151617181920212223242526272829303132333435363738394041// 阻塞当前线程，当permit可用时，才允许线程运行public static void park() { UNSAFE.park(false, 0L);}// 参数的blockerpublic static void park(Object blocker) { Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); // park返回之后，清空对应的blocker setBlocker(t, null);}// 带时间的parkpublic static void parkNanos(long nanos) { if (nanos &gt; 0) UNSAFE.park(false, nanos);}// 带时间，带参数public static void parkNanos(Object blocker, long nanos) { if (nanos &gt; 0) { Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, nanos); setBlocker(t, null); }}public static void parkUntil(long deadline) { UNSAFE.park(true, deadline);}public static void parkUntil(Object blocker, long deadline) { Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(true, deadline); setBlocker(t, null);} 12345public static void unpark(Thread thread) { // 唤醒thread if (thread != null) UNSAFE.unpark(thread);} 1234567891011121314// 获取下一个种子static final int nextSecondarySeed() { int r; Thread t = Thread.currentThread(); if ((r = UNSAFE.getInt(t, SECONDARY)) != 0) { r ^= r &lt;&lt; 13; // xorshift r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; } else if ((r = java.util.concurrent.ThreadLocalRandom.current().nextInt()) == 0) r = 1; // avoid zero UNSAFE.putInt(t, SECONDARY, r); return r;} 可以看到，LockSupport的代码相对来说，是比较简介的，而且从功能的角度来讲，也是比较单一的 使用经过上面的分析之后，对于LockSupport的使用相对来说，就比较简单的，这里给出一个简单的示例 123456789101112131415161718192021public static void main(String[] args) throws InterruptedException { Thread threadA = new Thread(()-&gt;{ Thread currentThread = Thread.currentThread(); System.out.println(currentThread.getName() + &quot; is working....&quot;); System.out.println(currentThread.getName() + &quot; is parking...&quot;); LockSupport.park(); System.out.println(currentThread.getName() + &quot; is wake up&quot;); }); Thread threadB = new Thread(()-&gt;{ Thread currentThread = Thread.currentThread(); System.out.println(currentThread.getName() + &quot; is working....&quot;); System.out.println(currentThread.getName() + &quot; waking up threadA&quot;); LockSupport.unpark(threadA); System.out.println(currentThread.getName() + &quot; is finish&quot;); }); threadA.start(); TimeUnit.SECONDS.sleep(1); threadB.start();} 输出内容如下 123456Thread-0 is working....Thread-0 is parking...Thread-1 is working....Thread-1 waking up threadAThread-0 is wake upThread-1 is finish 从输出的结果可以清楚地看出LockSupport的作用，但需要注意的是，LockSupport推荐在一些偏向于底层的工具中使用，如ReentrantLock、AbstractQueuedSynchronizer等中使用 在应用中使用，一般是推荐直接使用上一层的工具，而非直接使用LockSupport","link":"/2019/10/17/LockSupport%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%88%86%E6%9E%90/"},{"title":"TimeUnit使用及分析","text":"这篇文章主要是学习TimeUnit过程的一个记录及分析 TimeUnit是java.util.concurrent包下一个非常有用而且非常好用的工具，用于方便地进行各种时间单位的转换以及提供一些多时间单位的工具 TimeUnit使用及分析简介 以下内容来自doc TimeUnit代表在给定单位内的连续时间，并且提供了一系列的工具用于进行单位转换，计时、延迟等操作 TimeUnit本身不维护时间信息，仅对时间操作 使用先看下TimeUnit的使用，然后后面再分析下其具体的实现 时间转换在没有TimeUnit之前，时间转换是一个比较麻烦的事情，每次都需要人工计算，如将mill转分钟，有了该工具，就非常方便，而且不容易出错 12345678910111213141516public static void testTransform() { long now = System.nanoTime(); System.out.println(&quot;Now in nano: &quot; + now); System.out.println(&quot;Now in micro: &quot; + now / 1000); System.out.println(&quot;Now in mill: &quot; + now / 1000 / 1000); System.out.println(&quot;Now in second: &quot; + now / 1000 / 1000 / 1000); System.out.println(&quot;Now in minute: &quot; + now / 1000 / 1000 / 1000 / 60); System.out.println(&quot;TimeUnit=========&quot;); System.out.println(&quot;Now in nano: &quot; + now); System.out.println(&quot;Now in micro: &quot; + TimeUnit.NANOSECONDS.toMicros(now)); System.out.println(&quot;Now in mill: &quot; + TimeUnit.NANOSECONDS.toMillis(now)); System.out.println(&quot;Now in second: &quot; + TimeUnit.NANOSECONDS.toSeconds(now)); System.out.println(&quot;Now in minute: &quot; + TimeUnit.NANOSECONDS.toMinutes(now));} 任意时间单位的等待JDK默认提供的wait方法仅支持milliseconds作为时间单位，显然，如果需要其他单位，进行转换也是个麻烦的事情 所以TimeUnit也提供了方便的方式 123456789101112131415161718192021public synchronized void testWait() { // 等待一分钟 System.out.println(new Date()); try { // 人工计算，容易出错 wait(1000 * 60); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(new Date()); System.out.println(&quot;TimeUnit=========&quot;); System.out.println(new Date()); try { TimeUnit.MINUTES.timedWait(this, 1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(new Date());} 任意时间单位休眠有时候，需要调用Thread.sleep()，但是该方法同样仅支持毫秒为单位 12345678910111213141516public void testSleep() { // sleep一分钟 try { Thread.sleep(1000 * 60); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;TimeUnit=========&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }} 还有一个timedJoin也是对Thread.join的增强，就不举例了 小结TimeUnit本身并没有引入新的概念，只是将一些原本比较繁琐，容易出错的时间单位之间的转换操作封装起来，提供更加简便的接口而已 分析TimeUnit本身是一个枚举类 包含了若干个实例，对应不同的时间单位 123456789101112131415161718192021222324252627282930313233343536public enum TimeUnit { /** * 纳秒 */ NANOSECONDS {}, /** * 微秒 */ MICROSECONDS {}, /** * 毫秒 */ MILLISECONDS {}, /** * 秒 */ SECONDS {}, /** * 分钟 */ MINUTES {}, /** * 小时 */ HOURS {}, /** * 天 */ DAYS {};} 同时，为了更好地进行单位转换，提供了一系列的方法，默认情况下这些方法都抛出异常，具体的内容由其实例(子类)进行实现 123456789101112131415161718192021222324252627282930313233343536373839// 将给定时间转换为指定单位对应的时间public long convert(long sourceDuration, TimeUnit sourceUnit) { throw new AbstractMethodError();}// 转为纳秒public long toNanos(long duration) { throw new AbstractMethodError();}// 转为微秒public long toMicros(long duration) { throw new AbstractMethodError();}// 转为毫秒public long toMillis(long duration) { throw new AbstractMethodError();}// 转为秒public long toSeconds(long duration) { throw new AbstractMethodError();}// 转为分钟public long toMinutes(long duration) { throw new AbstractMethodError();}// 转为小时public long toHours(long duration) { throw new AbstractMethodError();}// 转为天public long toDays(long duration) { throw new AbstractMethodError();} 大概所有实例都会使用到的一个转换方法 123456// 计算 d * m，同时反之溢出static long x(long d, long m, long over) { if (d &gt; over) return Long.MAX_VALUE; if (d &lt; -over) return Long.MIN_VALUE; return d * m;} 此外，为了换算的方便，还提供了几个静态变量(分别对应上述的各个时间之间的转换关系) 1234567static final long C0 = 1L;static final long C1 = C0 * 1000L;static final long C2 = C1 * 1000L;static final long C3 = C2 * 1000L;static final long C4 = C3 * 60L;static final long C5 = C4 * 60L;static final long C6 = C5 * 24L; 由于这些转换相对来说比较简单，这里只分析其中一两个具体实现 123456789101112131415NANOSECONDS { // nano转nano，直接返回即可 public long toNanos(long d) { return d; } // nano转micro，c1/c0算出mico比nano的倍数，d/倍数，换算成micro public long toMicros(long d) { return d/(C1/C0); } // 同上，不展开了 public long toMillis(long d) { return d/(C2/C0); } public long toSeconds(long d) { return d/(C3/C0); } public long toMinutes(long d) { return d/(C4/C0); } public long toHours(long d) { return d/(C5/C0); } public long toDays(long d) { return d/(C6/C0); } public long convert(long d, TimeUnit u) { return u.toNanos(d); } // 注意这个方法，是TimeUnit的一个抽象方法，用于计算d比m多出来的微秒数（除了nano、micro外其他都为0） int excessNanos(long d, long m) { return (int)(d - (m*C2)); }} 123456789101112DAYS { // 通过x函数计算，同时避免溢出，最大允许转换为Long.MAX_VALUE/一天的nano数 public long toNanos(long d) { return x(d, C6/C0, MAX/(C6/C0)); } public long toMicros(long d) { return x(d, C6/C1, MAX/(C6/C1)); } public long toMillis(long d) { return x(d, C6/C2, MAX/(C6/C2)); } public long toSeconds(long d) { return x(d, C6/C3, MAX/(C6/C3)); } public long toMinutes(long d) { return x(d, C6/C4, MAX/(C6/C4)); } public long toHours(long d) { return x(d, C6/C5, MAX/(C6/C5)); } public long toDays(long d) { return d; } public long convert(long d, TimeUnit u) { return u.toDays(d); } int excessNanos(long d, long m) { return 0; }}; 另外几个比较常用的方法 1234567891011// 支持多种时间单位的waitpublic void timedWait(Object obj, long timeout) throws InterruptedException { if (timeout &gt; 0) { // 先转mill long ms = toMillis(timeout); // 计算剩余的nano int ns = excessNanos(timeout, ms); obj.wait(ms, ns); }} 123456789// 支持多种时间单位的joinpublic void timedJoin(Thread thread, long timeout) throws InterruptedException { if (timeout &gt; 0) { long ms = toMillis(timeout); int ns = excessNanos(timeout, ms); thread.join(ms, ns); }} 12345678// 支持多种时间单位的sleep，大概是TimeUnit中用得最多的方法了public void sleep(long timeout) throws InterruptedException { if (timeout &gt; 0) { long ms = toMillis(timeout); int ns = excessNanos(timeout, ms); Thread.sleep(ms, ns); }}","link":"/2019/10/06/TimeUnit%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%88%86%E6%9E%90/"},{"title":"axios导出文件使用总结","text":"这篇文章主要是最近几天在工作中遇到的导出文件总结 之前团队在导出文件的时候，由于使用axios导出之后，非文本文件都会乱码，所以采用另外一种方式，但是该方式存在严重缺陷，在经过调研之后，发现axios本身是支持的，所以重新采用通过axios来导出 axios导出文件使用总结背景之前在导出的时候，前端的同学直接使用axios，发现导出的时候，文件乱码而且没有办法获取到文件的内容，所以采用window.location.href=XXX直接指向下载地址 如：window.location.href=http://localhost/test/export 这种方式非常直观，直接通过浏览器来访问下载，但同时缺点也非常明显 仅支持get方式 无法携带头信息，尤其是系统需要权限访问的时候，只能开放该接口，从而引入不必要的风险 当参数信息多的时候，拼接在地址后面繁琐 尤其是在对接过程中，有一个接口本身的参数信息非常多，而且某些参数本身存在特殊字符，直接通过URL的形式，就需要先将其进行编码，然后接口收到之后，再解码回来，再组装成对象，操作繁琐，而且不通用 故决定调研新的方案 解决方案经过一番调研之后，发现axios本身是支持文件下载的(与文件格式、类型无关)，只是需要额外的配置 axios在发起请求的时候，有一个参数：responseType，该类型用于设置axios如何解析HTTP请求返回的数据，默认情况下，该值为string，从axios的代码可以看出，如下所示 12345export interface AxiosRequestConfig { .... responseType?: string; ...} 如此就可以看出前面通过axios下载非文本文件乱码的原因了，返回的数据流被axios解析为string类型的，而此时下载的文件本身是有其特定的类型如PDF、Excel这一类型，因此，在进行导出文件的时候，需要将返回类型配置为：Blob Blob是一个代表原始数据的不可变类，JS中的File是Blob派生出来的代表文件系统数据的对象 通过Blob对象，可以直接操作文件数据，此外，Blob对象可以通过URL.createObjectURL(XX)转换为URL，从而将Blob对象转换为一个地址，从而进行下载等操作 示例代码如下 12345678910111213141516171819202122232425axios({ url: root + url, data: param, method: method, responseType: 'blob', headers: { token: StorageUtils.getItem('token') } }).then((response) =&gt; { if (response.status !== 200) { // 错误处理 return } // response解析见下面分析 const url = window.URL.createObjectURL(response.data) // 将该url包装成一个连接，并且模拟点击，从而实现下载的功能 const link = document.createElement('a') link.href = url document.body.appendChild(link); link.click(); // 释放资源 window.URL.revokeObjectURL(url); document.body.removeChild(link) }); response 上面的代码中直接使用response.data作为createObjectURL()的参数，原因在于在axios中response的data属性本身代表的就是返回的数据，当然，在配置为blob类型之后，data就是一个Blob对象了 到这里，通过axios导出文件的处理方式就分析清楚了 总结在下载文件的时候，需要将responseType配置为blob，在获取到下载的数据之后，将其通过URL.createObjectURL转换为一个URL，然后通过&lt;a&gt;标签或者我们前面提到的window.location.href=XXX等能够通过URL发起GET请求操作的工具将下载完毕的字节流保留下来即可 所以说，碰到问题的时候，还是应该先调研、分析，而不是绕开问题，无论怎么绕开，最后还是有很大的概率会碰到该问题，毕竟问题本身没有解决，只是被绕开了，共勉","link":"/2019/11/21/axios%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"title":"【SpringBoot】SpringBoot 自动装配原理","text":"SpringBoot中很酷的一个功能是自动装配 装配的对象是依赖，也即Spring中的Bean，而所谓的自动装配，就是尽量不需要人工配置Bean信息，比如说在没有SpringBoot之前，我们装配一个Spring MVC，需要在配置文件中配置DispatcherServlet、视图解析器等等的依赖，而在SpringBoot中则不需要，只需要引入一个Starter就能做到 原理呢，就是通过某种形式来实现自动加载依赖，而不再通过程序员配置的形式来注入 这篇文章，就来详细分析SpringBoot中是自动装配的原理 【SpringBoot】SpringBoot 自动装配原理一个简单的StarterSpringBoot中的Starter是一中模块机制，通过引入该模块，就能实现该模块相关Bean的自动注入，为了弄清楚其原理，这里我们先写一个简单的Starter 新建一个maven项目，引入如下依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 然后新建一个配置类 12345678910@Configuration@EnableConfigurationPropertiespublic class HelloServiceAutoConfig { @ConditionalOnMissingBean @Bean(&quot;helloService&quot;) public HelloService helloService() { return new HelloService(); }} 上面有几个注解 @Configuration，是将该Bean声明为配置Bean @EnableConfigurationProperties，是开启自动配置配置文件功能 @ConditionalOnMissingBean，用于来实现条件注册Bean，当没有该Bean时才注册 @Bean，表示该方法返回的对象需要注册到IoC容器中 1234567891011@ConfigurationProperties(prefix = &quot;cn.xuhuanfeng.hello&quot;)public class HelloService { private String prefix; private String suffix; // 省了set、get方法 public String sayHello(String name) { return prefix + &quot; &quot; + name + &quot; &quot; + suffix; }} 上面的@ConfigurationProperties是用于将配置文件中的配置自动注入到Bean中，如里头的：prefix、suffix等信息 之后，在resources目录中新建一个META-INF目录，并且在里头建一个名为：spring.factories的文本文件，内容如下 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.xuhuanfeng.config.HelloServiceAutoConfig 键是：org.springframework.boot.autoconfigure.EnableAutoConfiguration，值则是上面的配置类的全路径名称 编译，打包，然后安装到本地仓库中：mvn install 此时，在本地就可以引用该模块了，可以建一个SpringBoot项目测试一下，这里就不演示了 为什么是Starter为什么需要打包成Starter呢？不能直接打包成一个普通的jar包，然后标注上Spring的Bean注解如：@Component，然后通过Spring的组件扫描机制自动装载进去吗？ 很遗憾，很多时候是不行的，原因在于，Spring的组件扫描机制是基于包路径的，也就是说，如果引入的jar包的包路径不符合类扫描路径的时候，是不会被Spring自动发现的，此时，又回到了手工创建Bean的时代了 增加包扫描路径，可行，但是不太现实，毕竟依赖包那么多，写不完的 Starter是如何工作的如果之前接触过SPI机制，那么从上面的spring.factories文件中，大概是可以猜得出来，Starter的运行原理了，对的，Starter通过类似于SPI的机制来实现配置类的加载，然后通过配置类加载来加载对应的Bean，从而实现自动装配的原理的 下面详细分析具体的实现细节 一个最基础的SpringBoot应用大概如下所示 123456@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 其中，最重要的是@SpringBootApplication注解，点击去可以看到如下信息： 12345// ....省略无关注解@EnableAutoConfigurationpublic @interface SpringBootApplication { // ....} 上面省略了一些不相干的注解，只留下了@EnableAutoConfiguration，该注解是实现Starter核心的核心 12345// ....@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration { // ....} 这里，最重要的是：@Import注解，以及其引入的：AutoConfigurationImportSelector @ImportJavaConfig项目中的一个组件，目的是用于将对应的bean添加到容器中，该注解可以支持以下几种类型的值 普通的类，这里的普通是指不承担其他的功能 配置类：也就是@Configuration标注的类 ImportSelector：导入选择器的实现类，容器会加载其方法返回的bean ImportBeanDefinitionRegistrar：beanDefinitionRegistrar的实现类 这里的AutoConfigurationImportSelector就是ImportSelector的实现，从下面的类图中可以看出 ImportSelector中只有一个方法：String[] selectImports(AnnotationMetadata importingClassMetadata)，容器会将该方法返回的全类名类加载到容器中 所以我们直接看AutoConfigurationImportSelector的selectImports方法即可 AutoConfigurationImportSelector#selectImports 12345678@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) { // .... // 这一行代码是关键 AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata,annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());} getAutoConfigurationEntry 12345678910111213141516protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) { // ... // 这一行是关键 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 后面的可以不看了 configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);} getCandidateConfigurations 12345678910protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { // 这一行是关键 List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations;} 看到这里有木有一点点惊喜：SpringFactoriesLoader，上面我们写的文件是：spring.factories SpringFactoriesLoader是Spring中一个通用的加载器，用于加载指定目录文件：FACTORIES_RESOURCE_LOCATION，也就是：&quot;META-INF/spring.factories&quot;中的配置信息 其中的方法：loadFactoryNames可以根据类型名称来获取指定配置项的内容 上面代码中的getSpringFactoriesLoaderFactoryClass()返回值是：EnableAutoConfiguration.class 这个是前面spring.factories中的key：org.springframework.boot.autoconfigure.EnableAutoConfiguration，也就是说，加载这个key中配置的bean，也就是我们自己写的配置Bean了 接着分析下去 loadFactoryNames 123456public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) { String factoryTypeName = factoryType.getName(); // 根据key来获取对应的value，这里key既是：EnableAutoConfiguration return loadSpringFactories(classLoader) .getOrDefault(factoryTypeName, Collections.emptyList());} loadSpringFactories 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories( @Nullable ClassLoader classLoader) { // 先从缓存中获取，如果有，直接返回 MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) { return result; } try { // 通过类加载加载指定的文件：META-INF/spring.factories Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); /* * public LinkedMultiValueMap() { * this.targetMap = new LinkedHashMap&lt;&gt;(); * } */ result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) { // 其中的一行，即类路径中的一个：spring.factories URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); // 将其内容作为properties加载该文件 Properties properties = PropertiesLoaderUtils.loadProperties(resource); // 遍历每一项 for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) { // key String factoryTypeName = ((String) entry.getKey()).trim(); // value，将value按照,切分 for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) { // 添加到map中，key就是对应的key result.add(factoryTypeName, factoryImplementationName.trim()); } } } // 放入缓存 cache.put(classLoader, result); return result; } catch (IOException ex) { throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); }} 到这里就一目了然了，SpringBoot的Starter其实是通过类似于SPI的机制 通过@Import导入：AutoConfigurationImportSelector，在AutoConfigurationImportSelector的selectImports中通过：SpringFactoriesLoader读取配置文件：spring.factories中的配置信息，然后将 对应的信息，也就是我们配置的自动配置类信息返回，并且容器会加载返回的自动配置类信息，而在自动类配置信息加载的时候，容器会解析其标注了@Bean的方法，从而实现了依赖的自动注入 实例虽然通过前面的简单的Starter我们已经知道了怎么实现了，不过为了说明我们的分析是正确的，我们通过springboot官方的一个AutoConfiguration来验证 这里选择：DispatcherServletAutoConfiguration，该配置信息位于：spring-boot-autoconfigure-2.2.4.RELEASE.jar/META-INF/spring.factories中，点开该文件之后，搜索该文件名就可以找到了 该类的基本信息如下： 12345678910111213141516171819202122232425262728293031@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(DispatcherServlet.class)@AutoConfigureAfter(ServletWebServerFactoryAutoConfiguration.class)public class DispatcherServletAutoConfiguration { // .... @Configuration(proxyBeanMethods = false)true@Conditional(DefaultDispatcherServletCondition.class)true@ConditionalOnClass(ServletRegistration.class)true@EnableConfigurationProperties({ HttpProperties.class, WebMvcProperties.class })trueprotected static class DispatcherServletConfiguration {truetrue@Bean(name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)truetruepublic DispatcherServlet dispatcherServlet(HttpProperties httpProperties, WebMvcProperties webMvcProperties) { // 注意这里哦truetruetrueDispatcherServlet dispatcherServlet = new DispatcherServlet();truetruetrue// ....truetruetruereturn dispatcherServlet;truetrue}truetrue@Beantruetrue@ConditionalOnBean(MultipartResolver.class)truetrue@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME)truetruepublic MultipartResolver multipartResolver(MultipartResolver resolver) {truetruetruereturn resolver;truetrue}true}} 总结这篇文章主要是分析SpringStarter的实现原理，首先是通过一个简单的Starter来说明Starter的实现方式，然后通过分析SpringBoot加载Starter的源码，详细地分析了加载的机制","link":"/2020/03/08/%E3%80%90SpringBoot%E3%80%91SpringBoot%20%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E5%8E%9F%E7%90%86/"},{"title":"红黑树学习笔记","text":"这篇文章是红黑树学习过程中的笔记，主要涉及到二叉搜索树、二叉平衡树、2-3树、红黑树，前面的每一种树都存在着各自的缺点，科学家们通过对这些缺点进行改进(现实世界不一定是按照这个顺序、过程来的，这里是我自己的理解，推导的过程)，最终得到了红黑树这种数据结构 红黑树是一种高性能的二叉搜索树，提供了在极端情况下，插入、删除、查找都是O(Log(N))的性能，同时也是Java中TreeMap，以及JDK1.8中HashMap用于提高性能的重要实现依据 二叉搜索树二叉树搜索树(BST，Binary-Search-Tree)是二叉树的一个变种，在存储的时候，每个节点的左节点的值比该节点的值小，右节点的值比该节点的值大，在建立二叉树的时候，通过该策略进行插入节点即可保障该性质的成立 通过该性质，BST可以实现在理想情况下O(Log(N))的查找性能，这里的理想情况是指颗BST是接近平衡的(任意叶子节点到root的距离差不大于1)，原因就在于数据完全被打散到各个节点中，并且节点中的顺序已经是维护好了(通过中序遍历即可获得一个递增序) 然而，BST在极端的情况下则会退化为链表，如数据本身就是有序(递增、递减)，那么节点的插入会一直发生在最左/最右的位置，因而检索性能会退化为O(N)，单数据量稍微大一些的时候，这两者的差距就很明显了，log(1024) = 10，已经接近100倍的差距了 二叉平衡树二叉检索树的理想情况下的O(Log(N))的检索性能是非常吸引人的，只是在极端情况下容易蜕变成链表，只要能解决这个问题，那么该数据结构就变得非常好用了 常用的解决方式是通过“平衡”的方式，将一颗不平衡的树通过某些操作在不违背该树的性质的情况下转换为平衡的树，那么问题就能得到解决了 常用的平衡操作是旋转，将某节点的左节点作为自己的父节点，自己成为该节点的右节点(右旋)，或者将该树的右节点作为自己的父节点，自己成为该节点的左节点(左旋)，如下图所示 二叉平衡树(AVL)就是通过旋转操作来实现“平衡”的一种二叉树，BST结合平衡操作就能构造出理想的BST，该BST在极端情况下也能达到O(Log(N))的检索性能 然而AVL也有比较明显的缺点，AVL为了实现平衡，定义了平衡的概念：任意叶子节点到root的距离差不大于1，这也就意味着，当某一个分支插入节点之后，不满足平衡条件时，就需要进行旋转操作，而基本上所有的插入操作都会导致旋转，这会带来严重的问题，为了平衡而实现的平衡操作，占据了大部分的操作时间，几乎抵消了平衡本身多带来的优势了 2-3树虽然AVL理想情况下非常的完美，但是由于AVL的旋转操作带来太大的性能损耗了，使得AVL本身并不太适合用于实际的使用，这也恰恰是AVL能够改进的地方，既然旋转的频率太高而带来性能损耗，那么不用旋转，而采用其他方式来实现就可以了，2-3树就是这样的一种数据结构 注：由于下面的图实在是太难画了，囧，下面出现的图来自《Algorithm 4th》里头的图，向作者大大表示感谢:)，作者的图画得真的超级好看，手残党表示非常羡慕了 2-3树通过定义两种类型的节点：两个分叉的节点(2节点)、三个分叉的节点(3节点)，并且通过节点之间的转换来实现树本身的平衡，从而抵消AVL频繁旋转带来的消耗 2-3的平衡操作有两种 节点分裂 节点分裂，目标节点是3节点时(插入后新元素后变成4节点)，进行节点分裂，将一个3节点分裂成两个2节点(中间元素向上合并到父节点中) 节点合并 当插入节点时，如果当前父节点是2节点，则将其转换为3节点，并且将新元素放在该节点即可 当目标节点是3节点，并且父节点时2节点时，当前3节点分裂，并且中间的元素合并到父节点(等价于拆分当前节点，然后往父节点插入元素，向上重复操作，只是插入操作变成了父节点) 其他的情况都是上面三种情况的重复，比如父节点是三节点，子节点也是三节点，此时依次往上拆分、合并即可 通过2-3树的拆分、合并操作，同样能使得树达到平衡状态，这个非常直观，也挺好证明的： 假设原先的2-3树是平衡树(0(nil)、1(2节点)、2(3节点)元素) 当2节点插入元素时，树高保持不变，所以树是平衡的 当3节点插入元素时： ​ 如果父节点是2节点，拆分当前3节点，并且合并中间元素到父节点，此时树高没有发生变化，所以树是平衡的 如果父节点是3节点，拆分当前3节点，并且将中间元素合并到父节点，父节点继续向上完成该操作，此时如果每个父节点都是3节点，则root会拆分，形成新的左右两个节点，此时树高+1，但树本身依旧是平衡的 由此可以证明，2-3树和AVL一样，都是平衡的，然而，事情到这里并没有结束，2-3树的操作实在是太复杂了，一会2节点‘一会3节点的，还各种合并、分裂，维护起来特别复杂，所以实际上的应用中，也没有使用2-3树作为平衡树使用 红黑树由于AVL、2-3树本身要么是操作太多，导致插入性能不佳，要么是操作复杂，不实际，因此科学家们想出了一种新的等效方案，红黑树 红黑树是2-3树的一个等效方案，或者说，红黑树是AVL与2-3树完美融合的一个实现，既保障了性能、实现起来也不太复杂(其实也非常复杂，囧…..) 红黑树的特性： 每个节点有两种颜色：黑色、红色，分别对应2-3树中的2节点、3节点 根节点是黑色的 从根节点出发到叶子节点，每条路径下没有相邻的两个红色节点(2-3树节点拆分、合并操作，通过AVL的旋转以及红黑树自身的变色操作进行等效变换) 从根节点触发到叶子节点，每个节点路径上的黑色节点个数相同(“平衡树”) 红黑树通过红黑节点来替代2-3树中的2、3节点，然后通过旋转、变色来替换2-3树的节点分裂、合并 从本质上来说，红黑树是2-3树 (上面的红色连接表示的左端表示的是红节点，将红色连接链接的节点合并在一起，并且消除红色连接，则可以得到对应的2-3树)，由于2-3树是平衡的，所以红黑树也是平衡的 从上面可以看到，红色节点其实是由2-3树中的3节点拆分得到，因此，2-3树中的2-3节点可以规约为一种节点，并且通过颜色变换来得到 《Algorithm 4th》中，作者规定了在等效的红黑树中，红色线条只能出现在左侧，而不能出现在右侧，其实是可以出现在右侧的，但是一棵树中，只能同时存在一个方向，要么都在左侧，要么都在右侧，这里同样约定只能出现在左侧 默认插入的节点都是红色节点，于是乎，会得到下面几种插入的情况 插入到单个节点的某一侧（相当于2-3树中的新插入节点） 插入到左侧，满足情况，无需任何变化 插入到右侧，违背了红色只能在左侧的情况，通过旋转进行调整 插入到2节点(等效2-3树的2节点，前面提到的)的某一侧 插入到左侧，同样满足 插入到右侧，不满足，通过旋转调整 插入到3节点的某一侧(前面提到的2-3树3节点的特性) 最左侧 父节点是黑色的，满足约束 父节点是红色的，违背了同一路径不能有两个相邻的红色节点，通过旋转，变色解决 中间，由于中间节点等效变换后，插入会直接在右侧，所以一定不满足，通过旋转，转换为1的形式，通过1的解决方式进行解决 最右侧，等效于2，通过2的方式进行解决 可以看到，2-3树的插入操作，可以通过红黑树进行完美的等效变化，红黑树的各个状态转换也能进行有效规约，因此，状态本身不存在膨胀情况，状态转换图如下","link":"/2020/12/06/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"记一次神奇的RedisLockRegistry异常分析过程","text":"一次神奇的RedisLockRegistry异常，程序运行过程中一直抛出java.nio.BufferOverflowException，百思不得其解，最后终于通过跟踪源代码，定位到问题，最终发现是低版本Spring-Redis的一个Bug 记一次神奇的RedisLockRegistry异常分析过程问题早上之前项目组的一个同事说在使用RedisLockRegistry出现了神奇的异常，让我帮忙看下问题所在，他自己分析不出来(其实就是懒，囧….)，刚好早上比较空闲，就看了下问题 异常信息： 123org.springframework.dao.CannotAcquireLockException: Failed to lock mutex at XXX; nested exception is java.nio.BufferOverflowExceptiontrueat org.springframework.integration.redis.util.RedisLockRegistry$RedisLock.rethrowAsLockException(RedisLockRegistry.java:362) trueat org.springframework.integration.redis.util.RedisLockRegistry$RedisLock.lock(RedisLockRegistry.java:356) 1234567Caused by: java.nio.BufferOverflowException: nulltrueat java.nio.HeapByteBuffer.put(HeapByteBuffer.java:189) ~[na:1.8.0_121]trueat java.nio.ByteBuffer.put(ByteBuffer.java:859) ~[na:1.8.0_121]trueat org.springframework.integration.redis.util.RedisLockRegistry$LockSerializer.serialize(RedisLockRegistry.java:620) trueat org.springframework.integration.redis.util.RedisLockRegistry$RedisLock$1.doInRedis(RedisLockRegistry.java:438) trueat org.springframework.integration.redis.util.RedisLockRegistry$RedisLock$1.doInRedis(RedisLockRegistry.java:423) trueat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:207) 分析从上面的异常信息来看，应该是在获取锁的时候出现异常BufferOverflowException，一开始分析的时候还觉得很奇怪，异常信息提示的是ByteBuffer的问题，好像跟锁本身没啥子挂钩(两个层次的问题，一个是应用层，一个是数据传输层) 从异常信息本身没有获取过多的信息，于是从异常堆栈入手分析，起点是：RedisLockRegistry.obtainLock#doInRedis 代码如下： 123456789101112131415public Boolean doInRedis(RedisConnection connection) throws DataAccessException { long expireAfter = TimeoutUtils.toSeconds(RedisLockRegistry.this.expireAfter, TimeUnit.MILLISECONDS); RedisSerializer&lt;String&gt; serializer = RedisLockRegistry.this.redisTemplate.getStringSerializer(); byte[][] actualArgs = new byte[][] { serializer.serialize(constructLockKey()), RedisLockRegistry.this.lockSerializer.serialize(RedisLock.this), serializer.serialize(&quot;NX&quot;), serializer.serialize(&quot;EX&quot;), serializer.serialize(String.valueOf(expireAfter)) }; return connection.execute(&quot;SET&quot;, actualArgs) != null;} 咋一看好像没啥问题，根据堆栈信息再进一步跟踪：LockSerializer.serialize，也就是上面第8行所在的地方，代码如下 123456789101112131415161718192021222324252627private class LockSerializer implements RedisSerializer&lt;RedisLock&gt; { @Override public byte[] serialize(RedisLock t) throws SerializationException { int hostLength = t.lockHost.length; int keyLength = t.lockKey.length(); int threadNameLength = t.threadName.length(); byte[] value = new byte[1 + hostLength + 1 + keyLength + 1 + threadNameLength + 8]; ByteBuffer buff = ByteBuffer.wrap(value); buff.put((byte) hostLength) .put(t.lockHost) .put((byte) keyLength) .put(t.lockKey.getBytes()) .put((byte) threadNameLength) .put(t.threadName.getBytes()) .putLong(t.lockedAt); return value; } @Override public RedisLock deserialize(byte[] bytes) throws SerializationException { // .... }} 这个类的是Spring团队为实现Redis分布式锁实现的一个序列化器，其中序列化和反序列化是对称的，所以挑选其中一个分析，果然，发现了一些端倪 1234567891011121314151617int hostLength = t.lockHost.length;int keyLength = t.lockKey.length();int threadNameLength = t.threadName.length();byte[] value = new byte[1 + hostLength + 1 + keyLength + 1 + threadNameLength + 8];ByteBuffer buff = ByteBuffer.wrap(value);buff.put((byte) hostLength) .put(t.lockHost) .put((byte) keyLength) .put(t.lockKey.getBytes()) .put((byte) threadNameLength) .put(t.threadName.getBytes()) .putLong(t.lockedAt); 这个方面的目的很清晰，就是以：长度内容长度内容...这样的形式键锁相关的信息进行序列化 注意1-3行、5-7行、11-17行，这里是有问题的string.length()获取的是字符数，比如 1234String a = &quot;123&quot;;String b = &quot;你好中国&quot;;System.out.println(a.length()); // 3System.out.println(b.length()); // 4 5-7行申请的byte[]长度也是用字符数进行计算的，然而，在11-17行的地方，用的是bytes，也就是字节数，这在单字节字符是正常的，而在多字节字符，比如汉语就有问题了 1234String a = &quot;123&quot;;String b = &quot;你好中国&quot;;System.out.println(a.getBytes().length); // 3System.out.println(b.getBytes().length); // 12 所以当使用的key或者threadName不是单字节字符时，就会出现文章开始提到的BufferOverflowException了，跟同事确认了下，确实线程名用的是英文名，囧….. 这里除了字符长度计算问题外，还有一个隐藏的Bug，同样在11-17行这里，(byte)XXXX，这里是将一个int转为byte，所以但int长度超过byte的范围(2^7-1)，即128的时候，就有坑了（溢出）…，放进去是没问题的，但是拿出来的时候，会出现拿一个负数的字节 12345byte[] host = new byte[buff.get()];buff.get(host);// 这里如果是负数的话，就很那啥了...byte[] lockKey = new byte[buff.get()];buff.get(lockKey); 后记前面提到了，项目中使用的Redis锁版本是：4.3.9，这是SpringBoot 1.5.3.RELEASE默认的版本，本来还想给官方提个issue，不过翻了下代码记录，在：5.0.x分支已经采用其他的方式了，记录及变更内容如下 12345678910111213commit f7f7bdd067428ae570c6bc0cfe489e1698c0a203Author: Vedran Pavic &lt;vedran.pavic@gmail.com&gt;Date: Fri Mar 31 23:47:27 2017 +0200INT-4248: Refactor `RedisLockRegistry`JIRA: https://jira.spring.io/browse/INT-4248To avoid unexpected double locking behavior in the cluster,remove the local cache functionality.Now with the new `clientId` property, the `expire` for the record instore is always update on each lock operation 123456789101112131415private boolean obtainLock() {trueBoolean success =truetruetrueRedisLockRegistry.this.redisTemplate.execute(truetruetruetrueRedisLockRegistry.this.obtainLockScript,truetruetruetrueCollections.singletonList(this.lockKey), truetruetruetrueRedisLockRegistry.this.clientId,truetruetruetrueString.valueOf(RedisLockRegistry.this.expireAfter));trueboolean result = Boolean.TRUE.equals(success);trueif (result) {truetruethis.lockedAt = System.currentTimeMillis();true}truereturn result;} 跟踪上面的execute方法，调用链：execute--&gt;execute--&gt;keysAndArgs 最终可以进入到下面的代码中： 1234567891011121314151617181920212223242526protected byte[][] keysAndArgs(RedisSerializer argsSerializer, List&lt;K&gt; keys, Object[] args) { final int keySize = keys != null ? keys.size() : 0; byte[][] keysAndArgs = new byte[args.length + keySize][]; int i = 0; // 序列化key if (keys != null) { for (K key : keys) { if (keySerializer() == null &amp;&amp; key instanceof byte[]) { keysAndArgs[i++] = (byte[]) key; } else { keysAndArgs[i++] = keySerializer().serialize(key); } } } // 序列化参数 for (Object arg : args) { if (argsSerializer == null &amp;&amp; arg instanceof byte[]) { keysAndArgs[i++] = (byte[]) arg; } else { keysAndArgs[i++] = argsSerializer.serialize(arg); } } return keysAndArgs;} 可以看到，从5.0.X版本开始，采用的是新的实现方式，其中的keySerializer()以及argsSerializer，返回的是当前RedisTemplate设定的序列化器，默认是：JdkSerializationRedisSerializer 这个就不存在前面提到的问题了 好像又水了一波…..那就这样吧","link":"/2020/09/11/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%A5%9E%E5%A5%87%E7%9A%84RedisLockRegistry%E5%BC%82%E5%B8%B8%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/"},{"title":"跳跃表学习笔记","text":"跳跃表学习笔记跳跃表(Skip List)，是一种基于概率，提供了查找、插入、删除近似于O(logN)性能的数据结构。 这篇文章是学习跳跃表的一个记录，包含了跳跃表的原理以及其Java实现 介绍跳跃表(Skip List)，是一种基于概率，提供了查找、插入、删除近似于O(logN)性能的数据结构。 在线性数据结构中，查找、插入、删除性能均为O(N)，当数据量比较大的时候，是非常不乐观的，因此，科学家们相处了各种各样的数据结构来进行优化，将线性的数据结构进行一系列转换，从而得到在理想情况下查找、插入、删除性能均为或近似为O(logN)的数据结构，前面提到的AVL、红黑树是通过平衡(旋转、变色)等将线性数据结构转换为平衡树，从而利用平衡树的特性来实现O(logN)的复杂度 除了平衡树之外，还有另外一种数据结构，跳跃表，采取另类的思路来实现同样的性能优化，平衡树等牺牲的是部分的操作性能，而跳跃表牺牲的则是空间 跳跃表可以达到与红黑树等类似的性能，并且实现起来相对简单，虽然消耗部分空间，但也具有一定的应用场景，例如redis中的sorted set、Java中的ConcurrentSkipListMap就是通过跳跃表来实现的 原理跳跃表本质上是基于链表，并且跳跃表中的元素是有序的(默认根据key递减) 传统的链表查找、插入、删除操作都是O(N)，跳跃表对其进行了优化，为原来的链表建立多个层次(基于概率函数)的索引，每个层次的索引依次递减(通过概率来控制，而非严格的数量关系)，从而建立了一个基于链表的性能卓越的跳跃表数据结构，如下图所示： 最底层黄色的节点是实际上真正的数据节点，从最底层往上的每一个层次都是下一个层次的索引 查找节点 在查找的时候，从最head节点出发，在最顶层开始往右边查找，直到第一个不小于目标值的节点出现，说明目标节点位于当前节点区间，从上图中也可以看到，最顶层的索引是非常稀疏的，所以最上层节点的查找速度是非常快的，然后从当前节点往下一层次查找，重复上述步骤，直到到达最底层 举个栗子：查找节点8 12341. head的最顶层(第4层)出发，此时已经到达第四层的末尾处2. 从第3层出发，1&lt;8，4&lt;8,6&lt;8，此时已经到达第三层的末尾处3. 从第二层key为6的节点出发，9&gt;8，继续往下一层查找4. 从第一层key为6的节点出发，6&lt;8，7&lt;8,8=8，找到目标节点 可以看到，此时仅仅需要4次查找，而链表本身的长度为10 插入节点 插入节点的前部分操作与查找节点一样，先找到离目标节点最近的节点(目标节点或前一个节点)，然后插入目标节点，根据概率函数，计算当前节点应该所占有的层次，然后依次补充将每个层次对应的索引链表连接起来(普通的链表插入操作) 具体插入步骤参见上图 删除节点 删除节点的操作步骤与插入节点类似，只是现在是找到之后，将其从各个层次的索引链表中删除(普通的链表删除操作) 注：以上所有的图片均来自维基百科-跳跃表介绍 实现从上面的描述以及图片示例，大致上已经能够猜测出实现的代码结构了 ListNode 123456789101112131415161718192021222324252627static class ListNode { // key private final String key; private String value; // 当前节点的层次数，由random函数生成 private Integer level; private final ListNode[] nexts; public ListNode(String key, String value, Integer level) { this.key = key; this.value = value; this.level = level; this.nexts = new ListNode[level]; } @Override public String toString() { return &quot;ListNode{&quot; + &quot;key='&quot; + key + '\\'' + &quot;, value='&quot; + value + '\\'' + &quot;, level=&quot; + level + '}'; }} SimpleSkipList 123456789101112131415161718192021222324252627/** * @author huanfeng */public class SimpleSkipList { // 节点的最高层次数 private static final int MAX_LEVEL = 16; // 控制每一层的概率 private static final double RATE = 0.25; // 跳跃表的头结点，该节点是空节点 private ListNode head = new ListNode(null, null, MAX_LEVEL); private int size = 1; private Random random = new Random(); private Integer randomLevel() { int level = 1; while (level &lt; MAX_LEVEL &amp;&amp; Double.compare(random.nextDouble(), RATE) &lt; 0) { level++; } return level; }} get：获取元素 12345678910111213141516171819202122public ListNode get(String key) { ListNode preNode = head; int level = preNode.level; // 注意这里查找出来的是目标key的前一个节点 // 从最高一层的索引链表往后、下查找 for (int i = level - 1; i &gt;= 0; i--) { // 判断next.val是否小于当前的key while (preNode.nexts[i] != null &amp;&amp; preNode.nexts[i].key.compareTo(key) &lt; 0) { preNode = preNode.nexts[i]; } // 往下一层继续查找 } // 如果前一个元素存在，并且其next的key等于目标key，说明我们找到了 if (preNode.nexts[0] != null &amp;&amp; preNode.nexts[0].key.compareTo(key) == 0) { return preNode.nexts[0]; } return null;} put：添加元素 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void put(String key, String value) { ListNode preNode = head; // 先查找看是否存在，存在则替换 ListNode currentNode = get(key); if (currentNode != null &amp;&amp; currentNode.key.compareTo(key) == 0) { currentNode.value = value; return; } int level = randomLevel(); ListNode[] nextHolder = new ListNode[level]; // 默认新插入的节点都由head指向，并且指向head.next // eg: // next = head.next // head -&gt; newNode -&gt; next for (int i = 0; i &lt; level; i++) { nextHolder[i] = head; } for (int i = level - 1; i &gt;= 0; i--) { while (preNode.nexts[i] != null &amp;&amp; preNode.nexts[i].key.compareTo(key) &lt; 0) { preNode = preNode.nexts[i]; } // 获取当前层次的next nextHolder[i] = preNode; } ListNode newNode = new ListNode(key, value, level); for (int i = 0; i &lt; level; i++) { // 将当前节点插入到所有层次中 // node的第i层的next = 目标节点的i层的next newNode.nexts[i] = nextHolder[i].nexts[i]; // 目标节点的i层的next指向当前的node nextHolder[i].nexts[i] = newNode; } head.level = Math.max(level, head.level); size++;} remove 12345678910111213141516171819202122232425262728293031public ListNode remove(String key) { ListNode preNode = head; int level = preNode.level; ListNode[] nextHolder = new ListNode[level]; for (int i = level - 1; i &gt;= 0; i--) { while (preNode.nexts[i] != null &amp;&amp; preNode.nexts[i].key.compareTo(key) &lt; 0) { preNode = preNode.nexts[i]; } nextHolder[i] = preNode; } // 找不到 if (preNode.nexts[0] == null || preNode.nexts[0].key.compareTo(key) != 0) { return null; } // 注意这里的步骤是必须的，因为跳跃表的level是随机的 // 因此，不是preNode的每一层的next都是指向目标节点 for (int i = level - 1; i &gt;= 0; i--) { if (nextHolder[i].nexts[i] != null &amp;&amp; nextHolder[i].nexts[i].key.compareTo(key) == 0) { nextHolder[i].nexts[i] = nextHolder[i].nexts[i].nexts[i]; } } return preNode.nexts[0];}","link":"/2020/12/17/%E8%B7%B3%E8%B7%83%E8%A1%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"驾照考取指南","text":"今天刚刚通过科目三、科目四，并且顺利地拿到了驾照，乘着考试的东西还没有忘记，将其记录下来，供有需要的有缘人参考 注：我是在深圳考取的驾照，这里的内容不同的城市可能稍微有点不同，请结合具体城市的实际情况使用 介绍驾照考取分为一下几个科目(满分均为100分) 科目一，90分及格 科目二，80分及格 科目三，90分及格 科目四(其实是科目三的道路安全)，90分及格 其中的科目一、科目四是笔试内容，形式为无纸化作答，也就是在俗称的电脑考，考试的内容是选择题，都是一些基础的安全概念，标识等 科目二是基础的操作技能训练，主要有五个内容 倒车入库/出库 侧方位停车 曲线行驶 直角转弯 半坡起步 科目三是道路行驶，主要包含以下几项 起步、停车 灯光操作 道路转弯(左转、右转) 直线行驶 变道 超车 加减档操作 掉头 攻略考试流程驾照的考取流程大致如下 选择驾校报名 科目一考试 通过了约教练练习科目二 科目二考试 通过了约教练练习科目三 科目三考试 科目四考试 获取驾照 注意，只有通过了上一个步骤，才能进行下一个步骤，这里是没法跳过的，而且科目二、三都只有五次机会，要是还没考过的话，本次报名就失效了，需要重新报名学习 驾校选择驾照的考试必须选择驾校，这个是国家规定的，哪怕你已经会开车了，也必须通过驾校学习之后才能报考 选择驾校以及教练，尽量从身边已经报考过的朋友、同事了解，避免踩坑，尤其是教练，有的教练脾气好，不会随便乱骂人，有的教练动不动就骂人，经常练车的时候让你感到怀疑人生，可以去知乎搜索：驾校教练骂人就知道了 科目一考试科目一考试只需要刷题即可，推荐使用驾校宝典APP，刷题的时候请注意，不要背题，不要背题，不要背题 如果你之前没有怎么接触过机动车，那么请认真对待科目一，弄懂每个题目涉及的内容(这些内容本质上就是《道路交通安全法》的浓缩)，比如前方道路左转的标识是哪一个，为什么是这样子的，而不是按照宝典中的技巧那样去记住，去记住题目的字眼 这部分如果每天抽半个小时做题，通过题目来掌握知识，基本上一周下来就可以掌握科目一要求的知识了，注意了，这里是指知识，而不是题目，题目只是形式，掌握那些知识才是重点。 将题目完整做完两遍，并且确定掌握知识点之后，就可以通过APP的模拟功能进行模拟，如果基本能保持90+，就可以约考了，如果是自主约考的方式，就自己去交管12123约考即可，如果是驾校负责，则等驾校通知即可 科目二考试科目二考试是整个驾照考取过程中最耗费时间的环节，尤其是如果你之前不会开车的话，整个科目二会花费相当多的时间 科目二一开始会学习方向盘，掌握方向盘的转向对车本身的转向的影响，比如方向盘左打一圈，车子本身会左转多少，这个基本上熟练了之后就能透过感觉来判断了 然后会学习离合器的控制，整个科目二的过程中需要掌握的核心就是方向盘、离合器、刹车器的使用，控制好这三个，剩下的就是练习了 然后就会开始练习倒车入库，这个部分是科目二中花费时间最多的，一般教练都会让你练好倒车入库之后才去练习其他的项目，基本上就是参考教练说的如何看点，转向即可 接下来就是侧方位、曲线、直角转弯、半坡起步，这几个是一起练习的，训练场一般是根据考试的路线建设的，这几个走一圈就是考试的完整路线了，掌握倒车入库之后就是所有科目串起来一起练习，也就是俗称的“跑圈” 科目二一定要记住那些点位，以及方向盘转向的时机，同时要理解好教练说的话，语言本身存在传递误差，加上部分教练本身没法表达清楚，因此一定要问清楚，然后结合网上的一些参考视频，抓紧时间掌握这部分的内容 可以结合这个视频来学习：科目二驾考教程详解、科目二 超耐心，点位可能跟教练讲的不一样，但是原理是一样的，只是参考点不同而已 科目三考试考完科目二的半个月后就可以进行科目三约考了，如果你有时间，就趁热打铁，通过科目二考试后，就学习科目三 科目三的关键是记住路线，记住路线，记住路线，记住所在考场的路线，一般是有三条线路，然后考试的时候随机分配线路 关于线路，要记住的有如下几个内容 路线怎么走，这个是最基础的 将路线拆分 哪些路段要用一档怠速走 哪些路段要上二挡、三挡、四挡 哪些路段要停车 … 如果光看图记不住的话，可以找张纸，看一遍，画一遍，不停地重复，知道自己能记住每个路线点 一般教练会发一张路线图纸和视频，结合这些看就行了，剩下的就是练习了 科目三的练习时间很短，一般就是三四天，平均下来一条路线也就练习两三次，练习的时候不要害怕，不要担心，害怕跟担心对练习一点帮助都没有，因此多了这两个也没啥用(科目三练习一直在害怕，担心，考科目三前一天晚上紧张得睡不着的我的真实经验) 这里的视频是深圳清湖科目三三条路线的视频，花了20块钱买的，有需要的话自取：链接: https://pan.baidu.com/s/1B377IZa_8OsRoN043WEBxg 提取码: q754 科目四在深圳，科目三跟科目四是可以连续考的，科目三考过了直接就可以在现场考科目四，考过了当场就可以拿证了 因此，在练习科目三的时候，也不要忘记科目四的学习(一般是考完科目二就先学习科目四，科目三练习的时候大概率是没有多余的时间来学习科目四了) 宝典APP继续走起 领驾照通过了四个考试项目就可以拿到驾照啦，希望每个人都能如愿拿到驾照 感悟从报名到领取驾照，前后大概是6个月(2020.11-2021.04)，这半年来，牺牲了蛮多的周六日去练习科目二，还有好几个晚上练习科目三到晚上十一点多，说实在，还是蛮累人的，但是拿到驾照的那一刻，还是很兴奋、很开心的，感谢你，亲爱的自己 这里要特别感谢一路上遇到的人，尤其是去考场这几次遇到的滴滴司机，科目一遇到滴滴司机一路跟我讲整个驾照考取的流程，要注意的细节，科目二遇到的滴滴司机一路开小灶给我培训操作要点(虽然已经掌握了，哈哈)，科目三遇到的滴滴司机看出我很紧张，一路陪我聊天，让我放松下来，这里真的很感谢你们，陌生的你们让这座城市有了新的温度 还有一起练车的哥们，你的沉着冷静让我学习了很多，祝愿你未来一切安好 至于教练，哼，好好说话会死吗？会死吗？会死吗？","link":"/2021/04/28/%E9%A9%BE%E7%85%A7%E8%80%83%E5%8F%96%E6%8C%87%E5%8D%97/"},{"title":"AtomicXXX使用及分析","text":"这篇文章主要是学习java.util.concurrent.atomic包过程中的记录及分析 atomic包下提供了众多的无锁的，线程安全的并发工具，在某些程度上扩充了Java的并发体系 AtomicXXX使用及分析 接下来的内容主要针对java.util.concurrent.atomic进行学习和分析 背景正如我们所知道的，Java中的递增操作，如i++并不是原子操作，也即是非线程安全，具体原因可以通过下面的例子看出 123456789101112public class IntegerTest { private int i = 0; public void incr() { i++; } public static void main(String[] args) { new IntegerTest().incr(); }} 这个例子包含一段非常简单代码，定义一个int变量，然后在方法中调用递增操作 下面的代码是通过javap -v XXX打印出来的字节码信息(仅incr方法) 12345678910111213141516171819public void incr(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lcn/xuhuanfeng/concurrency/atomic/primary/IntegerTest; 这里有一个地方需要注意，不能使用局部变量，如下面的例子 1234public void incr() { int i = 0; i++;} 此时由于i被封闭在了线程的栈帧中(一个方法对应一个栈帧)，在该栈帧中，变量是线程安全的，所以对应的操作也是安全的，javac直接采用iinc指令进行操作 123456public void incr(); Code: 0: iconst_0 1: istore_1 2: iinc 1, 1 // 直接调用iinc对局部变量进行递增操作 5: return 回到上面例子中的字节码 123456789101112131415161718public void incr(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 // 将this加载到操作数中，0号局部变量为this(下面的LocalVariableTable) 1: dup // 复制一份栈顶数据，即this 2: getfield #2 // Field i:I，获取字段i的值，并且push到操作数栈中 5: iconst_1 // 将 1 push到操作数栈中 6: iadd // 将 栈顶两个元素，即 0 和 1 进行相加 7: putfield #2 // Field i:I 将字段i写入到对象中 10: return LineNumberTable: line 12: 0 line 13: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lcn/xuhuanfeng/concurrency/atomic/primary/IntegerTest; 从字节码中可以看出，操作对象属性的时候，是先将其读取到操作数栈中，然后执行操作，再将其写入，也就是包含三个部分的操作：获取，操作，写入，这也印证了我们上面提到的i++本身并非原子操作 回到本节的主题，正是由于i++本身不是线程安全的，所以，在并发环境下进行此类操作的时候，需要进行同步处理，传统的做法是对方法加监视器锁，也即synchronized关键字或者加锁，即Lock接口的实现，这两种方式都是不错的方式，但，这两种锁本身都会带来一定的开销，如获取锁，释放锁等操作 在JDK1.5中，引入了java.util.concurrent.atomic包，并且提供了一系列的原子操作工具，如AtomicInteger、AtomicLong等，用于作为锁之外的另一种处理方式 atomic包中的所有操作都是基于CAS(Compare And Swap)机制进行处理的 CASCAS，全称是Compare And Swap，是一种基于无锁机制，需要CPU本身的支持，目前来说，使用的是CPU提供的指令CMPXCHG ，关于该指令，可以参考cmpxchg，不过我没看懂，囧….. atomic包中的操作都是基于CAS进行的 正如上面提及的，CAS需要CPU的支持，也即进行CAS操作的时候，需要使用原生的指令，而不是JVM指令，那么问题来了，在Java中是如何实现的呢 通过AtomicInteger中的代码我们可以大致了解一下 123public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1;} 可以看到，AtomicInteger中的cas操作是通过unsafe对象来操作的 1private static final Unsafe unsafe = Unsafe.getUnsafe(); 跟踪进去Unsafe类 123456789101112131415161718192021package sun.misc;public final class Unsafe { private static final Unsafe theUnsafe; @CallerSensitive public static Unsafe getUnsafe() { Class var0 = Reflection.getCallerClass(); // 检查是否是由Bootstrap Classloader if (!VM.isSystemDomainLoader(var0.getClassLoader())) { throw new SecurityException(&quot;Unsafe&quot;); } else { return theUnsafe; } } static { registerNatives(); Reflection.registerMethodsToFilter(Unsafe.class, new String[]{&quot;getUnsafe&quot;}); theUnsafe = new Unsafe(); }} 可以看到，Unsafe类的包名是sun.misc，并且Unsafe类仅能由Bootstrap Classloader进行加载，所以我们无法直接获取，但是也可以有其他的方法来操作，具体可以参考美团团队的文章：Java魔法类：Unsafe应用解析 跟踪进去之后，可以看到方法的签名：public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 由于是native方法，这里我就不展开了(其实主要是没看懂) 虽然看不懂，但也不影响对CAS机制的理解，CAS机制的原理也非常简单，其假设大部分情况下是没有人跟我们争数据的(乐观)，所以，不需要在每次修改的时候都获取锁，操作，再解锁，而是每次操作之前，先比较一下，看一下内存中的值是不是期待的值，如果是，则将其修改为目标值，否则，则说明有人在我们之前修改的数据，导致数据与预期的不一致，所以本次操作失败，当然，这个操作本身也不是原子的，但是有CPU的支持，一切就好说了 需要注意的是，CAS本身只会进行一次，如果失败了，那就失败了，但是这种操作给了我们一种启发，既然一次失败，那不停重试，直到成功，这种机制也称为自旋，即本身不拿锁，不阻塞，一直尝试，直到成功 可以看下Unsafe中的一个实现 123456789// atomicInteger中的incrementAndGet就是直接调用该方法来实现的public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;} AtomicXXX知道了Atomic本身是基于CAS的，并且大致了解了CAS的原理之后，关于AtomicXXX的使用其实就很简单了，每次操作的时候，都Atomic都是调用CAS，当需要一定设置成功的时候，就采用自旋机制进行操作 可以将AtomicXXX理解为对应的XXX的包装，并且提供了无锁的，能够保证线程安全的操作 需要注意的是，AtomicXXX中的对应字段的值都是volatile类型的，目的是为了保证可加性 123private volatile int value;private volatile long value;private volatile V value; AtomicInteger1234567891011121314151617181920212223242526public void testAtomicInteger() { AtomicInteger atomicInteger = new AtomicInteger(4); System.out.println(atomicInteger.get()); // 自增并且返回自增之后的值， ++i System.out.println(atomicInteger.incrementAndGet()); // 先返回再自增， i++ System.out.println(atomicInteger.getAndIncrement()); // i += n System.out.println(atomicInteger.getAndAdd(10)); // --i System.out.println(atomicInteger.decrementAndGet()); // i-- System.out.println(atomicInteger.getAndDecrement()); // i = 4 atomicInteger.set(4); // 如果内存中的值为4，则更新为10 boolean result = atomicInteger.compareAndSet(4, 10);} 对于AtomicInteger，基本上常用的也就这几个方法，更多的内容参考文档即可 AtomicBoolean相比于AtomicInteger，AtomicBoolean的操作就更加简单了 AtomicBoolean本身并没有直接对布尔值进行操作(主要是unsafe中也没有提供相应的操作)，本身实际上还是对int进行操作，1为true，0为false 12345public final boolean compareAndSet(boolean expect, boolean update) { int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u);} 看到这里，关于AtomicBoolean的操作就自然懂了，由目标是布尔类型，所以AtomicBoolean本身支持的操作不多 AtomicLong基本上AtomicLong提供的方法跟AtomicInteger类似，只是底层使用的unsafe提供的long相关的操作，所以这里就不展开了，参考下下面的方法签名即可 123456789101112131415161718192021public class AtomicLong { public AtomicLong(long); public AtomicLong(); public final long get(); public final void set(long); public final void lazySet(long); public final long getAndSet(long); public final boolean compareAndSet(long, long); public final boolean weakCompareAndSet(long, long); public final long getAndIncrement(); public final long getAndDecrement(); public final long getAndAdd(long); public final long incrementAndGet(); public final long decrementAndGet(); public final long addAndGet(long); public jString toString(); public int intValue(); public long longValue(); public float floatValue(); public double doubleValue();} AtomicReferenceAtomicReference的使用也基本同上，只是操作的目标是对象，而非原始数据类型，底层使用的是unsafe提供的关于对象相关的操作如：compareAndSwapObject、getAndSetObject等 方法签名如下 1234567891011public class AtomicReference&lt;V&gt; { public AtomicReference(V); public AtomicReference(); public final V get(); public final void set(V); public final void lazySet(V); public final boolean compareAndSet(V, V); public final boolean weakCompareAndSet(V, V); public final V getAndSet(V); public String toString();} AtomicIntegerArrayatomic包中，除了提供对于对象(原始类型，Object类型)相关的操作外，还对数组(特殊对象)提供相关的操作，当然，还是借助unsafe包中提供的工具的支持 数组，实际上就是一大块连续的内存区域，存储着相同数据类型的数据，所以，对数组的操作，实际上就是对这一块区域内存中某个部分进行操作，了解过c或者c++的同学应该比较清楚这一点，通过基址地址(数组头)+偏移即可操作数据中的每个元素 下面详细分析下AtomicIntegerArray的具体实现 属性 12345678910// 对应的unsafe操作private static final Unsafe unsafe = Unsafe.getUnsafe();// 获取基于数据的类中数据的第一个元素地址// 注意，这里不是获取某个数组对象的地址，是获取数组数据在对象中的相对位置// 如，int数组中的数据是在偏移量16(win,jdk64)开始，这个跟哪个数据对象是无关的private static final int base = unsafe.arrayBaseOffset(int[].class);// 元素大小的位数private static final int shift;// 实际的元素所存储的位置，注意是final类型private final int[] array; 初始化 123456789static { // 获取每个元素的大小，如int[] 为4 int scale = unsafe.arrayIndexScale(int[].class); // 检查元素大小是否是2的倍数，不是则报错 if ((scale &amp; (scale - 1)) != 0) throw new Error(&quot;data type scale not a power of two&quot;); // 31-scale前置的0个数，也就是获取到元素大小所占的位数，如：int[] =&gt; 31 - 29 = 2 shift = 31 - Integer.numberOfLeadingZeros(scale);} 辅助方法 1234567891011121314151617// 检查下标是否合法，由于是直接操作内存，避开了VM的下标检查，所以这一步是必须的private long checkedByteOffset(int i) { if (i &lt; 0 || i &gt;= array.length) throw new IndexOutOfBoundsException(&quot;index &quot; + i); return byteOffset(i);}// 获取该下标对应的地址，base + i * 2^sizeprivate static long byteOffset(int i) { return ((long) i &lt;&lt; shift) + base;}// 直接通过unsafe获取位置的数据private int getRaw(long offset) { return unsafe.getIntVolatile(array, offset);} 构造方法 12345678// final类型保证赋值的时候的可见性，所以这里不存在可见性问题public AtomicIntegerArray(int length) { array = new int[length];}public AtomicIntegerArray(int[] array) { this.array = array.clone();} 操作方法 1234// 获取长度 public final int length() { return array.length; } 1234// 获取某个元素public final int get(int i) { return getRaw(checkedByteOffset(i));} 1234// 设置某个元素public final void set(int i, int newValue) { unsafe.putIntVolatile(array, checkedByteOffset(i), newValue);} 1234// 获取并且返回public final int getAndSet(int i, int newValue) { return unsafe.getAndSetInt(array, checkedByteOffset(i), newValue);} 12345678// 比较并设置public final boolean compareAndSet(int i, int expect, int update) { return compareAndSetRaw(checkedByteOffset(i), expect, update);}private boolean compareAndSetRaw(long offset, int expect, int update) { return unsafe.compareAndSwapInt(array, offset, expect, update);} 其他的方法使用起来大致类似，就不展开了，可以看到，对数组的操作，本质其实也是对某个元素的操作 AtomicLongArrray分析完AtomicIntegerArray之后，AtomicLongArray就不成问题了，这里就不展开了，基本上思路是一样的，只是借助的unsafe方法不同 AtomicReferenceArray同上，只是数据的内容改为Object而已 AtomicXXXFieldUpdater在atomic包中，还存在一种特殊类型的工具，同样对应三种基本类型 AtomicIntegerFieldUpdater AtomicLongFieldUpdater AtomicReferenceFieldUpdater 通过其名称可以看出，这几个工具是用于更新字段的(FieldUpdater) 以下内容来自doc 一个基于反射的工具，用于原子性更新指定类的指定的volatile字段(int、long、reference)的值 从doc中就可以清晰地看出了，这几个工具类用于原子更新某个类的某个字段，这些字段必须是volatile类型的(保证可见性) 之所以需要这几个工具，是有时候我们已经设计好了某个类，或者由于历史原因，无法更改该类的某些字段，在并发环境下操作的时候除了直接加锁外，也可以使用这几个工具来轻化操作的代价 下面以AtomicIntegerFieldUpdater为例进行分析 1public abstract class AtomicIntegerFieldUpdater&lt;T&gt; {} 从类声明可以看到，该类是一个抽象类，并且是泛型的，其中的泛型代表的就是目标类的类型了 核心方法 12345678910111213141516171819// 构造器为protected，仅能继承使用protected AtomicIntegerFieldUpdater();// 工厂方法，参数为：执行类型和所要操作的字段public static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt;, String);// 剩下几个方法都是比较熟悉的了，都是对指定字段的操作而已，同AtomicXXXpublic abstract boolean compareAndSet(T, int, int);public abstract boolean weakCompareAndSet(T, int, int);public abstract void set(T, int);public abstract void lazySet(T, int);public abstract int get(T);public int getAndSet(T, int);public int getAndIncrement(T);public int getAndDecrement(T);public int getAndAdd(T, int);public int incrementAndGet(T);public int decrementAndGet(T);public int addAndGet(T, int); 在AtomicIntegerFiledUpdater中，提供了一个私有内部实现 12private static final class AtomicIntegerFieldUpdaterImpl&lt;T&gt; extends AtomicIntegerFieldUpdater&lt;T&gt; {} 下面着重分析该类 核心字段 12345678910// 本身还是通过unsafe来实现casprivate static final sun.misc.Unsafe U = sun.misc.Unsafe.getUnsafe();// 字段所在的偏移位置private final long offset;private final Class&lt;?&gt; cclass;// 字段所在的类private final Class&lt;T&gt; tclass; 构造器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 参数1：目标类的类型// 参数2：目标字段// 参数3：调用者类型，由于Java体系存在访问控制，所以需要鉴别调用者是否有权限操作该字段AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) { final Field field; final int modifiers; try { // 获取指定类的指定字段 field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() { public Field run() throws NoSuchFieldException { return tclass.getDeclaredField(fieldName); } }); // 确保调用者有权限访问 modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); // 如果类加载器为null，则为Bootstrap classLoader // 如果调用者不是有bootstrap加载，并且两者不是由同一个类加载器加载 // 并且目标类是由bootstrap加载或者两个加载器之间不是父子关系 // 则检查是否具有该包的访问权限 if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) { sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); } // 没有权限访问，直接抛出异常 } catch (PrivilegedActionException pae) { throw new RuntimeException(pae.getException()); // 其他类型异常 } catch (Exception ex) { throw new RuntimeException(ex); } // 目标字段只能是int类型 if (field.getType() != int.class) throw new IllegalArgumentException(&quot;Must be integer type&quot;); // 目标字段只能是volatile类型 if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException(&quot;Must be volatile type&quot;); // 如果是protect类型并且两者存在继承关系，并且不在同一个包 // 则转为子类 this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; tclass.isAssignableFrom(caller) &amp;&amp; !isSamePackage(tclass, caller)) ? caller : tclass; this.tclass = tclass; this.offset = U.objectFieldOffset(field);}// 判断是否是同一个包，直接通过包名private static boolean isSamePackage(Class&lt;?&gt; class1, Class&lt;?&gt; class2) { return class1.getClassLoader() == class2.getClassLoader() &amp;&amp; Objects.equals(getPackageName(class1), getPackageName(class2));}private static String getPackageName(Class&lt;?&gt; cls) { String cn = cls.getName(); int dot = cn.lastIndexOf('.'); return (dot != -1) ? cn.substring(0, dot) : &quot;&quot;;} 核心操作（仅分析其中一个，其他的类似啦） 123456789101112131415161718192021222324public final boolean compareAndSet(T obj, int expect, int update) { accessCheck(obj); return U.compareAndSwapInt(obj, offset, expect, update);}private final void accessCheck(T obj) { // 检查obj是否是传入的目标类的实例 if (!cclass.isInstance(obj)) throwAccessCheckException(obj);}private final void throwAccessCheckException(T obj) { if (cclass == tclass) throw new ClassCastException(); else throw new RuntimeException( new IllegalAccessException( &quot;Class &quot; + cclass.getName() + &quot; can not access a protected member of class &quot; + tclass.getName() + &quot; using an instance of &quot; + obj.getClass().getName()));} 至此可以看到，AtomicXXXFieldUpdater同样也是通过CAS来更新指定字段，只是多做了一些访问的限制，检查 AtomicLongFiledUpdater和AtomicReferenceFieldUpdater基本也类似，就不展开了 在使用该工具的时候，需要注意 调用者必须要有权限访问目标类的字段，如目标类的字段为private时，是不可访问的 字段必须是volatile类型的 字段必须是实例类型，不能是static修饰 字段不能是final类型 AtomicStampedReference在CAS的应用过程中，人们发现其存在一个问题，称之为ABA问题，示例如下 线程1，执行CAS(A,B)，然后执行CAS(B,A) 线程2，执行CAS(A,B)，此时CAS依旧成功，但是A已经不再是之前的A(虽然数值是一样的) 一般会通过版本号之类的机制来解决ABA问题，每次操作记录更新版本号，比较的时候带上版本号进行比较 在JDK中提供了AtomicStampedReference来处理这种情况 1public class AtomicStampedReference&lt;V&gt; {} 下面详细分析 核心字段 12345678910111213private volatile Pair&lt;V&gt; pair;private static class Pair&lt;T&gt; { final T reference; final int stamp; private Pair(T reference, int stamp) { this.reference = reference; this.stamp = stamp; } static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) { return new Pair&lt;T&gt;(reference, stamp); }} 可以看到，AtomicStampedReference中维护了一个pair属性，该属性是Pair的一个实例，Pair的定义也非常简单，就是一个引用加一个版本号 构造器 1234// 使用提供的引用及版本号来初始化pairpublic AtomicStampedReference(V initialRef, int initialStamp) { pair = Pair.of(initialRef, initialStamp);} 核心方法 1234567891011121314public V getReference() { return pair.reference;}public int getStamp() { return pair.stamp;}public V get(int[] stampHolder) { Pair&lt;V&gt; pair = this.pair; // 版本号存放在stampHolder[0] stampHolder[0] = pair.stamp; return pair.reference;} 1234567891011121314151617181920// cas，参数多了版本号信息public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) { Pair&lt;V&gt; current = pair; return // 比较引用值及版本号 expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; // 新值与当前值一样，或者更新成功 ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp)));}// 直接通过unsafe进行更新private boolean casPair(Pair&lt;V&gt; cmp, Pair&lt;V&gt; val) { return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val);} 123456//set public void set(V newReference, int newStamp) { Pair&lt;V&gt; current = pair; if (newReference != current.reference || newStamp != current.stamp) this.pair = Pair.of(newReference, newStamp);} 12345678// just update stamppublic boolean attemptStamp(V expectedReference, int newStamp) { Pair&lt;V&gt; current = pair; return expectedReference == current.reference &amp;&amp; (newStamp == current.stamp || casPair(current, Pair.of(expectedReference, newStamp)));} AtomicStampedReference提供的方法总体上比其他的少得多，常用的也就是compareAndSet了，通过代码的分析，也可以看到，其实就是在操作之前先比较一下引用的数据以及版本号，如果与预期一致，则采用CAS进行更新 AtomicMarkableReference前面提到了AtomicStrampedReference，从代码中可以看到，使用的是一个int作为版本号，而AtomicMarkableReference则可以视为其简化版本，使用的是boolean作为标记号 123456789101112private static class Pair&lt;T&gt; { final T reference; // 注意这里 final boolean mark; private Pair(T reference, boolean mark) { this.reference = reference; this.mark = mark; } static &lt;T&gt; Pair&lt;T&gt; of(T reference, boolean mark) { return new Pair&lt;T&gt;(reference, mark); }} 其他的基本一样，这里就不展开了 总结到此为止，基本上Atomic包中常用的工具我们都一一分析完毕，从分析的过程可以看出，Atomic包中的工具大致可以分为以下几类 AtomicXXX，直接对某个对象进行操作 AtomicInteger AtomicBoolean AtomicLong AtomicReference AtomicXXArray，对数组进行操作 AtomicIntegerArray AtomicLongArray AtomicReferenceArray AtomicXXXUpdater，针对对象中的某个字段 AtomicIntegerFieldUpdater AtomicLongFieldUpdater AtomicReferenceUpdater AtomicXXXReference，提供带版本号的支持 AtomicStampedReference AtomicMarkableReference 虽然看起来工具非常多，但是经过分类之后，其用途也就非常明显了，经过分析，我们也能更好地掌握和使用该工具了","link":"/2019/10/06/AtomicXXX%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%88%86%E6%9E%90/"},{"title":"Elasticsearch Bulk API学习笔记","text":"ES Bulk API在操作ES的过程中，有很多的情况下是需要同时往ES插入很多数据，这个时候有两种方式 第一种是通过ES的单个操作数据接口循环操作数据，这种操作方式会当请求次数多的时候，会有很明显的缺点，请求次数多，容易影响性能；单次插入数据的有效负载低(一个http请求的body携带的实际有效内容)，因此在数据规模比较大的时候，更倾向于使用第二种方式 第二种是通过ES的bulk接口，顾名思义，这个接口是用于批量操作数据的，这个接口本身支持同时使用多种类型的action(插入、删除、更改等)，然后一次提交批量的操作给ES，从而提高网络的有效负载，也一定程度上降低ES的请求数量 Bulk APIES的bulk操作是通过_bulk这个endpoint来实现的，方式是POST，一次bulk操作可以同时进行不同的操作，语法如下： 12345678POST /INDEX/_bulk{ &quot;index&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;1&quot; } }{ &quot;field1&quot; : &quot;value1&quot; }{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;2&quot; } }{ &quot;create&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;3&quot; } }{ &quot;field1&quot; : &quot;value3&quot; }{ &quot;update&quot; : {&quot;_id&quot; : &quot;1&quot;, &quot;_index&quot; : &quot;test&quot;} }{ &quot;doc&quot; : {&quot;field2&quot; : &quot;value2&quot;} } 每个操作本身是通过JSON来描述的，操作之间通过\\n进行分隔，其中的create、index两个操作均包含一个body，这个body本身也是一个JSON，并且通过\\n分隔，紧跟在操作描述之后，如果index操作指定了_index，则POST的时候，可以不用指定INDEX 注：如果是7.0以下的版本还需要指定_type:XX index示例： 12345POST /test-20201228/_bulk{&quot;index&quot;: {&quot;_id&quot;: &quot;123&quot;, &quot;_type&quot; : &quot;_doc&quot;}}{&quot;name&quot;: &quot;xaiver&quot;, &quot;age&quot;: 25}{&quot;index&quot;: {&quot;_id&quot;: &quot;124&quot;, &quot;_type&quot;: &quot;_doc&quot;}}{&quot;name&quot;: &quot;sharon&quot;, &quot;age&quot;: 24} 其他的根据语法进行操作即可 Bulk Java APIJava 的bulk本质上是对_bulk的封装而已，直接参考下官方的文档即可，简单的示例如下 123456789101112131415161718192021222324public class BulkTest { public static void main(String[] args) { RestHighLevelClient restClient = EsClient.getRestClient(); BulkRequest bulkRequest = new BulkRequest(); bulkRequest.add(new IndexRequest(&quot;test-20201228&quot;, &quot;_doc&quot;) .source(XContentType.JSON, &quot;name&quot;, &quot;jack&quot;, &quot;age&quot;, 35)); bulkRequest.add(new IndexRequest(&quot;test-20201228&quot;, &quot;_doc&quot;) .source(XContentType.JSON, &quot;name&quot;, &quot;tony&quot;, &quot;age&quot;, 50)); try { BulkResponse bulkResponse = restClient.bulk(bulkRequest, RequestOptions.DEFAULT); if (bulkResponse.hasFailures()) { for (BulkItemResponse bulkItemResponse : bulkResponse) { if (bulkItemResponse.isFailed()) { System.out.println(&quot;error....&quot;); } } } } catch (IOException e) { e.printStackTrace(); } }} BulkProcessor在普通的场景中，通过bulk或其对应封装的API来实现即可，然而，在一些特定场景中，单纯使用bulk却无法实现，比如说，我们想文档数量达到某一个阈值，或者文档大小达到某一个阈值就提交，避免某一个批次的数据量太大，造成ES处理缓慢，或者当没有达到上面的情况时，根据某个固定的频率提交，避免长时间没有数据提交从而造成活锁的情况 BulkProcessor使用根据上面的需求，我们是可以轻松通过实现的，不过，这次这个轮子ES的Java客户端已经造好了，使用方式如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public static void main(String[] args) { RestHighLevelClient restClient = EsClient.getRestClient(); BulkProcessor.Listener listener = new BulkProcessor.Listener() { // 提交之前回调 @Override public void beforeBulk(long executionId, BulkRequest request) { System.out.println(&quot;executionId: &quot; + executionId); System.out.println(&quot;before bulk, bulk size: &quot; + request.numberOfActions()); } // 提交之后回调，用于检查成功的、失败的数据 @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) { System.out.println(&quot;after bulk, executionId: &quot; + executionId); List&lt;DocWriteRequest&lt;?&gt;&gt; totalRequest = request.requests(); List&lt;DocWriteRequest&lt;?&gt;&gt; retryList = new ArrayList&lt;&gt;(); for (BulkItemResponse bulkItem : response.getItems()) { if (!bulkItem.isFailed()) { continue; } // 这里根据具体的业务逻辑来判断是否进行重试操作，其他的逻辑根据情况补充即可 RestStatus failStatus = bulkItem.getFailure().getStatus(); switch (failStatus) { case TOO_MANY_REQUESTS: case SERVICE_UNAVAILABLE: // 重试... retryList.add(totalRequest.get(bulkItem.getItemId())); break; default: break; } } } // 这里是失败，注意与前面的区别 @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) { System.out.println(&quot;失败：&quot; + failure.getMessage()); } }; BulkProcessor bulkProcessor = BulkProcessor .builder(((req, bulkResponseActionListener) -&gt; restClient.bulkAsync(req, RequestOptions.DEFAULT, bulkResponseActionListener)), listener) // 1000个action提交一次 .setBulkActions(1000) // 1MB提交一次 .setBulkSize(new ByteSizeValue(1, ByteSizeUnit.MB)) // 10s提交一次 .setFlushInterval(TimeValue.timeValueSeconds(10)) // 并发度 .setConcurrentRequests(2) .build();}// 现在只需要将数据塞进来就行了，当到达阈值的时候，会自动进行提交public void addEvent(BulkProcessor bulkProcessor, IndexRequest request) { bulkProcessor.add(request);} 可以看到，通过官方提供的API，我们只需要配置一个BulkProcessor.Listener，用于在提交前后获得通知，对应的重试逻辑，以及配置好触发提交的阈值即可，剩下的就只需要添加数据就行，当达到阈值的时候，会自动触发提交 BulkProcessor实现大致了解了其使用方式后，接下来看下其实现逻辑，做到知其然知其所以然 BulkProcessor.Listener接口就不分析了，其实就是前面提到的三个回调方法而已 BuilderBulkProcessor通过Builder模式来提供更加便捷的参数配置模式 BulkProcessor暴露了两个用于创建builder的方法： 12345678910111213141516171819public static Builder builder(Client client, Listener listener) { Objects.requireNonNull(client, &quot;client&quot;); Objects.requireNonNull(listener, &quot;listener&quot;); return new Builder(client::bulk, listener, client.threadPool(), () -&gt; {}); }// 我们重点分析这个方法，两者的原理是一样的public static Builder builder(BiConsumer&lt;BulkRequest, ActionListener&lt;BulkResponse&gt;&gt; consumer, Listener listener) { Objects.requireNonNull(consumer, &quot;consumer&quot;); Objects.requireNonNull(listener, &quot;listener&quot;); // 初始化调度器，底层是通过ScheduledThreadPoolExecutor来提供定时调度的能力 final ScheduledThreadPoolExecutor scheduledThreadPoolExecutor = Scheduler.initScheduler(Settings.EMPTY); // 返回Builder实例 return new Builder(consumer, listener, buildScheduler(scheduledThreadPoolExecutor), () -&gt; Scheduler.terminate(scheduledThreadPoolExecutor, 10, TimeUnit.SECONDS));} Builder有好几个参数前面已经看过了，接下来完整得看下其他的参数信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static class Builder { // 消费者，其实就是提交者，这里感觉用“生产者”感觉更加合适一些 private final BiConsumer&lt;BulkRequest, ActionListener&lt;BulkResponse&gt;&gt; consumer; // 监听器 private final Listener listener; // 调度器，核心在这里 private final Scheduler scheduler; // 关闭钩子 private final Runnable onClose; // 并发度，默认是1 private int concurrentRequests = 1; // action的数量，默认是1000 private int bulkActions = 1000; // 数据大小，默认是5MB private ByteSizeValue bulkSize = new ByteSizeValue(5, ByteSizeUnit.MB); // 定时提交的时间间隔 private TimeValue flushInterval = null; // 回退策略 private BackoffPolicy backoffPolicy = BackoffPolicy.exponentialBackoff(); // 索引 private String globalIndex; // 文档类型 private String globalType; // 路由 private String globalRouting; // 流水线 private String globalPipeline; private Builder(BiConsumer&lt;BulkRequest, ActionListener&lt;BulkResponse&gt;&gt; consumer, Listener listener, Scheduler scheduler, Runnable onClose) { this.consumer = consumer; this.listener = listener; this.scheduler = scheduler; this.onClose = onClose; } // 省略一大堆的builder方法 public BulkProcessor build() { // 调用BulkProcessor的构造方法进行初始化 return new BulkProcessor(consumer, backoffPolicy, listener, concurrentRequests, bulkActions,bulkSize, flushInterval, scheduler, onClose, createBulkRequestWithGlobalDefaults()); } private Supplier&lt;BulkRequest&gt; createBulkRequestWithGlobalDefaults() { return () -&gt; new BulkRequest(globalIndex, globalType) .pipeline(globalPipeline) .routing(globalRouting); }} BulkProcessor初始化123456789101112131415161718192021222324BulkProcessor(BiConsumer&lt;BulkRequest, ActionListener&lt;BulkResponse&gt;&gt; consumer, BackoffPolicy backoffPolicy, Listener listener, int concurrentRequests, int bulkActions, ByteSizeValue bulkSize, @Nullable TimeValue flushInterval, Scheduler scheduler, Runnable onClose, Supplier&lt;BulkRequest&gt; bulkRequestSupplier) { this.bulkActions = bulkActions; this.bulkSize = bulkSize.getBytes(); this.scheduler = scheduler; // 获取需要提交的内容 this.bulkRequest = bulkRequestSupplier.get(); this.bulkRequestSupplier = bulkRequestSupplier; // 注意这个，逻辑的处理核心就在这个类中 this.bulkRequestHandler = new BulkRequestHandler(consumer, backoffPolicy, listener, scheduler, concurrentRequests); // 定时提交策略的实现 this.cancellableFlushTask = startFlushTask(flushInterval, scheduler); this.onClose = onClose;} 添加数据BulkProcessor提供了很多个重载的add方法，不过最终都会调用internalAdd这个方法，重点看下这个方法即可 12345678// 注意这里是加了锁private synchronized void internalAdd(DocWriteRequest request, @Nullable Object payload) { ensureOpen(); // 添加 bulkRequest.add(request, payload); // 检查是否需要提交 executeIfNeeded();} executeIfNeeded 1234567private void executeIfNeeded() { ensureOpen(); if (!isOverTheLimit()) { return; } execute();} isOverTheLimit 1234567891011private boolean isOverTheLimit() { // 数量满足 if (bulkActions != -1 &amp;&amp; bulkRequest.numberOfActions() &gt;= bulkActions) { return true; } // 大小满足 if (bulkSize != -1 &amp;&amp; bulkRequest.estimatedSizeInBytes() &gt;= bulkSize) { return true; } return false;} execute 123456789private void execute() { final BulkRequest bulkRequest = this.bulkRequest; // 当前的id，其实就是一个单调递增的数值 final long executionId = executionIdGen.incrementAndGet(); this.bulkRequest = bulkRequestSupplier.get(); // 委托给bulkRequestHandler来执行 this.bulkRequestHandler.execute(bulkRequest, executionId);} 提交数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public void execute(BulkRequest bulkRequest, long executionId) { Runnable toRelease = () -&gt; {}; boolean bulkRequestSetupSuccessful = false; try { // 还记着这哥们吗，提交前的回调 listener.beforeBulk(executionId, bulkRequest); // 允许同时执行的并发度，这里通过信号量来实现 semaphore.acquire(); toRelease = semaphore::release; // 初始化栅栏，用于等待执行完成 CountDownLatch latch = new CountDownLatch(1); // 这里委托给retry进行真正的提交操作 retry.withBackoff(consumer, bulkRequest, new ActionListener&lt;BulkResponse&gt;() { @Override public void onResponse(BulkResponse response) { try { // 回调 listener.afterBulk(executionId, bulkRequest, response); } finally { semaphore.release(); latch.countDown(); } } @Override public void onFailure(Exception e) { try { // 回调 listener.afterBulk(executionId, bulkRequest, e); } finally { semaphore.release(); latch.countDown(); } } }); bulkRequestSetupSuccessful = true; if (concurrentRequests == 0) { latch.await(); } } catch (InterruptedException e) { // 异常处理 } finally { if (bulkRequestSetupSuccessful == false) { toRelease.run(); } }} Retry#RetryHandler#execute 12345public void execute(BulkRequest bulkRequest) { this.currentBulkRequest = bulkRequest; // 这里的consumer就是前面构造BulkProcessor传递一个lambda，示例中使用的是BulkAsync consumer.accept(bulkRequest, this);} 这里看起来只有短短两行代码，但是却很巧妙，经过层层包装之后，最终其实是使用外部传递进来的处理器，这样子的好处在于，调用方可以根据实际的情况来提交数据，而具体的其余的阈值判断等操作则是由BulkProcessor来执行，函数式编程的一个很巧妙的方式 到这里的话，我们就已经知道了，当达到数量阈值或者大小阈值的时候，触发的提交处理逻辑，其实是采用了延迟触发的方式，只有在添加数据的时候，才去检查是否满足阈值条件。当然，如果单纯通过这种方式来触发提交，就会出现有数据，但是不满足阈值，从而导致要很长的一段时间之内数据才会触发提交甚至不触发提交的情况发生，此时就需要通过另外的阈值–时间，来保障最低频次的提交 定时提交前面在看BulkProcessor的代码的时候，我们提到了这一行this.cancellableFlushTask = startFlushTask(flushInterval, scheduler);，这个就是定时提交的核心了 startFlushTask 12345678910111213141516171819202122private Scheduler.Cancellable startFlushTask(TimeValue flushInterval, Scheduler scheduler) { // 如果flushInterval为空，则表示不设置该任务 if (flushInterval == null) { return new Scheduler.Cancellable() { @Override public boolean cancel() { return false; } @Override public boolean isCancelled() { return true; } }; } final Runnable flushRunnable = scheduler.preserveContext(new Flush()); // 固定延迟调度，底层还是使用ScheduledThreadPoolExecutor return scheduler.scheduleWithFixedDelay(flushRunnable, flushInterval, ThreadPool.Names.GENERIC);} Flush 1234567891011121314151617class Flush implements Runnable { @Override public void run() { // 这里锁住了，所以如果定时提交数据的是时候，有人调用add，add会阻塞住 synchronized (BulkProcessor.this) { if (closed) { return; } if (bulkRequest.numberOfActions() == 0) { return; } // 还是回到了execute方法 execute(); } }} 到了这里，关于BulkProcessor的魔力我们就清楚了，通过设置数量阈值和大小阈值，当add时候会检查是否已经满足提交条件，如果满足，则会触发提交，同时，固定间隔时间之内也会触发提交，从而保障至少在指定的时间间隔之内，数据会被提交一次，当然，两个任务之间可能会同时提交，因此通过synchronized来进行同步保障","link":"/2020/12/28/Elasticsearch-Bulk-API%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Redis分布式锁使用总结","text":"这篇文章主要是对Redis分布式锁进行一个细致的分析，包括Redis分布式锁的核心原理，使用时需要注意的事项，Spring对Redis分布式锁的支持等 Redis分布式锁使用总结前言最近因为项目需要进行多实例的协调，使用到了分布式锁，所以对分布式锁的原理、使用等做了一番调查、学习，顺便将其记录下来，供需要的同学学习交流。 项目中使用的是基于Redis的分布式锁，所以这篇文件的内容都是是基于Redis分布式锁。 分布式锁简介谈起编程语言中的锁，开发者应该是相当熟悉的，当系统中存在多线程并且多线程之间存在竞态条件或者需要协作的时候，我们就会使用到锁，如Java中的Lock、Synchronized等，但是编程语言中提供的锁，基本上都只适用于在同一个机器上运行的情况，在分布式环境下并不适用。 而在某些情况下，我们是需要在多个机器实例/节点之间进行协作的，这个时候，就需要使用到分布式锁了。 顾名思义，分布式锁就是应用于在分布式环境下多个节点之间进行同步或者协作的锁 分布式锁同普通的锁一样，具有以下几个重要特性 互斥性，保证只有持有锁的实例中的某个线程才能进行操作 可重入性，同一个实例的同一个线程可以多次获取锁 锁超时，支持超时自动释放锁，避免死锁的产生 谁加的锁只能由谁释放 Redis分布式锁原理由于Redis的命令本身是原子性的，所以，非常适合于作为分布式锁的协调者。 一般情况下，为了保证锁的释放只能由加锁者或者超时释放，一般我们会将对应键的值设置为一个线程唯一标志，如为每个线程生成一个UUID，只有当线程的UUID与锁的值一致时，才能释放锁。 利用Redis来实现分布式的原理非常简单，加锁的时候为某个键设置值，释放的时候将对应的键删除即可。 不过在使用的时候，有一些需要注意的地方，下面我们详细看下基于Redis不同命令来实现分布式锁的操作 setnx命令在Redis2.6之前，常用于分布式锁的命令是：setnx key val，该命令在对应的键没有值的时候设置成功，存在值的时候设置失败，保证了同时只会有一个连接者设置成功，也即保证同时只会有一个实例的一个线程获取成功。 但是该命令存在一个缺陷，不支持超时机制，所以需要额外的命令来保证能够在超时的情况下释放锁，也就是删除键，可以配合expire命令来实现。 由于上述操作涉及到两个命令，所以最好的方式是通过lua脚本来实现加锁的操作，如下所示 123456# KEYS[1]是锁的名称，KEYS[2]是锁的值，KEYS[3]是锁的超时时间local c = redis.call('setnx', KEYS[1], KEYS[2])if(c == 1) then redis.call('expire', KEYS[1], KEYS[3])endreturn c 释放锁的时候，需要验证释放锁的是不是锁的持有者，具体代码如下 12345# KEYS[1]是锁的名称，KEYS[2]是锁的值if redis.call('get', KEYS[1]) == KEYS[2] then return redis.call('del', KEYS[1]) else return 0 end set命令从上面的setnx命令可以看到，加锁的操作还是比较麻烦的，所以，在Redis2.6之后，redis的set命令进行了增强，设置值的时候，同时支持设置过期时间 12# nx表示不存在的时候设置，ex表示设置过期时间，单位是秒set LOCK VAL nx ex 15 可以看到，通过该命令，进行加锁就方便很多了 释放锁的操作同setnx里提到的释放操作 Redis分布式锁实现上面我们提到的是Redis分布式锁的实现原理，不过，每次需要用到锁的时候都需要自己手动实现一次，虽然代码本身没有多少，其实也不是很方便。 正因为如此，有挺多的项目都实现了分布式，并且提供了更加丰富的功能，如下面讨论到的RedisLockRegistry RedisLockRegistrySpring-integration项目是Spring官方提供了集成各种工具的项目，通过integration-redis子项目，提供了非常丰富的功能，关于该项目，后面有时间再写篇文章具体分析一下，这里我们用到其中的一个组件RedisLockRegistry 导入依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-integration&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt; &lt;artifactId&gt;spring-integration-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置RedisLockRegistry 12345678910@Configurationpublic class RedisLockConfiguration { @Bean public RedisLockRegistry redisLockRegistry( RedisConnectionFactory redisConnectionFactory) { // 注意这里的时间单位是毫秒 return new RedisLockRegistry(redisConnectionFactory, &quot;registryKey&quot;, TIME); }} RedisLockRegistry相当于一个锁的管理仓库，所有的锁都可以从该仓库获取，所有锁的键名为：registryKey:LOCK_NAME，默认时间为60s 配置完锁的仓库之后，只需要注入仓库，当需要使用到锁的时候，从仓库中获取一个锁就可以了，如下所示 1Lock lock = redisLockRegistry.obtain(&quot;redis-lock&quot;); 该操作返回一个Lock对象，该对象其实是Spring实现的基于Redis的锁，该锁支持了丰富的功能，如tryLock等 但使用的时候，只需要跟普通的锁一样操作即可 12345678910// lock.tryLock(10, TimeUnit.SECONDS);lock.lock();try { // ops }catch(Exception e) { }finally { // 释放锁 lock.unlock();} 可以看到，通过RedisLockRegistry，我们可以更加方便地使用Redis分布式锁了 RedisLockRegistry源码分析上面学习了RedisLockRegistry的使用之后，接下来我们来具体看下RedisLockRegistry的具体实现 从上面的继承结构可以清晰地看出RedisLockRegistry的继承情况，而上面的几个接口基本上都只提供了基本的定义，这里就不展开分析了。直接看RedisLockRegistry的实现 构造函数首先是构造函数，有两个构造函数，如下 12345678910111213141516171819private static final long DEFAULT_EXPIRE_AFTER = 60000L;// 提供了默认的的过期时间，默认过期时间为60spublic RedisLockRegistry(RedisConnectionFactory connectionFactory, String registryKey) { this(connectionFactory, registryKey, DEFAULT_EXPIRE_AFTER);}public RedisLockRegistry(RedisConnectionFactory connectionFactory, String registryKey, long expireAfter) { Assert.notNull(connectionFactory, &quot;'connectionFactory' cannot be null&quot;); Assert.notNull(registryKey, &quot;'registryKey' cannot be null&quot;); this.redisTemplate = new StringRedisTemplate(connectionFactory); this.obtainLockScript = new DefaultRedisScript&lt;&gt;(OBTAIN_LOCK_SCRIPT, Boolean.class); this.registryKey = registryKey; this.expireAfter = expireAfter; this.unlinkAvailable = RedisUtils.isUnlinkAvailable(this.redisTemplate);} 上面第二个构造函数中，有两个没见过的属性，分别是obtainLockScript以及unlinkAvailable，分析如下 obtainLockScript 123private final RedisScript&lt;Boolean&gt; obtainLockScript;obtainLockScript = new DefaultRedisScript&lt;&gt;(OBTAIN_LOCK_SCRIPT, Boolean.class); 可以看到obtainLockScript是一个DefaultRedisScript实例，该实例的对象用于执行Lua脚本，具体的看下DefaultRedisScript的源码 上面的OBTAIN_LOCK_SCRIPT内容如下 12345678910private static final String OBTAIN_LOCK_SCRIPT =truetruetrue&quot;local lockClientId = redis.call('GET', KEYS[1])\\n&quot; +truetruetruetrue&quot;if lockClientId == ARGV[1] then\\n&quot; +truetruetruetruetrue&quot; redis.call('PEXPIRE', KEYS[1], ARGV[2])\\n&quot; +truetruetruetruetrue&quot; return true\\n&quot; +truetruetruetruetrue&quot;elseif not lockClientId then\\n&quot; + &quot; redis.call('SET', KEYS[1], ARGV[1], 'PX', ARGV[2])\\n&quot; +truetruetruetruetrue&quot; return true\\n&quot; +truetruetruetruetrue&quot;end\\n&quot; +truetruetruetruetrue&quot;return false&quot;; 可以看到，其实就是一段简单的Lua脚本，脚本逻辑如下 调用get命令获取对应的key，如果存在在走2，不存在，则走3 判断key的值是否是入参，如果是，则调用pexire设置过期时间，返回true表示加锁成功 如果不存在，则调用set命令进行加锁，并且设置过期时间，返回true表示加锁成功，从命令中可以看到，使用的参是px，所以构造函数传入的单位是毫秒而不是秒 如果没有执行2、3操作，则返回false，表示加锁失败 isUnlinkAvailable 该函数检查对应的redis是否支持UNLINK命令，该命令用于异步删除某个键，功能等同于del命令，但非阻塞，只有在redis4及以上版本才支持 函数内容如下： 123456789101112131415161718192021public static boolean isUnlinkAvailable(RedisOperations&lt;?, ?&gt; redisOperations) { return unlinkAvailable.computeIfAbsent(truetrueredisOperations, key -&gt; {truetruetrueProperties info = redisOperations.execute(truetruetruetruetrue(RedisCallback&lt;Properties&gt;) connection -&gt; truetruetruetruetrueconnection.serverCommands().info(SECTION));truetruetrueif (info != null) {truetruetruetrueString version = info.getProperty(VERSION_PROPERTY);truetruetruetrueif (StringUtils.hasText(version)) {truetruetruetruetrueint majorVersion = Integer.parseInt(version.split(&quot;\\\\.&quot;)[0]);truetruetruetruetruereturn majorVersion &gt;= 4;truetruetruetrue}truetruetruetrueelse {truetruetruetruetruereturn false;truetruetruetrue}truetruetrue}truetruetrueelse {truetruetruetruethrow new IllegalStateException(&quot;The INFO command cannot be used in pipeline/transaction.&quot;);truetruetrue}truetrue});true} 核心RedisLockRegistry的核心方法其实只有一个，就是obtainLock，具体实现如下 12345678private final Map&lt;String, RedisLock&gt; locks = new ConcurrentHashMap&lt;&gt;();@Overridepublic Lock obtain(Object lockKey) { Assert.isInstanceOf(String.class, lockKey); String path = (String) lockKey; return this.locks.computeIfAbsent(path, RedisLock::new);} 可以看到，每一个LockRegistry自己维护了一个LOCK-KEY-LOCK的map，这也表明，同一个Registry中，相同的键只会对应一个Lock对象 RedisLock从上面的分析中可以看到，LockRegistry维护了一个RedisLock对象的Map，键是锁的名称，值是对应的Lock对象，该对象是Spring实现的一个内部类，具体实现如下所示 构造方法123private RedisLock(String path) { this.lockKey = constructLockKey(path);} RedisLock有且只有一个私有构造方法，所以仅能在当前类中进行构造，这也意味着我们无法自己实例化RedisLock实例 构造的过程非常简单，只是初始化了lockKey，lockKey的内容如下 123private String constructLockKey(String path) { return RedisLockRegistry.this.registryKey + &quot;:&quot; + path;} 可以看到，lockKey的值其实就是Registry的名称 + : + 锁的名称 核心方法对于一把锁而言，最最核心的方法莫过于加锁和解锁了，RedisLock实现了Lock接口，提供了多样的加锁方式，分别如下所示 不可中断锁123456789101112131415161718192021private final ReentrantLock localLock = new ReentrantLock();@Overridepublic void lock() { this.localLock.lock(); while (true) { try { while (!obtainLock()) { Thread.sleep(100); //NOSONAR } break; } catch (InterruptedException e) { // 不可中断，所以忽略中断异常 } catch (Exception e) { this.localLock.unlock(); rethrowAsLockException(e); } }} 从上面的代码可以看到，lock方法首先尝试获取ReentrantLock，如果获取成功，才尝试去获取分布式锁，获取localLock的目的在于，如果本地有多个线程在竞争该锁，则只有获取到本地的锁的线程才能尝试去获取分布式锁，好处在于，减少了不必要的网络开销，提高性能 由于lock方法明确规定，如果获取不到锁，则进行阻塞，直至获取到锁或者出现异常，所以上面每隔100毫秒会去尝试获取锁，直到获取成功或者抛出异常为止 获取锁的代码也非常简单，如下所示 1234567891011121314151617181920212223// 实例化Registry的时候进行初始化private final String clientId = UUID.randomUUID().toString();private boolean obtainLock() { Boolean success = RedisLockRegistry.this.redisTemplate.execute( // 获取锁的lua脚本 RedisLockRegistry.this.obtainLockScript, // 获取的锁名称 Collections.singletonList(this.lockKey), // 锁的内容 RedisLockRegistry.this.clientId, // 锁的过期时间 String.valueOf(RedisLockRegistry.this.expireAfter)); boolean result = Boolean.TRUE.equals(success);true // 如果获取成功，则记录锁的时间 if (result) { this.lockedAt = System.currentTimeMillis(); } return result;} 从上面获取锁的代码可以看到，每一个LockRegistry实例只会有一个值，该值在Registry实例化的时候通过UUID生成，一个实例内的多个线程之间的竞争直接通过ReentrantLock进行，不涉及到Redis相关的操作。 可中断锁12345678910111213141516171819@Overridepublic void lockInterruptibly() throws InterruptedException { this.localLock.lockInterruptibly(); try { while (!obtainLock()) { Thread.sleep(100); //NOSONAR } } catch (InterruptedException ie) { // 释放锁，并且响应中断信号 this.localLock.unlock(); Thread.currentThread().interrupt(); throw ie; } catch (Exception e) { this.localLock.unlock(); rethrowAsLockException(e); }} 看懂了lock的代码，再来看lockInterruptibly就非常简单了，lock不响应中断信号，则lockInterruptibly则相应中断信号，因此，获取锁的过程如果出现中断，则结束获取操作了 尝试获取锁尝试获取锁以为着如果能获取锁，则获取，如果不能获取，则结束，当然，可以附带等待是时间，有两个版本的tryLock，如下 123456789101112131415161718192021222324252627282930313233343536373839404142@Overridepublic boolean tryLock() { try { // 调用另一个tryLock，并且将时间设置为0 return tryLock(0, TimeUnit.MILLISECONDS); } catch (InterruptedException e) { Thread.currentThread().interrupt(); return false; }}@Overridepublic boolean tryLock(long time, TimeUnit unit) throws InterruptedException { long now = System.currentTimeMillis(); // 先尝试获取本地锁，如果在指定时间内无法获取到本地锁，则放弃 if (!this.localLock.tryLock(time, unit)) { return false; } try { // 记录获取锁到期时间 long expire = now + TimeUnit.MILLISECONDS.convert(time, unit); boolean acquired; // 如果获取不到锁，并且时间还有剩余，则先休眠100毫秒，然后继续尝试获取 while (!(acquired = obtainLock()) &amp;&amp; System.currentTimeMillis() &lt; expire) { Thread.sleep(100); //NOSONAR } // 到这里表示获取锁超时 // 如果无法获取到分布式锁，则释放本地锁 if (!acquired) { this.localLock.unlock(); } return acquired; } catch (Exception e) { this.localLock.unlock(); rethrowAsLockException(e); } return false;} 具体的分析都详细写在注释里了，补充一点就是，从tryLock的实现中可以看到，tryLock本身是响应中断的，与接口的定义一致 释放锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 判断锁的所有者是否是当前实例public boolean isAcquiredInThisProcess() { return RedisLockRegistry.this.clientId.equals( RedisLockRegistry.this.redisTemplate.boundValueOps(this.lockKey).get());}// 删除对应的键，也即释放分布式锁private void removeLockKey() { if (this.unlinkAvailable) { RedisLockRegistry.this.redisTemplate.unlink(this.lockKey); } else { RedisLockRegistry.this.redisTemplate.delete(this.lockKey); }}@Overridepublic void unlock() { // 如果尝试释放的不是本线程加的锁，则抛出异常 if (!this.localLock.isHeldByCurrentThread()) { throw new IllegalStateException(&quot;You do not own lock at &quot; + this.lockKey); } // 当前线程持有的锁的数量，即重入的次数 // 如果此时 &gt; 1，表示当前线程有多次获取锁，释放的时候只减少本地锁的次数 // 此时其他的方法还持有锁，不能释放分布式锁 if (this.localLock.getHoldCount() &gt; 1) { this.localLock.unlock(); return; } try { // 此时分布式锁已经由于超时被释放了，抛出异常 if (!isAcquiredInThisProcess()) { throw new IllegalStateException(&quot;Lock was released in the store due to expiration. &quot; + &quot;The integrity of data protected by this lock may have been compromised.&quot;); }truetrue // 如果收到中断信号，则异步释放锁 // 尽快响应中断... if (Thread.currentThread().isInterrupted()) { RedisLockRegistry.this.executor.execute(this::removeLockKey); } else { removeLockKey(); } if (logger.isDebugEnabled()) { logger.debug(&quot;Released lock; &quot; + this); } } catch (Exception e) { ReflectionUtils.rethrowRuntimeException(e); } finally { this.localLock.unlock(); }} 总结本文主要简单介绍了分布式锁，在Redis中使用分布式锁的原理，本质就是set或者setnx命令的使用，以及对应版本的加锁以及解锁操作。 最后分析了RedisLockRegistry的具体实现，RedisLockRegistry是Spring提供的基于Redis的分布式锁的实现，主要包含两部分，一部分是本地锁，用于一个实例下多个线程的协调，只有获取到本地锁的线程才去尝试获取分布式锁，通过这种方式来提高获取锁的性能","link":"/2019/10/19/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"title":"浅谈SPI机制.md","text":"文章主要分析的Java中的SPI机制，SPI机制是一个基于约定的形式来加载对应的信息，实现者只需要按照约定，将对应的信息保存在指定文件中，应用启动之后就会自行去读取、发现，通过这种方式了提高了应用的可扩展性 浅谈SPI机制SPISPI全称是Service Provider Interface，翻译过来是服务提供者接口，这个翻译其实不那么形象，理解起来也不是很好理解，至少不那么见名知意。 其实SPI是一种机制，一种类似于服务发现的机制，什么叫做服务发现呢，就是能够根据情况发现已有服务的机制，好像说了跟没说一样，对吧，下面我们逐个来理解。 首先是服务，英文叫做Service，服务可以理解为就是某一种或者某几种功能，比如日常生活中的医生，提供看病的服务；家政公司，提供家政服务；房产中介公司，提供，这样子的话，关于服务，应该是理清楚了。 接下来是服务的发现，英文是Service Discovery，理解了服务，那么服务的发现就应该很好理解了，用大白话讲就是具有某种能力，可以发现某些服务，比如生活中的房产中介公司(服务发现)，他们就能够发现很多的拥有空闲房子并且愿意出租的人(服务)。 SPI机制的作用就是服务发现，也就是说，我们有一些服务，然后通过SPI机制，就能让这些服务被需要的人所使用，而我们这些服务被发现的过程就是SPI的任务了。 说到这里，可能你还是不太理解SPI是什么，接下来我们通过具体的例子分析来理解SPI。 在JDBC4.0之前，我们使用JDBC去连接数据库的时候，通常会经过如下的步骤 将对应数据库的驱动加到类路径中 通过Class.forName()注册所要使用的驱动，如Class.forName(com.mysql.jdbc.Driver) 使用驱动管理器DriverManager来获取连接 后面的内容我们不关心了。 这种方式有个缺点，加载驱动是由用户来操作的，这样就很容易出现加载错驱动或者更换驱动的时候，忘记更改加载的类了。 在JDBC4.0，现在我们使用的时候，上面的第二步就不需要了，并且能够正常使用，这个就是SPI的功劳了。 接下来我们先来看下为什么不需要第二步。 熟悉反射的同学应该知道，第二步其实就是将对应的驱动类加载到虚拟机中，也就是说，现在我们没有手动加载，那么对应的驱动类是如何加载到虚拟机中的呢，我们通过DriverManger的源码的了解SPI是如何实现这个功能的。 DriverManager.java 在DriverManager中，有一段静态代码(静态代码在类被加载的时候就会执行) 12345static { // 在这里加载对应的驱动类 loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);} 接下来我们来具体看下其内容 loadInitialDrivers() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private static void loadInitialDrivers() { String drivers; try { // 先获取系统变量 drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // SPI机制加载驱动类 AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // 通过ServiceLoader.load进行查找，我们的重点也是这里，后面分析 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); // 获取迭代器，也请注意这里 Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try{ // 遍历迭代器 // 这里需要这么做，是因为ServiceLoader默认是延迟加载 // 只是找到对应的class，但是不加载 // 所以这里在调用next的时候，其实就是实例化了对应的对象了 // 请注意这里 -------------------------------------------------------------------- 1 while(driversIterator.hasNext()) { // 真正实例化的逻辑，详见后面分析 driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } // 同时加载系统变量中找到的驱动类 String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); // 由于是系统变量，所以使用系统类加载器，而不是应用类加载器 Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 从上面的代码中并没有找到对应的操作逻辑，唯一的一个突破点就是ServiceLoader.load(Driver.class)方法，该方法其实就是SPI的核心啦 接下来我们来分析这个类的代码(代码可能有点长哦，要有心理准备) ServiceLoader.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;{ /** * 由于是调用ServiceLoader.load(Driver.class)方法，所以我们先从该方法分析 */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { // 获取当前的上下文线程 // 默认情况下是应用类加载器，具体的内容稍后分析 ClassLoader cl = Thread.currentThread().getContextClassLoader(); // 调用带加载器的加载方法 return ServiceLoader.load(service, cl); } /** * 带类加载器的加载方法 */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) { // 只是返回一哥ServiceLoader对象，调用自己的构造函数嘛 return new ServiceLoader&lt;&gt;(service, loader); } /** * 私有构造函数 */ private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) { // 目标加载类不能为null service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); // 获取类加载器，如果cl是null，则使用系统类加载器 loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; // 调用reload方法 reload(); } // 用于缓存加载的服务提供者 private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 真正查找逻辑的实现 private LazyIterator lookupIterator; /** * reload方法 */ public void reload() { // 先清空内容 providers.clear(); // 初始化lookupIterator lookupIterator = new LazyIterator(service, loader); }} LazyIterator.class LazyIterator是ServiceLoader的私有内部类 123456789101112131415private class LazyIterator implements Iterator&lt;S&gt;{ Class&lt;S&gt; service; ClassLoader loader; /** * 私有构造函数，用于初始化参数 */ private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; }} 到了上面的内容，其实ServiceLoader.load()方法就结束了，并没有实际上去查找具体的实现类，那么什么时候才去查找以及加载呢，还记得上面的Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();这一行代码吗，这一行代码用于获取一个迭代器，这里同样也没有进行加载，但是，其后面还有遍历迭代器的代码，上面标注为1的部分。 迭代器以及遍历迭代器的过程如下所示 ServiceLoader.java 12345678910111213141516171819202122232425262728public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { // 注意这里的providers，这里就是上面提到的用于缓存 // 已经加载的服务提供者的容器。 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); // 底层其实委托给了providers public boolean hasNext() { if (knownProviders.hasNext()) return true; // 如果没有缓存，则查找及加载 return lookupIterator.hasNext(); } // 同上 public S next() { if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} 上面已经分析过了，ServiceLoader.load()方法执行到LazyIterator的初始化之后就结束了，真正地查找直到调用lookupIterator.hasNext()才开始。 LazyIterator.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163// 希望你还记得他private class LazyIterator implements Iterator&lt;S&gt;{ Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; //检查 AccessControlContext，这个我们不关系 // 关键的核心是都调用了hasNextService()方法 public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } private boolean hasNextService() { // 第一次加载 if (nextName != null) { return true; } // 第一次加载 if (configs == null) { try { // 注意这里，获取了的完整名称 // PREFIX定义在ServiceLoader中 // private static final String PREFIX = &quot;META-INF/services/&quot; // 这里可以看到，完整的类名称就是 META-INF/services/CLASS_FULL_NAME // 比如这里的 Driver.class，完整的路径就是 // META-INF/services/java.sql.Driver，注意这个只是文件名，不是具体的类哈 String fullName = PREFIX + service.getName(); // 如果类加载器为null，则使用系统类加载器进行加载 // 类加载会加载指定路径下的所有类 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else // 使用传入的类加载器进行加载，其实就是应用类加载器 configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } // 如果pending为null或者没有内容，则进行加载，一次只加载一个文件的一行 while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } // 解析读取到的每个文件，高潮来了 pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true; } /** * 解析读取到的每个文件 */ private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError { InputStream in = null; BufferedReader r = null; ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); try { in = u.openStream(); // utf-8编码 r = new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;)); int lc = 1; // 一行一行地读取数据 while ((lc = parseLine(service, u, r, lc, names)) &gt;= 0); } catch (IOException x) { fail(service, &quot;Error reading configuration file&quot;, x); } finally { try { if (r != null) r.close(); if (in != null) in.close(); } catch (IOException y) { fail(service, &quot;Error closing configuration file&quot;, y); } } // 返回迭代器 return names.iterator(); } // 解析一行行的数据 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError { String ln = r.readLine(); if (ln == null) { return -1; } // 查找是否存在# // 如果存在，则剪取#前面的内容 // 目的是防止读取到#及后面的内容 int ci = ln.indexOf('#'); if (ci &gt;= 0) ln = ln.substring(0, ci); ln = ln.trim(); int n = ln.length(); if (n != 0) { // 不能包含空格及制表符\\t if ((ln.indexOf(' ') &gt;= 0) || (ln.indexOf('\\t') &gt;= 0)) fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;); int cp = ln.codePointAt(0); // 检查第一个字符是否是Java语法规范的单词 if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); // 检查每个字符 for (int i = Character.charCount(cp); i &lt; n; i += Character.charCount(cp)) { cp = ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp != '.')) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); } // 如果缓存中没有，并且当前列表中也没有，则加入列表。 if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); } return lc + 1; } /** * 上面解析完文件之后，就开始加载文件的内容了 */ private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { // 这一行就很熟悉啦 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { // 实例化并且将其转化为对应的接口或者父类 S p = service.cast(c.newInstance()); // 将其放入缓存中 providers.put(cn, p); // 返回当前实例 return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen }} 到此，解析的步骤就完成了，在一开始的DriverManager中，我们也看到了在DriveirManager中一直在调用next方法，也就是持续地加载找到的所有的Driver的实现类了，比如MySQL的驱动类，Oracle的驱动类啦。 这个例子有点长，但我们收获还是很多，我们知道了JDBC4不用手动加载驱动类的实现原理，其实就是通过ServiceLoader去查找当前类加载器能访问到的目录下的WEB-INF/services/FULL_CLASS_NAME文件中的所有内容，而这些内容由一定的规范，如下 每行只能写一个全类名 # 作为注释 只能使用utf-8及其兼容的编码 每个实现类必须提供一个无参构造函数，因为是直接使用class.newInstance()来创建实例的嘛 由此我们也明白了SPI机制的工作原理，那么这个东西有什么用呢，其实JDBC就是个最好的例子啦，这样用户就不需要知道到底是要加载哪个实现类，一方面是简化了操作，另一方面避免了操作的错误，当然，这种一般是用于写框架之类的用途，用于向框架使用者提供更加便利的操作，比如上面的引导我看到SPI的例子，其实是来自一个RPC框架，通过SPI机制，让我们可以直接编写自定义的序列化方式，然后由框架来负责加载即可。 SPI实战小案例上面学习完了SPI的例子，也学习完了JDBC是如何实现的，接下来我们来通过一个小案例，来动手实践一下SPI是如何工作的。 新建一个接口，内容随便啦 HelloServie.java 123public interface HelloService { void sayHello();} 然后编写其实现类 HelloServiceImpl.java 123456public class HelloServiceImpl implements HelloService { @Override public void sayHello() { System.out.println(&quot;hello world&quot;); }} 关键点来了，既然是学习SPI，那么我们肯定不是手动new一个实现类啦，而是通过SPI的机制来加载，如果认真地看完上面的分析，那么下面的内容应该很容易看懂啦，如果没看懂，再回去看一下啦。 在实现类所在项目(这里是同个项目哈)的类路径下，如果是maven项目，则是在resources目录下 建立目录META-INF/services 建立文件cn.xuhuanfeng.spi.HelloService（接口的全限定名哈） 内容是实现类的类名:cn.xuhuanfeng.spi.impl.HelloServiceImpl(注意这里我们直接放在同个项目，不是同个项目也可以的！！！) 自定义一个加载的类，并且通过ServiceLoader.load()方法进行加载，如下所示 public class HelloServiceFactory { public HelloService getHelloService() { ServiceLoader&lt;HelloService&gt; load = ServiceLoader.load(HelloService.class); return load.iterator().next(); } } 测试一下，enjoy :) 如果你有兴趣的话，可以尝试将实现放在另一个项目中，然后打包成jar包，再放置在测试项目的classpath中，enjoy :) 总结本小节我们主要学习了SPI，主要包括了SPI是什么，JDBC4中不需要手动加载驱动类的原理，并且详细看了DriverManager中的代码实现，最后，通过一个简单的小案例来实现我们自己的SPI服务，通过这个小节，应该说，SPI的大部分内容我们是掌握了，当然，里面管理类加载器部分我们还没有学习，这里先挖个坑，后面有时间再分析一下。","link":"/2020/03/08/%E6%B5%85%E8%B0%88SPI%E6%9C%BA%E5%88%B6-md/"},{"title":"AQS之AQS分析","text":"接下来的这篇文章将详细分析AQS，AQS全称是AbstractQueuedSynchronizer，翻译过来是抽象队列同步器，也即AQS是一个基于队列实现的抽象同步器 AQS封装了获取锁，释放锁等操作，同时暴露一些try开头的方法交给子类来实现，通过继承AQS可以非常方便地实现一个线程安全的并发同步器，在java.util.concurrent包中的大多数高层次同步器，如CountdownLatch、ReentrantLock等都是通过AQS实现的 常用的基于AQS高层次同步器有如下几个 CountdownLatch CyclicBarrier Semaphore ReentrantLock 这篇文章只分析AQS提供的通用逻辑实现，分析完AQS之后，后面再用新的篇章分析基于AQS的同步工具的具体实现细节 本文参考自javadoop的 一行一行源码分析清楚AbstractQueuedSynchronizer 一行一行源码分析清楚 AbstractQueuedSynchronizer (二) 非常感谢大神无私地分享 AQS之AQS分析核心概念在具体分析AQS之前，有几个核心概念需要先弄清楚，这些概念是看懂接下来内容必不可少的 链表链表是一个基础的线性数据结构，节点之前通过”指针”链接起来，从而构成一个完整的链，java.util.LinkedList就是一个非常典型的链表的实现 链表根据实现细节的不同，有三种比较典型的链表 单向链表，节点通过单向指针链接起来，每个节点只能访问其后面的节点 双向链表，每个节点通过前向指针，后向指针分别链接前节点、后节点，每个节点可以访问其前后节点 循环链表，链表收尾相连，构成一个环，有两种典型实现 单向循环链表 双向循环链表 AQS中获取不到锁的排队就是通过一个双向链表来实现，该队列也称为等待队列(同步队列) 同时也通过内部类ConditionObject，来实现Condition的语义，在某个条件上等待的语义就是通过一个单向链表来实现，该队列也称为条件队列 锁锁，这个概念并不陌生，在并发环境下，对于临界区的访问，为了避免并发操作对数据带来不一致性(也称为竞态条件)，通常需要先获取锁再执行对应操作 根据同时可以被持有对象的不同，锁可以分为两种 独占锁，也称为X锁，顾名思义，同时只能被一个线程持有，只有加锁的线程才能解开锁 共享锁，也称为S锁，允许同时多个线程持有(同时加锁或者解锁都是可以) 根据是否可被中断，锁可以分为两种 可中断锁，顾名思义，收到中断信号，并且会处理中断信号，在Java中通常表现为抛出中断异常InterruptedException 不可中断锁，发生中断异常时，仅记录中断信号而不会抛出中断异常 根据获取锁的时机不同，锁可以分为两种 抢占锁，也称为非公平锁，释放锁的那一刻，允许新来的线程参与锁的抢占 不可抢占锁，也称为公平锁，按照先来后到的顺序分配锁 根据锁的策略，可以分为两种 乐观锁，认为竞争本身很小，所以大部分情况下是不需要获取锁来访问临界区 悲观锁，认为竞争大，每次访问临界区都需要获取锁 上面的几种分类是常见的锁的分类，这些分类之间是可以相互组合的，如不可中断独占锁，可中断共享锁等 在AQS中，提供了独占锁和共享锁的实现，同时，提供一个方法用于实现公平锁、非公平锁 无锁化在旧版的JDK中，提供了基于监视器的synchronized关键字，用于作为锁的实现，该锁是自动获取以及释放，有时候也称为对象锁，因为锁的目标就是某个对象 使用锁的好处的使用方便，直观，但也有比较明显的缺点 通常获取锁的时候，如果无法获取到锁，则线程本身会被阻塞，等到锁重新释放的时候，才会重新尝试获取锁，当并发比较大的时候，对于锁的竞争会非常激烈，容易影响性能 在一些场景中，临界区本身非常小，对于临界区的操作时间比获取锁、释放锁两个操作加起来的时间还小，也就容易造成锁本身带来的消耗大于实际工作的时间 于是，无锁化的概念逐渐提出，无锁化，顾名思义，对临界区的操作本身不再通过加锁的形式来访问，有时候，这种形式也称为乐观锁，目前采用得比较多的就是通过CAS来实现无锁化操作，CAS本身需要CPU提供支持，关于Java中的CAS实现，可以大致参考下之前的文章：AtomicXXX使用及分析 在AQS中，对于临界区(锁状态、链表节点改变等)的操作，都是通过CAS来实现的 条件等待条件等待在编程中非常常见，某一个线程需要某些资源，而这些资源目前还没有准备完成，此时线程就需要等待该资源准备完成之后再运行，在等待期间，线程需要挂起，这个过程也称为”条件等待”。 等待某个条件发生，如常见的生产者消费者模型中，当缓冲区满了的时候，生产者需要等待缓冲区有空间，当缓冲区空的时候，消费者需要等待缓冲区有内容 在Java中，每一个对象都可以作为一个条件，多个线程可以在该对象上进行等待，如常见的obj.wait()，在进行条件等待的时候，需要先获取该对象锁，否则会抛出监视器异常，执行wait操作之后，线程会被挂起，同时，线程持有的锁会被释放；当被其他线程唤醒，即notify()的时候，线程会被唤醒，重新获取锁，然后继续执行(注意，此时条件不一定满足，因为从条件发生到线程获取到CPU执行存在时间差，可能线程继续执行的时候，条件又不满足了，所以一般是将条件等待放在循环中，唤醒之后重新检查一下是否条件满足) AQS核心内容Node结构Node是AQS的一个内部类，该类本身所包含的属性不多，却是整个AQS的核心，有如下几个属性 waitStatus，等待状态 thread，节点对应的线程 next，指向等待队列下一个节点 prev，指向等待队列前一个节点 nextWaiter，指向条件队列下一个节点 其中的waitStatus是比较复杂的，用于标志当前节点所处的状态，有以下几个值 CANCELLED：1，表示线程取消等待 0，默认值 SIGNAL：-1，表示下一个节点需要被唤醒 CONDITION：-2，表示当前节点处于等待条件发生 PROPAGATE：-3，表示下一个节点等待共享锁的线程需要被无条件通知 nextWaiter是另外一个比较有趣的字段，前面提到了，AQS支持条件等待，当多个线程在同一个条件上等待时，显然，也是需要将其合理的组织起来 Node中通过类型的Node的nextWaiter将其串联起来，其值有两种 当处于共享模式时，节点的值均为SHARE 当处于排他模式时，为等待同样条件的节点(默认为null，表示没有) 当节点处于等待获取锁时，等待队列如下图所示 当节点处于等待某个条件时，条件队列如下所示 AQS结构AQS的实现细节非常复杂，各种情况错综复杂，考虑地非常详细，但是，AQS的结构本身非常简单，由一个head一个tail构成等待队列，一个state代表锁状态，一个exclusiveOwnerThread代表独占锁持有线程 state就是一个整数，0表示当前锁没有被占有，大于0表示重入，为了保证可见性，同时被声明为volatile exclusiveOwnerThread代表的是当前占据独占锁的线程，该属性继承于AbstractOwnableSynchronizer AQS的完整结构如下 获取锁前面提到了，AQS提供的核心功能其实就是获取锁以及释放锁这两个操作，对于AQS的理解，关键也在于这两个操作，根据锁类型的不同，AQS提供了独占锁与共享锁两种不同类型的操作，接下来详细分析每一个操作 获取独占锁AQS中，获取锁的操作通过acquire开头的一些方法完成的，根据是否可被中断，分为两种：可中断以及不可中断，关于这两者前面已经介绍了，这里就不展开，直接分析AQS的实现 不可中断12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} acquire方法是一个模板方法，留下了tryAcquire交由子类实现，也即子类根据实现的不同，决定什么时候能够获取成功(返回true)，什么时候获取失败(返回false) 由于获取成不成功是由子类决定的，并且不同的工具的含义也不同，这里我们只重点看下获取失败的操作 根据独占锁的语义，一把锁同时只能被一个线程持有，在持有锁期间，其他线程尝试获取锁，都应该被阻塞或者挂起，结合上面的前面等待队列的图示，不难猜出，获取失败之后的大致流程就是将当前线程包装成链表节点，然后添加到链表中，最后挂起自己，等待唤醒 addWaiter操作 首先是addWaiter操作，在AQS中，等待队列的一个节点也称为一个waiter，那么，这个方法就很显然了，将线程包装成一个waiter，然后添加到等待队列中 1234567891011121314151617181920212223242526272829303132// 参数mode代表的含义是当前线程的等待类型，这里是独占锁，那就是EXCLUSIVE啦private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 初始情况下，head=tail=null // pred != null说明等待队列初始化完成了 // 那就尝试将自己挂在队列尾部，成为新的尾部 if (pred != null) { // 将当前节点的prev指针指向原来的tail(这一步线程安全) node.prev = pred; // 1 // 通过cas将原来的tail设置为自己 // 注意，这里是存在并发情况的，如果有两个线程同时将自己设置为尾部 // 那么存在一个被另一个覆盖的情况，所以需要通过CAS来保证只有一个成功 if (compareAndSetTail(pred, node)) { // 2 // 如果cas成功，则将原尾部的next指向自己，使自己成为新的尾部 pred.next = node; // 3 return node; } // 上面的1、2、3三个步骤不能变换顺序，否则会出现数据错乱 } // 如果到了这里，有两种情况 // 1、队列未初始化 // 2、CAS失败，表明同一时刻有另一个线程抢先成为尾节点了 // 那应该怎么办呢？ // 很显然，入队是必须的，那就只能一直尝试入队，直到成功为止了 enq(node); return node;} enq操作 12345678910111213141516171819202122// 该操作意图很简单，一直尝试入队，直到成功为止private Node enq(final Node node) { for (;;) { Node t = tail; // 此时队列尚未初始化，那就初始化一下咯 if (t == null) { // 注意，同样存在并发，所以需要通过CAS if (compareAndSetHead(new Node())) tail = head; // 可以看到，初始化本身是延迟到有节点入队的时候才进行的 // 初始化也很简单，就是创建一个空节点作为头部，同时，初始化尾部 // 注意，初始化之后没有return，所以重新循环会进入到else中 } else { // 这一步就跟addWaiter里面的操作一样啦 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} 到目前为止，完成了三个操作 尝试直接获取锁，如果可以，那就获取到，接着按照线程的处理逻辑走 如果获取失败，那将自己挂到等待队列尾部 如果队列未初始化，那就先初始化一下 如果挂到队列尾部失败，那就一直挂，直到成功，失败的原因只有一个，被其他人抢了，那最后一定会入队成功的，当没有其他人抢占入队的时候，自己就能入队了 经过前面的几个步骤，此时线程已经入队成功了，此时线程面临着两个选择 如果入队完了之后，刚刚好排到自己去运行了，那就不用挂起了，直接去执行就完事了 另一种就是，还没轮到自己去运行，那就老老实实挂起了 acquireQueued 123456789101112131415161718192021222324252627282930313233// 返回true表示挂起过程发生中断，false表示没有final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 获取前一个节点 final Node p = node.predecessor(); // 如果前一个节点是head，并且能拿到锁 if (p == head &amp;&amp; tryAcquire(arg)) { // 将自己设置为头结点，直接返回 setHead(node); p.next = null; failed = false; return interrupted; } // 到了这里，说明要么不是头结点，要么就抢不过别人 // 那就看下是否要挂起了，要就挂起了 // 当shouldParkAfterFailedAcquire返回false时，就接着循环 // 返回true，就进入park了 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // park返回true表明需要中断，记录下中断信号 interrupted = true; } } finally { // 注意这里，正常走流程是不会到这里的 // 如果走到这里，说明是抛出异常了，那就取消了 // 毕竟执行过程出错了 if (failed) cancelAcquire(node); }} shouldParkAfterFailedAcquire 1234567891011121314151617181920212223private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 如果前一个节点的ws为SIGNAL，说明当前节点已经向前节点 // 告知自己需要被唤醒了，那接着挂起吧 if (ws == Node.SIGNAL) return true; // 如果前一个节点的ws&gt;0，说明前一个节点取消等待了 // 那只能重新找一个新的前向节点了 if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 到了这里说明此时ws=0或者-3 // 那重新修正一下，修改为SIGNAL(-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } // 刚刚修改完状态或者调整父节点，本次先不挂起 // 下一波再试试看能不能直接运行，实在不行再挂起，毕竟挂起的代价还是蛮高的 return false;} parkAndCheckInterrupt 123456789private final boolean parkAndCheckInterrupt() { // 到这里就挂起了 LockSupport.park(this); // 到这里线程就醒来 // 醒来的原因有两个 // 1. 收到中断信号 // 2. 其他线程执行unpark操作(也就是signal啦) return Thread.interrupted();} cancelAcquire 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void cancelAcquire(Node node) { if (node == null) return; node.thread = null; // 如果前面也有节点取消了，那顺便清理一下吧 // 毕竟取消了就没有排队的意义了 Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; Node predNext = pred.next; // 标志为取消状态 node.waitStatus = Node.CANCELLED; // 到了这里，当前节点前面的取消了排队的节点就已经被清理了 // 如果node为尾节点，那将pred设置为新的tail // 由于此时对tail操作，所以存在竞态(可能此时有人同时入队) if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { // 将pred的next设置为null，也就是tail的next清空啦 // 原来是引用node嘛 compareAndSetNext(pred, predNext, null); } else { // 如果进入这里，说明取消排队的节点位于队列中间，也就是前后都有人 // 如果位于中间，那就得看下需不需要通知后面的节点了 int ws; // if的条件很严苛，只有同时满足三个，才会进入 // 进入的目的就是把node后面的节点挂在起来，毕竟node本身已经取消了 if ( // 1. node的前节点不是head pred != head &amp;&amp; // 2. 前节点的状态值=-1或者&lt;=0并且修改为-1成功 // 这一点是避免执行到if的时候，pred自己也取消了(取消的waitStatus是-1) // ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; // 3. pred存在线程，这个应该只是额外检查，大部分情况下都是存在的 pred.thread != null) { Node next = node.next; // 将pred的next设置为next，也就是跳过了node了 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); } else { // 不满足上面情况的，那就直接唤醒后面的节点了 unparkSuccessor(node); } node.next = node; // help GC }} unparkSuccessor 123456789101112131415161718192021222324private void unparkSuccessor(Node node) { // 将node状态改为0，表明即将唤醒后面的节点 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 如果next节点为空或者已经取消排队 // 那就从后往前找了(这种情况还是很少的，大部分情况都是正常的节点) if (s == null || s.waitStatus &gt; 0) { s = null; // 为什么需要从后往前呢 // 当s为null时，很显然了，next链已经断开，只能从prev入手了 // 如果已经取消排队了呢？ // 回顾一下cancelAcquire的最后一行node.next = node // 此时next链(可能)也已经断开了 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) LockSupport.unpark(s.thread);} 到了这里，获取锁的完整过程就接近分析完毕了，重新回顾一下acquire方法 123456public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 如果发送中断了，那就发送一个中断信号，毕竟之前的已经取消了 selfInterrupt();} 可中断前面我们详细分析了acquire方法，该方法是不可中断的，从代码中也可以看到，当发生中断时只是记录下中断信号，然后重新等待获取锁 而可中断的获取锁的方式就不同了，当发生中断的时候，会直接抛出中断异常，从而结束当前的等待，具体看下面分析 acquireInterruptibly 123456789public final void acquireInterruptibly(int arg) throws InterruptedException { // 先检查一下是否需要中断 if (Thread.interrupted()) throw new InterruptedException(); // 同样的，先试一下，如果失败，再接着走 if (!tryAcquire(arg)) doAcquireInterruptibly(arg);} doAcquireInterruptibly 123456789101112131415161718192021222324252627private void doAcquireInterruptibly(int arg) throws InterruptedException { // 包装成Node final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; // 下面的处理逻辑基本同acquireQueued，只是现在响应中断了 try { for (;;) { final Node p = node.predecessor(); // 跟前面一样，拿到锁就结束 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } // 检查是否需要挂起，注意这里发生中断之后，直接就抛出 // 中断异常了 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }} 有了前面的铺垫，分析可中断的情况就简单得多了，从代码中也可以看出，不可中断和可中断的区别就在于，可中断在发生中断之后，就取消排队(注意是在finally里面，一定会执行的)，然后抛出异常了 到这里，获取锁的全部内容就分析完毕了，如果没怎么看懂的话，再结合源码多看几次就大致能看懂了 获取共享锁共享锁的相对于独占锁来说，支持同时多个线程持有锁，这也就使得其稍微有点复杂，接下来详细分析共享锁，同样的，共享锁支持不可中断以及可中断两种形式 不可中断 acquireShared 12345public final void acquireShared(int arg) { // 同样的，先试下，不成功的话，就接着往下走 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);} tryAcquireShared方法返回类型是一个int，有三种含义 负数，表示获取失败 0，以独占形式获取 正数，获取成功 doAcquireShared 12345678910111213141516171819202122232425262728293031323334353637383940private void doAcquireShared(int arg) { // 包装成worker，注意模式是SHARE final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 如果是头节点 if (p == head) { // 先尝试一下，说不定能成功呢 int r = tryAcquireShared(arg); if (r &gt;= 0) { // 到这里说明获取成功了 // 设置头部并且尝试唤醒下一个节点 setHeadAndPropagate(node, r); p.next = null; // 如果有中断，那传递一下中断信号 if (interrupted) selfInterrupt(); failed = false; return; } } // 这一部分就跟获取独占锁处理逻辑一样了 // 检查是否需要挂起，需要就挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; // 这里需要特别注意 // 唤醒之后，被唤醒的节点的前一个节点一般就是head，所以，会接着唤醒后续节点 } } finally { // 同样的，失败就取消排队 if (failed) cancelAcquire(node); }} 从上面的方法可以看到，共享锁的获取方式跟独占锁还是挺接近的，区别在于共享模式中，节点获取到锁之后，会传递信号，具体分析如下 setHeadAndPropagate 1234567891011121314151617private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // 注意这个操作，将自己设置为头节点 setHead(node); // 如果propagate &gt; 0或者原有的head的状态是&lt;0 // 或者新的head的状态是&lt;0 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; // 如果s是共享模式 if (s == null || s.isShared()) // 唤醒下一个节点，此时，下一个节点的prev就是当前节点 // 而前面已经将当前节点设置为head，所以，很大概率下个节点 // 也会被唤醒(如果能拿到锁) doReleaseShared(); }} doReleaseShared 123456789101112131415161718192021222324252627private void doReleaseShared() { for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; // 如果head的状态为-1，则改为0，并且唤醒下一个节点 if (ws == Node.SIGNAL) { // 这里失败的原因在于可能多个人同时修改head的状态 // 比如当前线程以及唤醒当前线程的线程 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h); } // 如果head状态为0，则将其改为PROPAGATE // 这里就不是很理解，改成PROPAGATE的意义是什么??? else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; } // 如果头节点没有发生变化，说明唤醒之后，后续节点 // 还没有调度执行，说明此时任务还是比较繁重，那就退出 // 当前线程唤醒其他线程的任务了 // 这里还是不太明白？？？ if (h == head) break; }} 从这里可以看到，在获取到锁之后，每个线程都会尝试唤醒下一个节点，而每个线程被唤醒之后，都会检查自己前面是否是头结点，能否获取到锁，如果都可以，就会继续唤醒接下来的线程 这是与独占模式最大的区别，共享模式下，一旦释放锁，会接着尝试唤醒等待队列中处于共享模式的其他节点，注意，是每个被唤醒节点都会这么做，这就相当于一个唤醒链了 可中断看完了独占锁的可中断模式，很容易就能猜到共享锁的可中断模式了 acquireSharedInterruptibly 123456789public final void acquireSharedInterruptibly(int arg) throws InterruptedException { // 先检查中断情况 if (Thread.interrupted()) throw new InterruptedException(); // 拿不到锁，那就排队挂起 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);} doAcquireSharedInterruptibly 123456789101112131415161718192021222324252627private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 其实就这里变化了，变成了直接抛出中断异常 throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }} 释放锁前面的获取锁部分，详细分析了获取锁的过程，有获取锁，自然就有释放锁了，锁的释放过程相对于获取锁来说，就简单地多了，毕竟释放锁本身并不需要进行同步，接下来详细分析释放锁的过程 同样的，独占锁和共享锁的释放过程是不同了，所以下面也是区分开两者进行分析 释放独占锁独占锁的释放本身来说，比共享锁简单，因为能够释放独占锁，本身就意味着自己已经持有独占锁了，那一切的操作都是无需关注并发问题的 独占锁的释放主要包含两个流程 释放自己占据的资源(即锁的状态) 唤醒后续节点 release 12345678910public final boolean release(int arg) { // 尝试释放，释放成功就唤醒后续节点 if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 同样的，tryRelease本身是一个空方法，由子类实现，关于如何使用，会在后续分析基于AQS的工具中具体分析到，这里先挖个坑 释放共享锁释放共享锁相对于独占锁来说，稍微有点复杂，但如果仔细看前面的获取共享锁部分，那其实释放锁的过程基本也就清楚了 releaseShared 12345678public final boolean releaseShared(int arg) { // 尝试释放一下 if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false;} doReleaseShared 这个方法是实际释放锁的操作，不过这里就不分析了，为啥？前面分析获取共享锁已经分析过了，如果忘记了，返回去看一下就可以了 ConditionObject如果你看到这里，首先应该恭喜你，关于AQS的大部分内容基本已经分析完毕了，AQS中最最复杂的内容已经结束了，接下来分析的内容可以理解为AQS的扩展部分 在AQS中，提供了条件等待的语义实现，关于条件等待的基础概念，在前面核心概念部分稍微提到了，接下来将详细分析其具体语义及AQS的实现 条件等待条件等待其实就是等待指定条件的发生，当线程在处理某个任务的之后，需要特定的资源/条件下才能接着进行，那么，线程就应该停止下来等待该条件的发生，当然，对于开发者而言，就需要对应的工具来实现该语义了 在JDK中，提供了最原始的支持，每一个Object对象本身就是一个条件队列，通过Object对象的wait方法就可以实现在该条件上进行等待，通过notify或者notifyAll就可以唤醒在该条件上等待的对象，同时，需要注意，操作这些方法时候，需要获取该条件的监视器锁 AQS之所以也提供条件等待的支持，就是原始的条件等待本身不够强大，具体表现为：一个Object对象有唯一一把监视器锁，唯一一个等待队列，但在实际使用过程中，却经常需要有同一把锁对应多个条件的情况，如，在操作缓冲区的时候，需要获取缓冲区的锁，然后进行操作(读/写)，此时，缓冲区满了以及缓冲区有空间，对应的是两个条件，但是对应的是操作缓冲区这把锁，通过原始的实现方法，就得通过两个锁来实现两个条件等待了，当条件越多的时候，需要的锁数量也就越多，锁越多，就越不好维护，万一一不小心忘记释放了呢 所以，在JDK1.5中，提出了Condition的概念，同时，通过AQS提供实现 Condition的语义与原始的条件等待是一样的，但解决了原始条件等待存在的问题，对于Condition的操作，同样需要获取对应的锁，只是Condition不再依赖于监视器锁，而是通过自定义锁提供支持，如ReentrantLock，同一把锁可以支持一个到多个Condition，从而满足了在同一把锁上实现多个条件等待的需求 Condition Condition接口提供的方法都非常清晰，简单看一下即可 12345678910public interface java.util.concurrent.locks.Condition { public abstract void await() throws InterruptedException; public abstract void awaitUninterruptibly(); public abstract long awaitNanos(long) throws InterruptedException; public abstract boolean await(long, TimeUnit) throws InterruptedException; public abstract boolean awaitUntil(Date) throws InterruptedException; // 对应Object的nofity和notifyAll public abstract void signal(); public abstract void signalAll();} Condition中的await对应的就是Object中的wait，signal对应notify，signalAll对应notifyAll，至于为什么不直接覆盖，应该是为了保留原始的语义，Condition本身也可以作为一个条件(一切均继承Object) 了解了AQS加锁的过程，大致也可以猜出来，等待条件发生的过程其实就是将等待的节点挂到指定的条件队列上，而条件的到达，其实就是对应的操作了 接下来详细分析AQS中Condition语义的实现，即ConditionObject ConditionObjectConditionObject结构ConditionObject也是AQS的内部类，包含的属性也是比较简单的 firstWaiter lastWaiter 两个属性的类型都是Node，就是上面已经分析过的那个Node，看到这里，大致上就可以猜出来了，AQS中的Conditoin实现其实就是一个链表，将等待的节点挂到该链表上而已 等待等待的语义就是说，当前这个条件不满足接着运行下去的需求，那么需要挂起等待其条件的发生，当然，由于自己已经挂起了，那么唤醒自然就是由其他人来操作了 当然，等待本身也是支持不可中断已经可中断的，从前面分析获取锁的过程大致已经可以得知，两者差异不大，这里我们就放一起分析了，不单独开一个小节 await 1234567891011121314151617181920212223242526272829303132333435public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 将自己添加到条件队列中(先看下面对该方法的分析，再接着往下走) Node node = addConditionWaiter(); // 释放自己占据的锁，必须先获取锁才能进行等待(先看下面对该方法的分析，再接着往下走) int savedState = fullyRelease(node); // 到这里就说明锁释放成功了，那接下来就准备挂起，等待条件发生了 int interruptMode = 0; // 检查看自己是否在同步队列(等待队列) // 如果不在，那就说明自己还没有被唤醒，此时醒来是意外 // 为什么呢？ // 联想一下前面获取锁的操作，要执行条件等待，必须先获取锁，此时自己必定是队头 // 同时，等待之前，必须释放锁，此时会唤醒等待队列的后续节点，那么，也就意味着自己已经 // 离开了等待队列，在条件队列中了 // 如果又回到了等待队列，那么就说明情况发生了，自己被重新移动回等待队列中(参加唤醒操作) while (!isOnSyncQueue(node)) { LockSupport.park(this); // 检查是否在等待过程中出现中断(先看下面对该方法的分析，再接着往下走) if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 直接滑动到checkInterruptWhileWaiting的分析之后，这里太庞大了，放在后头分析 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);} addConditionWaiter 1234567891011121314151617181920// 将等待节点添加到条件队列中，该方法可以说是条件等待的核心了private Node addConditionWaiter() { Node t = lastWaiter; // 如果有节点取消等待了，那就先移除咯 // 取消了就没必要等待了 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } Node node = new Node(Thread.currentThread(), Node.CONDITION); // 比较直观，将自己挂到队尾就行了 // 这里之所以不需要通过CAS，是因为此时已经持有锁了，不存在并发情况 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;} unlinkCancelledWaiters 12345678910111213141516171819202122232425// 将取消排队的节点移除private void unlinkCancelledWaiters() { Node t = firstWaiter; Node trail = null; // 从头到尾扫一遍，如果取消了，就将其移除 while (t != null) { Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) { // 断开t t.nextWaiter = null; // trail为null说明中间没有出现跳点，即(取消-不取消-取消的情况) if (trail == null) firstWaiter = next; // 跳过取消的节点 else trail.nextWaiter = next; if (next == null) lastWaiter = trail; } // 如果节点依旧在等待，trail往后移动就行 else trail = t; t = next; }} fullyRelease 1234567891011121314151617181920212223// 完全释放锁，毕竟有重入的情况存在// 返回当前锁的情况，后续重新获取的时候需要使用到final int fullyRelease(Node node) { boolean failed = true; try { // 获取当前锁状态(包含重入的情况) int savedState = getState(); // 如果能够释放成功，那就返回了 // release的行为取决了tryRelease // 正常情况来说，释放都是成功的，毕竟是自己持有锁 if (release(savedState)) { failed = false; return savedState; // 如果释放失败，那就抛出监视器异常 } else { throw new IllegalMonitorStateException(); } } finally { // 如果当前节点失败，将当前节点状态调整为取消，后面会被移除 if (failed) node.waitStatus = Node.CANCELLED; }} isOnSyncQueue 12345678910111213final boolean isOnSyncQueue(Node node) { // 如果此时状态还是等待(见signal分析)，或者前面没有节点 // 说明还没有在等待队列中(思考一下进入等待队列的操作，先修改prev，再修改next) if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 如果next已经有值了，那就说明一定在等待队列中了 // (思考一下进入等待队列的操作,先修改prev，再修改next) if (node.next != null) return true; // 从后往前找一下，看是否存在于等待队列中 // 同样需要结合入等待队列的操作分析 return findNodeFromTail(node);} findNodeFromTail 12345678910private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) return false; t = t.prev; }} checkInterruptWhileWaiting 1234567// 检查是否在等待条件过程中发送中断private int checkInterruptWhileWaiting(Node node) { return Thread.interrupted() ? // 如果发生中断，看下是在哪个环节发送的中断 (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;} transferAfterCancelledWait 1234567891011121314151617final boolean transferAfterCancelledWait(Node node) { // 此时已经唤醒了，修改一下状态 // 此时有两种情况，一种是通过signal唤醒，那么状态会被signal修改,CAS失败 // 如果CAS成功，意味着是非正常唤醒，有可能是中断，有可能是系统偶然唤醒 // 但此时已有中断信号，说明只能是被中断了 // 注意，此时CAS是成功的 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) { // 如果被意外唤醒，那进入到等待队列排队吧 enq(node); return true; } // 到这里说明是正常唤醒，如果还没有在等待队列中，说明signal操作还没有完成 // 自旋一下等待完成就可以了 while (!isOnSyncQueue(node)) Thread.yield(); return false;} 接着回到最开始的await操作 await 12345678910111213141516171819202122232425262728public final void await() throws InterruptedException { // ..... while (!isOnSyncQueue(node)) { // 到这里就挂起了 LockSupport.park(this); // 到这里就被唤醒了 // 1.通过signal唤醒 // 2.中断唤醒 // 前面分析到这里，checkInterruptWhileWaiting会返回三种值 // 0，没有发生中断，那么就继续检查，排队吧 // 如果不是0，说明发生了中断，那就该起来工作了 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 注意，此时只是被唤醒，还没有拿到锁 // 重新排队等待获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 到这里说明获取锁，顺便清理一下取消的节点 if (node.nextWaiter != null) unlinkCancelledWaiters(); // 如果发生了中断，那就处理一下 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);} reportInterruptAfterWait 123456789101112131415private void reportInterruptAfterWait(int interruptMode) throws InterruptedException { // THROW_IE(-1)，transferAfterCancelledWait返回true则返回该值 // 说明此时是被中断唤醒，那就需要抛出中断异常了 // REINTERRUPT(1)，通过signal正常唤醒 // await是可中断的 if (interruptMode == THROW_IE) throw new InterruptedException(); // 发送下中断信号就行 else if (interruptMode == REINTERRUPT) selfInterrupt();} 到这里，等待条件的操作就结束了，重新梳理一下await操作的流程 将自己添加到条件队列中 释放占据的锁 释放失败说明是非法操作 等待唤醒 signal唤醒 中断唤醒 唤醒之后，等待获取锁，获取之后 接着挂起之前的流程 或者需要抛出异常，则直接抛出中断异常 唤醒前面详细分析了等待条件发生的具体操作，接下来分析唤醒的具体操作 signal 123456789public final void signal() { // 如果不是排它锁的持有者，则直接抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; // 唤醒下一个节点 if (first != null) doSignal(first);} doSignal 12345678910private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // first即将唤醒，断开连接 first.nextWaiter = null; // 将找到的第一个合适的节点从条件队列移动到等待队列 } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);} transferForSignal 1234567891011121314151617// 将节点移动到等待队列，等待唤醒final boolean transferForSignal(Node node) { // 如果修改状态失败，说明中途已经被唤醒了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 入队 Node p = enq(node); int ws = p.waitStatus; // 如果前状态已经取消排队，修改前节点表示自己需要被唤醒 // 如果修改失败，那就说明前节点状态已经发送了变化，把自己也唤醒 // 由于已经入队了，所以会去参与竞争锁 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} 可以看到，唤醒的操作也是比较直观的，将第一个正常的节点移动到等待队列中等待唤醒，或者直接唤醒该节点(特殊情况) signalAll signal操作只是唤醒其中的一个，如果需要唤醒多个，则通过signalAll 1234567public final void signalAll() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);} doSignalAll 12345678910// 将所有节点都尝试移动到等待队列，等待获取锁private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null);} 到这里，唤醒的操作分析就结束了，稍微总结一下唤醒的过程 将节点移动到等待队列 根据情况决定唤醒该节点还是结束本次唤醒操作(等待等待队列头节点唤醒即可) 总结到了这里，基本上AQS的核心功能就分析完成了，当然，还有少部分的内容没有分析，这并非偷懒或者遗忘，而是这一部分的内容与后面的内容更加贴切，所以就将其放在后面分析了 在本文中，详细对AQS进行了详细的介绍，AQS是一个并发安全的同步器，通过AQS，可以简单快捷地实现一个并发安全的工具，当然，本文中只是提出这点，但并没有具体体现，在后面一篇文章中将结合已有基于AQS实现的同步在体现AQS的这个特点 在本文中，我们详细分析了AQS的获取锁的方式，包括 独占锁 不可中断 可中断 共享锁 不可中断 可中断 同时详细分析了其释放锁的具体操作以及条件队列的实现ConditionObject 从分析中可以看出，AQS是基于链表来实现的，等待队列是基于双向链表，而条件队列是基于单向链表。如果获取不到锁或者条件不满足，则将其放到对应的队列尾部，等待唤醒，条件队列的节点唤醒之后，会将自己从条件队列移动到等待队列，等待获取锁 通过对AQS的分析，可以更好地理解一些并发工具的特性，在使用这些工具的时候能让我们更加清楚这些工具的注意事项 好了，到这里，对AQS的分析就告一段落了，后面将详细分析基于AQS实现的几个同步工具，Let’s keep going on.","link":"/2019/11/20/AQS%E4%B9%8BAQS%E5%88%86%E6%9E%90/"},{"title":"AQS之同步工具","text":"在前面一篇文章中，详细分析了AQS的原理，但没有涉及到AQS的使用，对于AQS我们也只是知其所以然而不止其然，只知道AQS长什么样，有什么用，是怎么实现的，但却缺少了最核心的，AQS要怎么用 在这篇文章中，我们将详细分析众多基于AQS实现的同步工具，如ReentrantLock、CountdownLatch等，通过这些工具的实现来了解AQS的使用，从而打通AQS使用、分析的整个过程 AQS之同步工具前言前面提到了，java.util.concurrent包中的很多同步工具都是基于AQS来实现，常用的工具有 ReentrantLock CountdownLatch Semaphore CyclicBarrier … 这篇文章将对上面列出的这四个工具进行详细分析 这四个工具大体上可以分为两类，其中ReentrantLock代表的是独占锁模式，另外三个或多或少代表的则是共享锁模式，分别对应了AQS的两种模式 对于这四个工具的分析，会分成两部分，第一个部分是该工具的介绍、使用、应用场景，第二个部分则是这篇文章的重点，即该工具的源码分析，希望这篇文章能对你有所帮助 ReentrantLockLockjava.util.concurrent.locks.Lock接口是JDk1.5中引入的，提供与synchronized相同的锁的语义，即限制资源的访问，但两者有所区别(废话，没区别就不需要增加了) 两种锁各有千秋 synchronized的优点在于使用简单、方便，本身由JVM控制锁的获取及释放，所以开发者不需要担心忘记释放锁的情况，但是其不足也是比较明显 仅支持阻塞模式，即锁要么获取成功，要么阻塞直到获取成功 不支持超时 不支持中断 synchronized的不足就是Lock接口所需要补充的了，Lock接口提供的功能如下 123456789101112public interface Lock { // 不支持中断的获取锁，与synchronized使用一致 public abstract void lock(); // 支持中断的获取锁 public abstract void lockInterruptibly() throws InterruptedException; // 仅尝试获取锁，如果成功，则返回true，如果获取失败，则返回false，不阻塞 public abstract boolean tryLock(); // 同上，但是在指定时间内如果能获取到，则成功返回true，失败返回false，中断则抛出异常 public abstract boolean tryLock(long, TimeUnit) throwsInterruptedException; public abstract void unlock(); public abstract Condition newCondition();} 从上面的方法结合前面的分析，大概就能猜出来Lock所提供的功能了 ReentrantLockReentrantLock是java.util.concurrent.locks.Lock接口的实现 本身提供的重入的语义，并且支持公平模式以及非公平模式 所谓重入，一把锁可以多次被同一个线程持有，即该锁可以被该线程“重入” 重入基本上是必须的，比如有两个被同一个锁限制访问的方法，如果锁本身不具备重入的话，那该线程将无法在其中一个方法访问另一个方法，因为在访问第一个方法的时候，已经获取了锁，而此时还没有释放锁就去访问第二个方法，由于锁本身不重入，所以要求该线程重新获取锁，但该锁已经被获取了，所以无法再被获取 注意，synchronized提供的也是具有重入语义的锁 使用既然是锁，那使用其实也就非常直观了，在进入临界区之前，获取锁，退出临界区之后，释放锁 接下来看下其具体使用 123456789101112131415161718192021222324252627class Task implements Runnable { private Lock lock; public Task(Lock lock) { this.lock = lock; } @Override public void run() { Thread thread = Thread.currentThread(); log.info(&quot;thread:[{}] try to get lock&quot;, thread); try { // 获取锁 lock.lock(); log.info(&quot;thread:[{}] get the lock&quot;, thread); Random random = new Random(); try { TimeUnit.SECONDS.sleep(random.nextInt(10)); } catch (InterruptedException ignored) {} }finally { log.info(&quot;thread:[{}] release the lock&quot;, thread); // 释放锁 lock.unlock(); } }} 如果同时传入一把锁，在多线程环境下执行该任务，可以看到可能同时多个线程打印出try to get lock，但只会有一个线程打印出get the lock，打印出release the lock，即释放锁只有，其他线程才有可能获取到锁 重入锁的使用很简单，但需要注意，一定要保证获取到的锁在不需要使用的使用能够释放，Doug Lea在Lock接口的doc中也推荐在try-finally块中使用，并且在finally中释放，这样可以保证无论是否执行过程中抛出异常，一定能够释放该锁(finally)一定会执行 其他尝试获取锁的方式也是类似的，这里就不举例了 分析接下来就是这一小节的重头戏了，我们将挨个分析ReentrantLock的方法 签名及属性ReentrantLock的签名 12public class ReentrantLock implements Lock, java.io.Serializable {} 属性 1private final Sync sync; Sync是ReentrantLock的内部类，继承了AQS，在AQS的doc中明确说明，所有AQS的子类应该尽量封闭在工具类的内部，避免被外部直接访问 方法 构造方法 1234// 默认情况下是非公平模式public ReentrantLock() { sync = new NonfairSync();} 1234// 传入true则是公平模式，false是非公平模式public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 获取锁 1234// 不可中断public void lock() { sync.lock();} 1234// 可中断public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1);} 12345// 尝试获取锁，注意这个哦，不管是公平锁还是非公平锁// tryLock都是直接非公平的，毕竟就试一下public boolean tryLock() { return sync.nonfairTryAcquire(1);} 12345// 带超时时间的尝试获取锁public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout));} 释放锁 123public void unlock() { sync.release(1);} 创建condition 123public Condition newCondition() { return sync.newCondition();} 查看当前线程持有锁数量 123public int getHoldCount() { return sync.getHoldCount();} 查看当前线程是否是排它锁持有者 123public boolean isHeldByCurrentThread() { return sync.isHeldExclusively();} 是否锁住 123public boolean isLocked() { return sync.isLocked();} 是否是公平锁 123public final boolean isFair() { return sync instanceof FairSync;} 获取属主 123protected Thread getOwner() { return sync.getOwner();} 查看是否还有线程在排队 123public final boolean hasQueuedThreads() { return sync.hasQueuedThreads();} 查看等待队列长度 123public final int getQueueLength() { return sync.getQueueLength();} 查看还在等待的线程 123protected Collection&lt;Thread&gt; getQueuedThreads() { return sync.getQueuedThreads();} 查看某一条件下是否还有线程在等待 1234567public boolean hasWaiters(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);} 查看条件队列长度 1234567public int getWaitQueueLength(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);} 获取在条件队列上等待的线程 1234567protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);} 从上面的方法在可以看到，几乎所有的操作都是委托给了sync对象，这也就意味着真正的操作其实是sync 在接着往下看之前，我们先来回忆一下AQS，AQS中提供了众多的tryXXX方法，用于子类实现对应的尝试获取 操作，也就是说，子类决定了能否获取锁，如果不能，那么剩下的就是AQS的事情了，同样的，释放锁的操作也是如此 SyncSync是ReentrantLock的内部类，继承了AQS，提供了ReentrantLock的所有功能，有两个子类，FairSync和NonfairSync，分别提供公平锁和非公平锁的实现 Sync是一个抽象类，把公平锁跟非公平锁公有的逻辑都实现了，大部分的功能都是直接调用AQS的方法来实现 Sync本身的代码不长，我们就直接分析了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; abstract void lock(); // 非公平锁的获取 final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 如果没有人获取 if (c == 0) { // 既然是非公平，那就不管有没有人排队了，直接上 // 能抢到就是我的了 if (compareAndSetState(0, acquires)) { // 设置自己为排它锁所有者 setExclusiveOwnerThread(current); return true; } } // 如果是重入，那就直接获取到了 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } // 获取失败 return false; } // 尝试释放锁 // 公平锁跟非公平锁的释放是一样的，所以在父类实现了 // relase会先调用tryRelase(),try成功了就唤醒下一个节点 protected final boolean tryRelease(int releases) { int c = getState() - releases; // 如果当前线程不是排它锁的获取，那就是非法操作了 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果c==0，意味着锁可以完全释放了，否则就是重入 if (c == 0) { free = true; setExclusiveOwnerThread(null); } // 重新设置下锁状态 setState(c); return free; } // 当前线程是否是排它锁的获取者 protected final boolean isHeldExclusively() { return getExclusiveOwnerThread() == Thread.currentThread(); } // 获取Condition对象 final ConditionObject newCondition() { return new ConditionObject(); } // 获取当前锁的属主 final Thread getOwner() { return getState() == 0 ? null : getExclusiveOwnerThread(); } // 获取当前持有的资源数，只有是排它锁的持有者才能获取得到 final int getHoldCount() { return isHeldExclusively() ? getState() : 0; } // 锁是否已经被获取了 final boolean isLocked() { return getState() != 0; } // 用于序列化的 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); setState(0); // reset to unlocked state }} 有了前面AQS的分析，这里分析起来就轻松多了 FairSync123456789101112131415161718192021222324252627282930313233343536// 公平锁实现static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; // 可以看到，lock方法其实就是调用了AQS的acquire方法 // 回忆一下，AQS的acquire会先调用tryAcquire final void lock() { acquire(1); } // tryAcquire protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 没有人在执行 if (c == 0) { // 既然是公平，那就得看一下有没有人在排队了 // 如果有，那获取失败，老老实实排队去 // hasXXX是来自AQS的方法，见下面分析 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 重入 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; }} hasQueuedPredecessors 12345678910111213// 公平锁实现的核心，就是先看下有没有人在排队public final boolean hasQueuedPredecessors() { Node t = tail; Node h = head; Node s; // 如果h != t说明队列有元素，有两种情况 // 1. head刚刚初始化(回忆一下AQS的enq方法)，有人在执行初始化操作 // 2. 已经有元素在排队了 return h != t &amp;&amp; // h.next == null说明有人在执行初始化的入队操作，说明有人了 // s.thread 不是自己，也说明有人了 ((s = h.next) == null || s.thread != Thread.currentThread());} 可以看到，有了AQS之后，一个公平锁的实现是非常简单的，只需要实现一个tryAcquire一个tryRelease就可以了 NonfairSync前面我们提到，ReentrentLock默认的实现就是非公平锁，在看Sync的时候，我们也看到了一个名为nonfairTryAcquire的方法，隐约中已经可以猜测得到该方法就是非公平锁获取锁的实现了 1234567891011121314151617static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; // 非公平，那就先抢一下，抢到了就是我的了 final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); // 抢不到就调用acquire else acquire(1); } // 直接通过nonfairTryAcquire protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }} 到这里，非公平锁的分析就结束了，有木有一种挖槽的感觉，这实现居然如何简洁 小结ReentrantLock是JDK1.5提供的另一种锁的实现，支持重入，支持公平锁、非公平锁。 其实际操作是委托给内部类 Sync，Sync是基于AQS实现的同步对象，包含两个子类，FairSync、NonfairSync，分别对应的就是公平锁、非公平锁 从这里我们就可以看出了，对于一个锁的实现，只需要继承AQS，然后实现其tryLock、tryRelease方法就足够了，这也是AQS设计的初衷 CountdownLatchCountdownLatch同样是JDK1.5提供的并发工具，不过用途则与ReentrantLock不同 CountdownLatch翻译过来是栅栏，用于是实现一部分线程等待另一部分线程完成工作，然后再继续往下执行任务的场景，最典型的用途就是异步转同步 使用下面的例子演示了如何使用CountdownLatch来实现线程相互等待(异步转同步)的功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Slf4jpublic class CountdownLatchTest { public static void main(String[] args) { int threadNum = 5; CountDownLatch startLatch = new CountDownLatch(1); CountDownLatch finishLatch = new CountDownLatch(threadNum); for (int i = 0; i &lt; threadNum; i++) { Thread thread = new Thread(new Task(startLatch, finishLatch)); thread.start(); } try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException ignored) {} log.info(&quot;main: everyone start working....&quot;); // 开始打开栅栏 startLatch.countDown(); log.info(&quot;main: waiting for job finish&quot;); try { // 等待所有任务完成 finishLatch.await(); } catch (InterruptedException ignored) { } // main的其他工作本来与其他任务是并行，现在只有工作任务完成了才会进行到这里 // 也就是将原本异步的任务转为了同步 log.info(&quot;main: all job done&quot;); } static class Task implements Runnable { private CountDownLatch startLatch; private CountDownLatch finishLatch; public Task(CountDownLatch startLatch, CountDownLatch finishLatch) { this.startLatch = startLatch; this.finishLatch = finishLatch; } @Override public void run() { Thread thread = Thread.currentThread(); log.info(&quot;thread: [{}] is waiting start signal&quot;, thread); try { // 所有线程等待开始 startLatch.await(); } catch (InterruptedException ignored) { } log.info(&quot;thread: [{}] start working...&quot;, thread); Random random = new Random(); try { TimeUnit.SECONDS.sleep(random.nextInt(10)); } catch (InterruptedException ignored) { } log.info(&quot;thread: [{}] finish working...&quot;, thread);truetruetruetrue // 线程完成任务 finishLatch.countDown(); } }} 再举一个例子，调用一个方法，该方法通过线程去拉取数据，只有拉取数据任务结束，该方法才返回，这个时候CountdownLatch就非常重要了，只需要启动线程之后，执行await()等待，线程完成之后通过countdown()打开栅栏就可以实现我们的想法了，简洁而高效 分析按照老惯例，分析下CountdownLatch的实现，通过上面的说明，我们已经知道了是基于AQS实现的，并且，可以被多个线程同时持有，那就是共享模式无疑了 签名及属性签名 12public class CountDownLatch {} 属性 1private final Sync sync; 看到这里，是不是有种似曾相似的感觉，跟ReentrantLock灰常相似 方法 构造方法 1234public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count);} 等待 123public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1);} 带超时时间的等待 1234public boolean await(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));} 打开闭锁 123public void countDown() { sync.releaseShared(1);} 获取当前计数 123public long getCount() { return sync.getCount();} CountdownLatch锁提供的方法相对来说比较少，可以看到，基本上也是委托给了sync 在接着往下之前，先回忆一下，AQS中，共享模式跟独占模式是很相似的，都是要求子类实现tryXX方法，不同的是，共享模式是实现tryXXXShared而独占模式是实现tryXX Sync1234567891011121314151617181920212223242526272829303132333435363738// 同样的，继承AQSprivate static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; // 使用count来初始化AQS Sync(int count) { setState(count); } // 获取数量，其实就是获取state的值 int getCount() { return getState(); } //回忆一下，AQS中acquireShared/acquireSharedInterruptibly会到调用该方法 // 该方法返回&gt;0表示可以获取，&lt;0表示获取失败 // 结合前面await，可以猜到，当state==0时，await操作成功，即“获取到锁” protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } // 释放，再回忆一下AQS的releaseShared protected boolean tryReleaseShared(int releases) { // 自旋释放 for (;;) { int c = getState(); // 如果c==0，说明是独占形式了，不能释放 if (c == 0) return false; int nextc = c-1; // 如果资源个数为0，说明可以释放锁了 // 释放之后，就会执行unpark操作了，从而将await的线程唤醒 // 由于是共享，所以所有await的线程都会被唤醒 if (compareAndSetState(c, nextc)) return nextc == 0; } }} 到了这里CountdownLatch的分析就结束了，可以看到，有了AQS，一切的操作就变得非常简单了 小结分析完了CountdownLatch之后，我们可以直观地看到，实现一个并发安全的共享类型的同步工具，同样只需要实现tryAcquireShared以及tryReleaseShared，其他的直接交给AQS就可以了，AQS真好 SemaphoreSemaphore是我们分析的第三个基于AQS的同步工具 Semaphore，翻译过来是信号量，本身维护了一组凭证，代表可用资源数量，当需要使用的时候，先向Semaphore申请，使用完毕之后归还，如果资源无法满足，则挂起该线程，等待有足够的资源 根据上面的描述，可能会觉得很熟悉，跟锁很相似，确实，凭证数量为1的信号量就退化成了锁了，也可以将Semaphore理解为多元锁 Semaphore是基于共享模式实现的，提供了公平模式与非公平模式的支持 使用Semaphore的使用也是比较简单的，主要就是资源的申请acquire以及释放release 12345678910111213141516171819202122232425262728293031323334353637383940public class SemaphoreTest { public static void main(String[] args) { // 凭证总数量为4个 Semaphore semaphore = new Semaphore(4); for (int i = 0; i &lt; 10; i++) { new Thread(new Task(semaphore)).start(); } } static class Task implements Runnable { private Semaphore semaphore; public Task(Semaphore semaphore) { this.semaphore = semaphore; } @Override public void run() { log.info(&quot;try to get resource&quot;); try { // 每次申请一个 // 所以在当前系统中，最多同时有4个任务获取到凭证 semaphore.acquire(); } catch (InterruptedException ignored) { } log.info(&quot;get the resource&quot;); Random random = new Random(); try { TimeUnit.SECONDS.sleep(random.nextInt(10)); } catch (InterruptedException ignored) {} log.info(&quot;finish job, release resource&quot;); // 归还资源 semaphore.release(); } }} 分析签名及属性签名 12public class Semaphore implements java.io.Serializable {} 属性 1private final Sync sync; 咦，好面熟 方法 构造方法 123public Semaphore(int permits) { sync = new NonfairSync(permits);} 123public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits);} permits，即凭证，是必须的，默认情况下是非公平模式，与ReentrentLock相似 获取一个凭证 123public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1);} 获取多个凭证 1234public void acquire(int permits) throws InterruptedException { if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits);} 不可中断获取凭证 123public void acquireUninterruptibly() { sync.acquireShared(1);} 不可中断多个凭证 1234public void acquireUninterruptibly(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireShared(permits);} 尝试获取凭证 123public boolean tryAcquire() { return sync.nonfairTryAcquireShared(1) &gt;= 0;} 尝试获取多个凭证 1234public boolean tryAcquire(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); return sync.nonfairTryAcquireShared(permits) &gt;= 0;} 带超时时间的尝试获取凭证 1234public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));} 超时时间多个凭证 12345public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { if (permits &lt; 0) throw new IllegalArgumentException(); return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));} 释放凭证 123public void release() { sync.releaseShared(1);} 释放多个凭证 1234public void release(int permits) { if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits);} 查看可用凭证 123public int availablePermits() { return sync.getPermits();} 缩减凭证 1234protected void reducePermits(int reduction) { if (reduction &lt; 0) throw new IllegalArgumentException(); sync.reducePermits(reduction);} 释放所有凭证，返回当前可用凭证 123public int drainPermits() { return sync.drainPermits();} 可以看到，其实是满满的套路，所有的操作同样委托给了Sync SyncSync是Semaphore中的核心，Sync是一个抽象类，提供了Semaphore中通用的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 1192457210091910933L; // 可以看到，通过permits来初始化state Sync(int permits) { setState(permits); } final int getPermits() { return getState(); } // 非公平锁的获取 // 一直自旋，直到获取成功或者资源不足 final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; // 资源不足，立即返回 // 资源足够，CAS失败，说明有竞争，继续试一下就行 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } } // 尝试释放 // 自旋，直到释放成功 protected final boolean tryReleaseShared(int releases) { for (;;) { int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; } } // 缩减，其实就是重新设置state final void reducePermits(int reductions) { for (;;) { int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error(&quot;Permit count underflow&quot;); if (compareAndSetState(current, next)) return; } } // 清空，其实就是将其设置为0 final int drainPermits() { for (;;) { int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; } }} Sync就没啥好说的啦，看一下代码大概就清楚了 FairSync12345678910111213141516171819202122// 公平模式static final class FairSync extends Sync { private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) { super(permits); } protected int tryAcquireShared(int acquires) { for (;;) { // 既然是公平模式，那就先看先有没有人排队 // 有就说明获取失败，需要排队 if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } }} 套路啊套路 NonfairSync1234567891011static final class NonfairSync extends Sync { private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) { super(permits); } protected int tryAcquireShared(int acquires) { return nonfairTryAcquireShared(acquires); }} 小结Semaphore提供了一种限制资源获取的方式，只有先获取到对应的凭证，才能接着操作，基于AQS的共享模式实现，提供了公平模式、非公平模式 如果从上一篇文章跟下来，看到这里，大概只有一个想法了，AQS是真的强 CyclicBarrier习惯了上面三个工具的分析模式，可能会觉得，CyclicBarrier已经没有分析的必要了，如果这样想，那可能就会错过了很有趣的CyclicBarrier CyclicBarrier，翻译过来是循环栅栏，对，同样也是栅栏，所以从概念上来说，是与CountdownLatch类似的功能，也是用于线程的同步，只不过，两者的目标不一样 CountdownLatch主要是针对多个不同任务之间进行协作的，如任务A需要等待任务B完成之后再接着运行 CyclicBarrier是针对同一类型任务的，只有所有任务都到达某个点之后，这些任务才接着继续执行 需要区分好两者的使用场景 使用下面这里例子，表达的就是前面所举的例子了，所有线程先执行任务，所有到达A点之后，栅栏才会打开，然后执行第二个任务，同时到达之后，完成任务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Slf4jpublic class CyclicBarrierTest { public static void main(String[] args) { int threadNum = 10; // 初始化参与人数，以及每个任务完成之后的操作 CyclicBarrier barrier = new CyclicBarrier(threadNum, new Runnable() { @Override public void run() { log.info(&quot;all job done&quot;); } }); for (int i = 0; i &lt; threadNum; i++) { new Thread(new Task(barrier)).start(); } } static class Task implements Runnable { private CyclicBarrier cyclicBarrier; public Task(CyclicBarrier cyclicBarrier) { this.cyclicBarrier = cyclicBarrier; } @Override public void run() { Thread thread = Thread.currentThread(); Random random = new Random(); log.info(&quot;thread: [{}] start running...&quot;, thread); try { TimeUnit.SECONDS.sleep(random.nextInt(10)); } catch (InterruptedException ignored) {} log.info(&quot;thread: [{}] at pointA, waiting...&quot;, thread);truetruetruetrue // 我的第一任务到达，等待其他人完成 try { cyclicBarrier.await(); } catch (InterruptedException e) { log.error(&quot;IE&quot;, e); } catch (BrokenBarrierException e) { log.error(&quot;broken &quot;, e); } log.info(&quot;thread: [{}] start another job&quot;, thread); try { TimeUnit.SECONDS.sleep(random.nextInt(10)); } catch (InterruptedException ignored) {} // 我的第二任务到达，等待其他人完成 try { cyclicBarrier.await(); } catch (InterruptedException e) { log.error(&quot;IE&quot;, e); } catch (BrokenBarrierException e) { log.error(&quot;broken &quot;, e); } // 完成所有任务 log.info(&quot;thread: [{}] finish job&quot;, thread); } }} 从示例中就可以看出，只有一个阶段的CyclicBarrier，其实就是一个CountdownLatch啦 分析签名及属性签名 12public class CyclicBarrier {} 属性 12345678910// 惊不惊喜，意不意外，居然不是Sync了private final ReentrantLock lock = new ReentrantLock();// 等待其他人完成private final Condition trip = lock.newCondition();// 参与人数private final int parties;// 所有线程到达之后执行的任务private final Runnable barrierCommand;// 当前年代，也称为当前阶段private Generation generation = new Generation(); 看到这里，是不是有种被坑的感觉，这明明就没有AQS的身影，怎么可以放在这里呢，咳咳，请注意ReentrantLock以及lock.newConditoin() 从这里就可以看出，CyclicBarrier是通过ReentrantLock以及Condition来实现的，小样，本质还是一样的，只会比继承AQS更加简单 大致上我们已经可以猜出来了，通过ReentrantLock进行访问的限制，通过Condition进行条件的等待 Generation 12345// 记录阶段的，每个阶段对应一个Generation对象private static class Generation { // 记录当前阶段是否已经被打破了，也即CyclicBarrier是否被打破 boolean broken = false;} 方法 构造方法 1234567// 参与人数以及全体到达之后需要执行的任务public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;} 123public CyclicBarrier(int parties) { this(parties, null);} 自己已到达，等待别人完成 12345678public int await() throws InterruptedException, BrokenBarrierException { try { // false代表不设置超时 return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen }} 1234567public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException { // 带超时时间的版本 return dowait(true, unit.toNanos(timeout));} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; // 先持有锁 lock.lock(); try { final Generation g = generation;truetrue// 判断一下当前CyclicBarrier是否已经被打破了 // 如果是，则抛出BrokenBarrierException异常 if (g.broken) throw new BrokenBarrierException(); // 检查一下是否发生了中断 // 如果发生了中断，则打破栅栏 // 并且抛出InterruptedException if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } // 到这里的话，说明一切正常 int index = --count; // 如果count等于0，说明最后一个任务已经到达 // 可以唤醒其他人了 if (index == 0) { boolean ranAction = false; try { final Runnable command = barrierCommand; // 如果有任务需要执行，就由当前线程负责执行 if (command != null) command.run(); ranAction = true; // 为下一轮做准备 nextGeneration(); return 0; } finally { // 如果执行终结任务发送问题 // 那就打破栅栏 if (!ranAction) breakBarrier(); } } // 到这里，说明要么不是最后一个任务，要么执行终结任务过程出错了 // 一直等待，直到正常结束或者异常退出 for (;;) { try { // 还记得这一行代码吗 // private final Condition trip = lock.newCondition(); // 如果没有设置超时，那么就一直等待就行了 if (!timed) trip.await(); // 如果设置了超时，时间还没到，那就进行超时等待 else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { // 如果等待过程发生中断 // 1.如果还在当前这一年代，并且没有被打破 // 那就打破，并且抛出异常 if (g == generation &amp;&amp; ! g.broken) { breakBarrier(); throw ie; } else { // 如果已经到了下一代，说明是最后一个任务已经执行完成 // 已经有人执行完nextGeneration，睡过了头？？？ // 直接发信号告诉当前线程就行了 Thread.currentThread().interrupt(); } }truetruetrue // 如果醒来后发现已经被打破了，那就抛出异常 if (g.broken) throw new BrokenBarrierException(); // 如果年代已经变了，说明已经正常结束了 // 那就应该跳出循环了 if (g != generation) return index; // 设置了超时时间，并且时间已经过去了 // 那就是等待超时了 if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } // 还记得这里吗，在finally释放锁哦 } finally { lock.unlock(); }} 调整到下一代 123456789private void nextGeneration() { // 唤醒全部等待的线程 // 此时已经获取了锁，所以不必重新获取了 trip.signalAll(); // 重置计数器 count = parties; // 新建一个年代器 generation = new Generation();} 打破 1234567private void breakBarrier() { // 打破了 generation.broken = true; count = parties; // 唤醒全部 trip.signalAll();} 查看是否已经打破 12345678910public boolean isBroken() { final ReentrantLock lock = this.lock; // 需要先获取锁 lock.lock(); try { return generation.broken; } finally { lock.unlock(); }} 重置Barrier 123456789101112public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { // 先打破 breakBarrier(); // 在进行到下一代，表示重置 nextGeneration(); } finally { lock.unlock(); }} 获取等待的线程数量 1234567891011public int getNumberWaiting() { final ReentrantLock lock = this.lock; lock.lock(); try { // parties是总数，count是已经减少的 // 两者之差就是还在等待的 return parties - count; } finally { lock.unlock(); }} 小结好了，到这里，基本上关于CyclicBarrier的分析就结束了，从上面的分析中可以看出，CyclicBarrier本身是通过ReentrantLock以及Condition来实现的，本身实现难度不高，但却非常的巧妙 CyclicBarrier的使用也是非常简单的，与CountdownLatch的使用场景有点微妙的区别，使用时千万注意两者的区别 总结好了，到这里，关于四个常用的基于AQS的同步工具的分析就结束了 这篇文章详细地介绍了四个常用的基于AQS的同步工具，包括了其使用的场景，源码的分析，通过源码的分析，我们可以看到，基于AQS的同步器的实现是比较简单的，只需要根据所要实现的同步器的类型(共享模式、独占模式)选择继承的方法tryXX、tryXXShared就能够实现一个安全的、可靠的同步器了 相信通过这两篇文章的分析，你能更好地理解AQS的设置，已经对应工具的实现原理，在后面开发过程中，能更好地应用这些工具 当然了，关于AQS的工具还远远不止这些，后面有时间的话，我会再写一篇文章，分析其他几个也非常好用的工具，这里先挖个坑","link":"/2019/11/25/AQS%E4%B9%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"title":"Java容器之Map(JDK1.6)","text":"Java容器之Map(JDK1.6) Map是Java众多容器家族中一个重要的成员…. Map一个数据结构，对于数据结构而言，最重要的其实就是数据的组织形式，也就是数据在该结构中如何存放，其组织形式也最终决定了其功能、性能，其核心点在于初始化、增加元素、查找元素、删除元素等方面，因此，下面的内容都是围绕这些核心点进行展开 Map接口是Java容器框架重要的一员，其核心是将一个key映射为value，其中key必须是一个可序列化的类型，而value则没有限制，根据实现的不同，Map有几个重要的子类，如 基于Hash算法的HashMap，提供了接近O(1)的查找、修改、删除性能 同样基于Hash算法，并且提供插入顺序或者访问顺序获取的LinkedHashMap 同样基于Hash算法，并且具备并发性能的ConcurrentHashMap 基于红黑树，提供了基于key排序的TreeMap等 当然，此外还有很多基于其他算法的Map，不过最常用到的也就是上面的几种了，这篇文章大致分析了这几个实现的代码包括了结构特点，初始化、插入、查找、删除等 这篇文章基于JDK1.6，原因是1.6的代码比较直观，没有过多的为了性能优化而简化的逻辑，相对来说比较适合入门分析，之后会抽时间再分析1.7、1.8的实现 HashMap核心概念容量：HashMap中桶的数量，默认是16 装填因子：HashMap中元素个数与总大小的比值，默认是0.75f 阈值：当HashMap中元素个数达到某个值时，进行扩容，该值称为阈值(threshold)，数值上=容量*装填因子 结构及特点HashMap是Map的一个实现，其内部结构是一个Entry数组构成的基于链式冲突解决法的hash结构实现，Entry是key-value组成的一个有序对 允许key、value为null，如果key是null，则放置在第一个桶(0号桶)中 初始化HashMap有四种初始化方式，对应四个构造器 无参构造器：使用默认的装填因子、容量、阈值 带容量构造器：使用自定义容量而不是默认容量 带容量、装填因子构造器：使用自定义容量、状态因子初始化 通过其他Map进行初始化 每种初始化方式都会直接或者间接调用一个空方法init()，该方法是一个钩子方法，用于子类进行初始化后进行某个特殊的定制操作 其中1、2、3初始化方式类似，只是2、3进行多了参数校验，校验容量是否符合规定(2的X次方)，是否超过最大值，装填因子是否合法等，然后初始化table，也就是桶的大小 方式4比较特殊，是直接从其他的Map进行初始化的，包含了两步 通过map的大小来计算容量，然后调用3使用默认装填因子进行初始化 将map的元素一个个添加到新的Map中：核心代码在putAllForCreate这个方法中，如下分析 putAllForCreate 12345678private void putAllForCreate(Map&lt;? extends K, ? extends V&gt; m) { // 通过Map的entrySet迭代器进行entrySet的迭代 for (Iterator&lt;? extends Map.Entry&lt;? extends K, ? extends V&gt;&gt; i = m.entrySet().iterator(); i.hasNext(); ) { // 对于每一个entry，调用putForCreate将其添加到Map中 Map.Entry&lt;? extends K, ? extends V&gt; e = i.next(); putForCreate(e.getKey(), e.getValue()); }} putForCreate 123456789101112131415161718192021private void putForCreate(K key, V value) { // 如果key是null，则将其hash值设置为0，放置在0号桶中，如果不是，则计算其hash值 int hash = (key == null) ? 0 : hash(key.hashCode()); // 计算该hash值在桶中的位置 int i = indexFor(hash, table.length); // 从目标桶的第一个元素触发，遍历该链上的每个元素 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; // 如果哈希值相等，并且key不为null并且相等，则将该值设置为对应的值，即替换更新 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { e.value = value; return; } }true // 如果在桶中没找着，则将其插入该桶中 createEntry(hash, key, value, i);} createEntry 1234567void createEntry(int hash, K key, V value, int bucketIndex) {true// 获取头节点 Entry&lt;K,V&gt; e = table[bucketIndex]; // 将新增节点作为头结点，并且将原来的头结点设置为当前节点的下一个节点 table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); size++;} indexFor 1234static int indexFor(int h, int length) { // 这里直接使用位运算，提高处理速度，也是桶数量必须是2的倍数的原因所在 return h &amp; (length-1);} 添加元素添加元素有两种方式 添加一个元素：put 添加多个元素：putAll put 12345678910111213141516171819202122232425262728public V put(K key, V value) { // 如果key是null，则走独立的处理逻辑-&gt;放在0号桶 if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); // 可以看到，这里跟putForCreate的处理逻辑是类似的 // 找到目标的桶，然后遍历一下，看看这个桶所在的链上有没有相同的元素，有就替换，没有就添加 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; // 关注下这里，这是LinkedHashMap实现的核心 e.recordAccess(this); return oldValue; } } modCount++; // 这里不是使用前面的createEntry()原因在于createEntry只会在初始化的时候调用，此时已经&quot;扩容&quot;好了 // 而put的时候，不一定扩容好 addEntry(hash, key, value, i); return null;} putForNullKey 1234567891011121314private V putForNullKey(V value) { // 直接从零号桶遍历列表，找到key=null的 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null;} addEntry 1234567891011void addEntry(int hash, K key, V value, int bucketIndex) { // 拿到当前的桶 Entry&lt;K,V&gt; e = table[bucketIndex]; // 新建entry并且将其插入到头部(链表的头插法) table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); // 如果此时大于阈值，那么就扩容(hashMap中很重要的一个知识点) // 扩容是指桶扩容，为原来的2倍 if (size++ &gt;= threshold) resize(2 * table.length);} resize 123456789101112131415161718void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; // 检查是否超过最大容量 if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; }true // 新建桶 Entry[] newTable = new Entry[newCapacity]; // 将旧桶的数据复制到新桶上 transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);} transfer 123456789101112131415161718192021222324void transfer(Entry[] newTable) { Entry[] src = table; int newCapacity = newTable.length; // 遍历每个桶 for (int j = 0; j &lt; src.length; j++) { Entry&lt;K,V&gt; e = src[j]; // 遍历桶上的整个链 if (e != null) { src[j] = null; do { // 重新计算桶的位置，这里同样采用的是头插法 // 这里需要特别注意 // hashMap中著名的多线程导致的CPU空转(CPU狂飙且无法停止)就是在这里发生的 // 见下面分析 Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } }} 空转问题的发生过程可以参考下面的图，其实，本质上就是因为并发导致的指针指向反转，从而造成了指针收尾相接，造成死循环 putAll 123456789101112131415161718192021222324252627public void putAll(Map&lt;? extends K, ? extends V&gt; m) { int numKeysToBeAdded = m.size(); if (numKeysToBeAdded == 0) return; // 注意这里不是m.size + size &gt; threshold // 原因在于，如果m里头的元素都跟现有map一样，那就会扩容多一倍的空间 if (numKeysToBeAdded &gt; threshold) { // 计算新加入的key所需要的桶数量 int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1); if (targetCapacity &gt; MAXIMUM_CAPACITY) targetCapacity = MAXIMUM_CAPACITY; int newCapacity = table.length; // 如果大于现有桶的数量，则进行扩容 while (newCapacity &lt; targetCapacity) newCapacity &lt;&lt;= 1; if (newCapacity &gt; table.length) resize(newCapacity); } // 迭代entry，一个个加入map for (Iterator&lt;? extends Map.Entry&lt;? extends K, ? extends V&gt;&gt; i = m.entrySet().iterator(); i.hasNext(); ) { Map.Entry&lt;? extends K, ? extends V&gt; e = i.next(); put(e.getKey(), e.getValue()); }} 查找元素看完了添加元素，其实查找元素就基本上知道是怎么处理了，无非就是先计算key所在的哈希桶，然后遍历该链表，看是否存在，如果存在，返回对应的value，不存在返回null get 123456789101112131415public V get(Object key) { // 如果是key是null，则从零号桶中查找元素 if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; } return null;} getForNullKey 1234567private V getForNullKey() { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) return e.value; } return null;} 此外，HashMap还提供一个用于检查是否包含某个值的方法 containsValue 123456789101112public boolean containsValue(Object value) { if (value == null) return containsNullValue(); Entry[] tab = table; // 其实就是遍历每个桶的链表 for (int i = 0; i &lt; tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (value.equals(e.value)) return true; return false;} 删除元素删除元素包含两个步骤 查找目标元素 将找到的目标元素从链表中移除 remove 1234public V remove(Object key) { Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value);} removeEntryForKey 1234567891011121314151617181920212223242526272829303132333435final Entry&lt;K,V&gt; removeEntryForKey(Object key) { int hash = (key == null) ? 0 : hash(key.hashCode()); int i = indexFor(hash, table.length); // 通过两个指针的位置变化来实现链表的元素删除 Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) { Entry&lt;K,V&gt; next = e.next; Object k; // 如果e所指向的元素就是目标元素 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { modCount++; size--; // 如果此时e是第一个元素，那么直接用next替换table[i]就行 // 如果是中间元素，就通过前一个节点的next=当前节点的next来跳过当前节点 if (prev == e) table[i] = next; else prev.next = next; // 留意下这个空方法 e.recordRemoval(this); return e; } prev = e; e = next; } return e;} LinkedHashMap结构及特点LinkedHashMap是HashMap的一个变种，提供了“有序的”Map能力(本质上是通过额外的指针将所有元素根据指定顺序串联起来，在HashMap中维护多了一个双端链表结构)，HashMap中遍历得到的结果是无序的，而LinkedHashMap则能够提供基于访问/添加的顺序的能力，如按照插入的顺序，或者访问的顺序来获取元素，通过参数：accessOrder来控制，可以用LinkedHashMap来实现一个简单的单线程版本的LRU Cache 类签名： 123456public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt;{} 核心概念由于LinkedHashMap直接继承自HashMap，所以基本同HashMap LinkedHashMap中增加了一个类型为Entry的header元素，用于获取顺序元素的起始点，此外Entry结构比HashMap的多了两个指针：before、after，用于维护既定顺序 初始化LinkedHashMap提供了五种方式来初始化 指定初始容量、装填因子，同时指定元素顺序为插入顺序 指定初始容量，顺序为插入顺序 采用默认参数，顺序为插入顺序 从其他的Map进行构造，顺序为插入顺序 指定初始容量、装填因子、顺序(true：访问顺序，false：插入顺序) 此外，从前面的HashMap初始化方法中知道，每种方式都会直接或者间接调用init()方法来实现子类自己的定制化需求，而LinkedHashMap就用到了这个特性 init 123456void init() { // 初始化header节点(链表的头结点) header = new Entry&lt;K,V&gt;(-1, null, null, null); // 初始化header的前后节点信息 header.before = header.after = header;} 添加元素添加元素本身是直接用父类，也就是HashMap的方法，此外，利用了前面我们提到的e.recordAccess(this);来实现按照访问顺序改变节点顺序 Entry#recordAccess 12345678910void recordAccess(HashMap&lt;K,V&gt; m) { LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) { lm.modCount++; // 将当前节点从链表中移除 remove(); // 然后将当前节点添加到header前面，成为第一个元素 addBefore(lm.header); }} 同时，前面也看到了createEntry以及addEntry这两个方法，分别用于从其他Map构造的时候使用以及put的时候使用，LinkedHashMap重写了这两个方法，用于实现记录链表顺序 createEntry 12345678void createEntry(int hash, K key, V value, int bucketIndex) { HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(hash, key, value, old); table[bucketIndex] = e; // 注意这里，将e添加到header前面(头插法)，于是就成为第一个元素 e.addBefore(header); size++;} addEntry 123456789101112131415161718void addEntry(int hash, K key, V value, int bucketIndex) { // 先将新元素插入到头节点 createEntry(hash, key, value, bucketIndex); // 然后判断是否需要提出最末尾的元素 // header是双端链表的头结点，所以header.after就是链表的末尾节点 // 如果需要，则移除，不需要则检查是否需要扩容 Entry&lt;K,V&gt; eldest = header.after; // 钩子方法，默认是false，LRU的核心 if (removeEldestEntry(eldest)) { removeEntryForKey(eldest.key); } else { if (size &gt;= threshold) resize(2 * table.length); }} removeEldestEntry 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return false;} 在前面我们看到了，如果需要resize的时候，会通过transfer函数来实现扩容的实际操作，这里LinkedHashMap同样覆盖了该方法，提供了自己的实现 transfer 1234567891011void transfer(HashMap.Entry[] newTable) { int newCapacity = newTable.length; // 直接遍历双端链表，一个个元素重新插入即可，注意，此时链表本身的顺序没有改变 // 也就是说，扩容操作不会影响LinkedHashMap的顺序 for (Entry&lt;K,V&gt; e = header.after; e != header; e = e.after) { int index = indexFor(e.hash, newCapacity); e.next = newTable[index]; newTable[index] = e; }} 查找元素LinkedHashMap获取元素的方式与HashMap大同小异，只是多了一些额外的操作 get 123456789public V get(Object key) { // 获取节点,父类方法 Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; // 注意这里，如果是访问顺序，那么这里会移动节点 e.recordAccess(this); return e.value;} 此外LinkedHashMap同样覆盖了containsValue方法，提供的是从header出发遍历的方式来实现检查某个值是否在map中 删除元素LinkedHashMap中移除元素采用的是父类的方法，只不过在移除的时候，需要多移除双端链表的元素，通过recordRemoval方法来实现 LRU Cache的简单实现LRU全称是Least Recently Used，即最近最少未使用，根据最后一次使用的时间来淘汰数据的缓存过期策略，在看完了LinkedHashMap的实现逻辑之后，我们可以非常方便地使用LinkedHashMap来实现一个单线程版本的简单的LRU 123456789101112131415class SimpleLruCache extends LinkedHashMap&lt;String, String&gt; { private int maxSize; public SimpleLruCache(int initialCapacity, float loadFactor, int maxSize) { // accessOrder 设置为true，表示切换为基于访问模式的LinkedHashMap super(initialCapacity, loadFactor, true); this.maxSize = maxSize; } @Override protected boolean removeEldestEntry(Map.Entry&lt;String, String&gt; eldest) { // 每次添加时检查一下，如果大于maxSize时，移除最后一个元素 return size() &gt; maxSize; }} ConcurrentHashMap结构及特点前面提到的HashMap和LinkedHashMap本身都不是线程安全的，在多线程环境下会出现各种奇奇怪怪的问题，虽然JDK在之前的版本中提供了HashTable这个工具，不过HashTable本身所有的方法都用synchronized进行修饰，这样就意味着无论是读写HashTable的并发度都为1，这在并发度比较高的情况下，性能相对较差 为了应对这个问题，JDK团队提供了ConcurrentHashMap，一个相对来说性能好一些，并且能基本上满足需求的近乎线程安全的hashMap，虽然ConcurrentHashMap也是以HashMap结尾，不过跟前面提到的HashMap本身没有直接的关系，只是他们两者的实现都是基于hash函数来实现散列功能 ConcurrentHashMap实现的原理也是比较好理解的，由于读本身不改变数据元素，不改变结构，所以在读取数据的时候，无需加锁，写操作本身会影响结构，所以需要加锁，但是由于Hash函数本身的特点，只有哈希值一样(哈希冲突)的才会在同一个桶中，所以，理论上来说，访问不同的桶是不相互影响的，也就是说，并发度可以提高到桶数量这个级别 除此之外，HashMap允许key、value为null，而ConcurrentHashMap则不允许 核心概念SegmentSegment是ConcurrentHashMap中用于并发管理的基本单元，Segment的数量等于并发度，Segment本身其实也是一个HashMap，只不过具备了并发访问控制能力，所以，在理解的时候，可以直接将其当做HashMap来理解即可，也就是说，其实ConcurrentHashMap是一个两级HashMap，第一级用于控制并发，第二级才是实际存储数据的地方 Segment结构： 12345678static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable { transient volatile int count; transient int modCount; // 阈值 transient int threshold; transient volatile HashEntry&lt;K,V&gt;[] table; final float loadFactor;} HashEntryHashEntry的结构与HashMap中的Entry基本一致，不过指针字段都用final修饰，确保了强一致性 1234567static final class HashEntry&lt;K,V&gt; { final K key; final int hash; // volatile修饰，保证可见性 volatile V value; final HashEntry&lt;K,V&gt; next;} ConcurrentHashMap ConcurrentHashMap的结构基本如上图所示，其中需要主义的就是Segment桶是用final修饰的，也就是说，创建完成之后，Segment桶不可变，并发度不可调整，但是Segment里头的哈希桶是可以变更的，也就意味着，哈希扩容是发生在Segment里边的哈希桶，而非Segment桶本身 初始化ConcurrentHashMap一共提供了五种初始化方式 采用默认的初始化容量(默认16)、装填因子(默认0.75)、并发度(默认16) 指定初始容量、其余使用默认 指定初始容量、装填因子、其余默认 指定上述三个参数 从其他Map初始化 前面四种方式最终都是通过4的形式进行初始化，代码如下 123456789101112131415161718192021222324252627282930313233343536373839public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // 将并发度调整为2的x次方 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) { ++sshift; ssize &lt;&lt;= 1; } // segmentShift是在计算Segement位置时hash code需要移动的位数 segmentShift = 32 - sshift; // 用于计算所在的Segment桶 segmentMask = ssize - 1; this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 这里是初始化时，每个Segment桶应该初始化的hash桶个数 // 其实就是总的个数/并发度，然后向上调整为最近的2的X次方 int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = 1; while (cap &lt; c) cap &lt;&lt;= 1; // 初始化每一个Segment for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);} 通过其他Map初始化，有两个步骤 通过4的方式先初始化桶 将map的数据逐个放到桶中(putAll方法) putAll 1234public void putAll(Map&lt;? extends K, ? extends V&gt; m) { for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue());} put 12345678// 这里key、value为null都会触发空指针异常public V put(K key, V value) { if (value == null) throw new NullPointerException(); int hash = hash(key.hashCode()); // 先计算segment桶的位置，然后委托segment进行put操作 return segmentFor(hash).put(key, hash, value, false);} segmentFor 12345final Segment&lt;K,V&gt; segmentFor(int hash) { // 哈希值先算术右移segmentShift，也就是移动32-并发度 // 得到的是前(并发度)位的数据，然后&amp;并发度，得到在Segment桶的个数 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];} Segment#put 12345678910111213141516171819202122232425262728293031323334353637383940414243V put(K key, int hash, V value, boolean onlyIfAbsent) { // 通过ReentrantLock的lock方法进行锁 // 确保同时只有一个线程在该Segment桶进行操作 lock(); try { int c = count; // 如果大于阈值，则扩容 if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; // 计算应所在的哈希桶 int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 遍历整条链表，看是否存在 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; // 如果存在 if (e != null) { oldValue = e.value; // 并且不是putIfAbsent，则更新该值 // 如果是，则忽略本次操作 if (!onlyIfAbsent) e.value = value; } else { // 如果不存在，就采用头插法，加入到链表中 oldValue = null; ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // write-volatile } return oldValue; } finally { // 释放锁 unlock(); }} rehash 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void rehash() { HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity &gt;= MAXIMUM_CAPACITY) return; // 创建一个新的hash桶，大小为原来的2倍 HashEntry&lt;K,V&gt;[] newTable = HashEntry.newArray(oldCapacity&lt;&lt;1); threshold = (int)(newTable.length * loadFactor); int sizeMask = newTable.length - 1; for (int i = 0; i &lt; oldCapacity ; i++) { HashEntry&lt;K,V&gt; e = oldTable[i]; // 如果原来的桶有元素 if (e != null) { HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; // 并且只有一个元素，则将其当做桶的第一个元素即可 if (next == null) newTable[idx] = e; else { // 如果有多个元素，由于桶大小是2的X次方，所以很大概率原来在同一个桶的元素 // resize之后还在同一个桶，如果是这种情况，那么可以减少HashEntry的创建了 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; // 从第一个元素开始，向后找，找出最后连续N个且在同一个新桶的元素 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) { int k = last.hash &amp; sizeMask; if (k != lastIdx) { lastIdx = k; lastRun = last; } } // 这最后N个元素都在同一个桶，直接放到新桶就行了 newTable[lastIdx] = lastRun; // 没有放到新桶的元素，一个个复制一份，然后塞进去 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) { int k = p.hash &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(p.key, p.hash, n, p.value); } } } } table = newTable;} 添加元素添加元素有三种方式 直接添加一个元素：put 直接从一个map中添加元素：putAll 如果不存在则放进去，存在则忽略：putIfAbsent 第三种方式是ConcurrentMap接口定义的，目的是为了解决并发环境下Check-And-Set(两个操作步骤)出现的数据不一致问题 putIfAbsent 1234567public V putIfAbsent(K key, V value) { if (value == null) throw new NullPointerException(); int hash = hash(key.hashCode()); // 注意这里，最后一个参数onlyIfAbsent是true，表示替换，前面分析了哦 return segmentFor(hash).put(key, hash, value, true);} 查找元素查找元素有多种方式 根据key获取元素，get 检查是否包含某个key，跟get类似，不分析了 检查是否包含某个value 获取当前大小 get 1234public V get(Object key) { int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash);} Segment#get 12345678910111213141516171819V get(Object key, int hash) { // 注意这里，get方法是没有获取锁的 if (count != 0) { HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) { // 找到了 if (e.hash == hash &amp;&amp; key.equals(e.key)) { V v = e.value; // 如果值非空，则直接返回 if (v != null) return v; // 否则，检查一下是否是因为指令重排序引起的(注意这里没有获取锁) return readValueUnderLock(e); } e = e.next; } } return null;} Segment#readValueUnderLock 123456789V readValueUnderLock(HashEntry&lt;K,V&gt; e) { // 可以看到，其实就是加个锁，重新获取 lock(); try { return e.value; } finally { unlock(); }} 检查是否包含某个值，这里稍微复杂一些 containsValue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public boolean containsValue(Object value) { if (value == null) throw new NullPointerException(); final Segment&lt;K,V&gt;[] segments = this.segments; int[] mc = new int[segments.length]; // 先尝试无锁获取，减少不必要的获取锁操作 for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) { int sum = 0; int mcsum = 0; // 遍历每个Segment for (int i = 0; i &lt; segments.length; ++i) { int c = segments[i].count; // 计算mcsum mcsum += mc[i] = segments[i].modCount; // 如果包含，则必定是包含，直接返回即可 if (segments[i].containsValue(value)) return true; } // 如果第一轮没有拿到数据，那么检查下是否是由于并发引起的 boolean cleanSweep = true; if (mcsum != 0) { for (int i = 0; i &lt; segments.length; ++i) { int c = segments[i].count; if (mc[i] != segments[i].modCount) { cleanSweep = false; break; } } } // 如果不是并发引起的，说明结果是正确的，就是不存在 if (cleanSweep) return false; } // 如果两轮都没得出正确结果，也就是都是因为并发引起的数据不正确，那么就加锁获取 for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); boolean found = false; try { for (int i = 0; i &lt; segments.length; ++i) { if (segments[i].containsValue(value)) { found = true; break; } } } finally { for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); } return found;} 或者size等操作与container基本类似，就不展开了 删除元素删除元素有两种操作 根据key删除 根据key、value删除，只有都匹配才删除 remove 1234public V remove(Object key) {int hash = hash(key.hashCode()); return segmentFor(hash).remove(key, hash, null); } Segment#remove 123456789101112131415161718192021222324252627282930313233343536V remove(Object key, int hash, Object value) { lock(); try { int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) { V v = e.value; if (value == null || value.equals(v)) { oldValue = v; ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; // 由于HashEntry中的next字段是final类型，所以目标节点前面的元素 // 没有办法跟hashMap一样，直接通过next = next.next来断开节点 // 只能是重新复制一份，然后重新链接回链表中 // 没有人链接的节点，即e，由于gc root不可达，所以会被gc for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; count = c; } } return oldValue; } finally { unlock(); }} TreeMap结构及特点JDK中的TreeMap是红黑树的实现，关于红黑树，可以先看下这篇[红黑树学习笔记](红黑树学习笔记 | 凌风的小窝 (xuhuanfeng.cn))，强烈建议读一下《Algorithm 4th》中相关的章节 TreeMap会对Key进行排序，也意味着，TreeMap是一个有序的Map，同时，为了维护顺序，必然也会带来一些性能的损耗(相比于HashMap) TreeMap实现了NavigableMap，提供了获取大于/小于某个key的Entry，获取降序map等等跟排序有关的能力，进一步扩充了Map本身的能力 核心操作TreeMap是一个红黑树，红黑树是BST的一个变种，所以TreeMap本身就是一个BST，那么对于TreeMap的各种操作，实际上就是对应BST的各种操作 在BST中，中序遍历得到的结果就是一个已经排好序的结果，而在TreeMap中，我们无论是通过迭代器，还是其他的方式获取Map的元素列表，最终其实都是在访问BST，并且是以中序的方式访问 在BST的访问中，有几个比较重要的操作，如获取第一个元素，获取最后一个元素，获取某个元素的前一个元素，获取某个元素的下一个元素等，这些特性本身也是有序带来的特点 第一个元素在二叉树中，第一个元素是根节点，也就是root节点，然而，在BST中则不是，BST中的第一个元素是指值最小的那个元素，这个元素会出现在一下几个地方 如果root为null，则不存在(树本身都不存在) 如果左节点不为空，则一直往最节点走，目标就是最左节点的最左节点 如果最左节点不存在，则root本身就是目标元素 123456789final Entry&lt;K,V&gt; getFirstEntry() { Entry&lt;K,V&gt; p = root; // root为空 if (p != null) // 如果左节点不为空，则一直往左走，否则，当前节点就是目标(第一个元素) while (p.left != null) p = p.left; return p;} 最后一个元素最后一个元素与第一个元素相反，位于最右子树的最右节点 12345678final Entry&lt;K,V&gt; getLastEntry() { Entry&lt;K,V&gt; p = root; if (p != null) // 一直往右走 while (p.right != null) p = p.right; return p;} 某个元素的下一个元素某个元素的下一个元素同样的，是指在排序中位于该元素的下一个元素，他们可能并不是直接连接在一起的，也即，root的right并不一定就是root的下一个元素 下一个元素的查找算法： 如果右节点存在，目标节点为：右节点的最左节点 如果右节点不存在，则为沿着根路径往上走，直到出现“右拐”节点(第一个比本节点大的节点)，该节点就是目标节点 12345678910111213141516171819static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) { if (t == null) return null; else if (t.right != null) { Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; } else { Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; // 往上走，找到第一个右拐点 while (p != null &amp;&amp; ch == p.right) { ch = p; p = p.parent; } return p; }} 某个元素的前一个节点前一个节点查找算法 如果左节点不为空，则目标节点为左节点的最右节点 如果左节点为空，则沿着根节点往上走，直到第一个“左拐”节点出现 1234567891011121314151617181920static &lt;K,V&gt; Entry&lt;K,V&gt; predecessor(Entry&lt;K,V&gt; t) { if (t == null) return null; // 左节点的最右节点 else if (t.left != null) { Entry&lt;K,V&gt; p = t.left; while (p.right != null) p = p.right; return p; } else { Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; // 沿着根节点出发，找到第一个”左拐“节点 while (p != null &amp;&amp; ch == p.left) { ch = p; p = p.parent; } return p; }} 初始化TreeMap提了四种初始化方式 使用key的默认排序方式 自定义key排序器 从map接口的实例初始化，同时使用key的默认排序方式 从SortedMap初始化(注意与3的不同) 从map接口的实例初始化，会先检查下是否是SortedMap的实例，如果是的话，会通过4进行初始化，如果不是的话，就直接通过父类(AbstractMap)的putAll操作，最终会回到自己的put方法 putAll 123456789101112131415161718192021222324public void putAll(Map&lt;? extends K, ? extends V&gt; map) { int mapSize = map.size(); // size == 0表示初始化 // 新的map非空，并且是SortedMap的实例 if (size==0 &amp;&amp; mapSize!=0 &amp;&amp; map instanceof SortedMap) { // 获取map的排序器 Comparator c = ((SortedMap)map).comparator(); // 如果跟自己的排序器一样，那说明符合自己的排序规则 if (c == comparator || (c != null &amp;&amp; c.equals(comparator))) { ++modCount; try { buildFromSorted(mapSize, map.entrySet().iterator(), null, null); } catch (java.io.IOException cannotHappen) { } catch (ClassNotFoundException cannotHappen) { } return; } } // 如果不是初始化，或者排序器不一样，则直接通过父类的putAll进行操作 // 父类的putAll会遍历map，然后一个个调用put操作 super.putAll(map);} buildFromSorted 12345678private void buildFromSorted(int size, Iterator it, java.io.ObjectInputStream str, V defaultVal) throws java.io.IOException, ClassNotFoundException { this.size = size; // 构建红黑树 root = buildFromSorted(0, 0, size-1, computeRedLevel(size), it, str, defaultVal);} computeRedLevel 1234567// level = log(sz)private static int computeRedLevel(int sz) { int level = 0; for (int m = sz - 1; m &gt;= 0; m = m / 2 - 1) level++; return level;} buildFromSorted 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// itr 存储是树的中序遍历(BST的中序遍历得到的序列就是有序)// 由于中序遍历的时候，根节点在最中间，左子树在根的左边，右子树在根的右边// 因此，重新构建树的时候，需要先构建左子树，构建根，然后构建右子树private final Entry&lt;K,V&gt; buildFromSorted(int level, int lo, int hi, int redLevel, Iterator it, java.io.ObjectInputStream str, V defaultVal) throws java.io.IOException, ClassNotFoundException { if (hi &lt; lo) return null; int mid = (lo + hi) / 2; Entry&lt;K,V&gt; left = null; // 递归构建左子树 if (lo &lt; mid) left = buildFromSorted(level+1, lo, mid - 1, redLevel, it, str, defaultVal); K key; V value; //如果it非空，则从it取数据，否则从stream取数据 if (it != null) { if (defaultVal==null) { Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;)it.next(); key = entry.getKey(); value = entry.getValue(); } else { key = (K)it.next(); value = defaultVal; } } else { key = (K) str.readObject(); value = (defaultVal != null ? defaultVal : (V) str.readObject()); } // 到这里左子树已经构建完成，构建根节点 Entry&lt;K,V&gt; middle = new Entry&lt;K,V&gt;(key, value, null); // 如果当前节点的层次为最低层，则将节点设置为红色 if (level == redLevel) middle.color = RED; // 构建左节点 if (left != null) { middle.left = left; left.parent = middle; } // 构建右节点 if (mid &lt; hi) { Entry&lt;K,V&gt; right = buildFromSorted(level+1, mid+1, hi, redLevel, it, str, defaultVal); middle.right = right; right.parent = middle; } // 返回当前子树 return middle;} 到这里，从其他的排序树构建的过程就结束了，接下来看下一个个元素构建的过程，也就是put方法 put 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public V put(K key, V value) { Entry&lt;K,V&gt; t = root; // 如果root为null，则构建root即可 if (t == null) { root = new Entry&lt;K,V&gt;(key, value, null); size = 1; modCount++; return null; } int cmp; Entry&lt;K,V&gt; parent; Comparator&lt;? super K&gt; cpr = comparator; // 如果比较器非空，说明自定义了key的比较方式 if (cpr != null) { do { // 记录下parent parent = t; // 如果小，则往左走 cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; // 如果大，则往右走 else if (cmp &gt; 0) t = t.right; // 否则，直接替换 else return t.setValue(value); } while (t != null); } // 采用key默认的比较方式 else { if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do { parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); } while (t != null); } // 初始化当前节点 Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(key, value, parent); // 作为左节点 if (cmp &lt; 0) parent.left = e; // 作为右节点 else parent.right = e; // 由于加入新节点之后，可能会出现违背红黑树规则的情况 // 因此，需要调整(旋转、变色)下树的结构，以保障红黑树的特性 fixAfterInsertion(e); size++; modCount++; return null;} fixAfterInsertion 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980private void fixAfterInsertion(Entry&lt;K,V&gt; x) { // 新加入的节点默认是红节点 x.color = RED;true // 如果父节点也是红色，则违背了红黑树“红色节点的子节点均为黑色节点”的原则 // 通过 1：旋转，2：变色进行处理 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) { // 如果x的父节点(记为p)是p的父节点的左节点，也就是红色的父节点位于祖父节点的左侧 if (parentOf(x) == leftOf(parentOf(parentOf(x)))) { // 获取p的兄弟节点 Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); // case 1: // 如果p的兄弟节点y也是红色 if (colorOf(y) == RED) { // 直接将p以及y变为黑色，然后父节点变为红色 setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); // 沿着根路径继续向上 x = parentOf(parentOf(x)); } else { // case 2: // y是黑色 // x在p的右侧 if (x == rightOf(parentOf(x))) { // 父节点先左旋，于是就变成了两个红色节点都位于左侧 x = parentOf(x); // 此时x指向原来的p rotateLeft(x); } // x节点位于p的左侧 // x父节点变成黑色 setColor(parentOf(x), BLACK); // x的父节点的父节点变成红色 setColor(parentOf(parentOf(x)), RED); // x的父节点的父节点右旋 rotateRight(parentOf(parentOf(x))); // 此时就转换为了 case1，在循环中会继续进行变色 } } else { // x的父节点p，是p的父节点的右节点 Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); // case 3： // 如果p的兄弟节点，是红色，其实就回到了case 1，直接变色即可 if (colorOf(y) == RED) { setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); } else { // case 4: // 如果x是p的左节点，其实是case2的镜像，就进行右旋 if (x == leftOf(parentOf(x))) { x = parentOf(x); rotateRight(x); } // 此时是p以及x都是右节点，且都是红节点 // 将p设置为黑色 setColor(parentOf(x), BLACK); // 将p的父节点设置为红色 setColor(parentOf(parentOf(x)), RED); // 将p的父节点进行右旋 rotateLeft(parentOf(parentOf(x))); // 此时转换为了case 1 } } } // 将根的颜色重置为黑色 root.color = BLACK;} 到这里，TreeMap的初始化也就完成了，其实，添加元素也完成了 添加元素见上面的put、putAll分析 查找元素查找元素有多种方式，比如查找某个key，查找第一个大于/小于该key的节点等等 get 1234public V get(Object key) { Entry&lt;K,V&gt; p = getEntry(key); return (p==null ? null : p.value);} getEntry 1234567891011121314151617181920212223final Entry&lt;K,V&gt; getEntry(Object key) { // 如果comparator非空，则使用自定义的comparator来查找元素 if (comparator != null) return getEntryUsingComparator(key); // 如果key为null，非法 if (key == null) throw new NullPointerException();Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; // 使用key自定义的排序器进行查找，简单的BST查找，就不展开了 while (p != null) { int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; } return null; } getEntryUsingComparator 123456789101112131415161718// BST查找，只是使用自定义的排序器final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) { K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) { Entry&lt;K,V&gt; p = root; while (p != null) { int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; } } return null; } 其他的方法就根据使用的时候，如果不理解再进行分析即可，就不展开了 删除元素在HashMap中，删除元素只需要通过改变指针的指向就能解决，而在LinkedHashMap中，无非也就多了额外的指针变化，然而，在TreeMap中，情况则复杂很多，由于删除之后，可能导致红黑树不平衡了，所以，还需要进一步进行平衡操作 remove 1234567891011public V remove(Object key) { // 找不到就说明不存在，无需删除 Entry&lt;K,V&gt; p = getEntry(key); if (p == null) return null; V oldValue = p.value; deleteEntry(p); return oldValue;} deleteEntry 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private void deleteEntry(Entry&lt;K,V&gt; p) { modCount++; size--; // 如果左右节点都非空 if (p.left != null &amp;&amp; p.right != null) { // 查找p的下一个元素(还记得这个方法的实现吗？) Entry&lt;K,V&gt; s = successor (p); // 将该节点值方在p中，并且将p指正s，此时变成了移除s p.key = s.key; p.value = s.value; p = s; } // 查找原来的s，现在的p的后继(左儿子，没有则找右儿子)，用于替换p // 注意这里，此时p只有左或者右节点，不存在两者都有的情况 Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); // 如果存在，也即p不是叶子节点 if (replacement != null) { replacement.parent = p.parent; // 如果p没有父节点，说明p是root，那么此时replacement将成为新的root if (p.parent == null) root = replacement; // 如果p是左节点，则将replacement作为左节点 else if (p == p.parent.left) p.parent.left = replacement; // 作为右节点 else p.parent.right = replacement; // 清空p的连接信息 p.left = p.right = p.parent = null; // 如果p(替换节点)是黑色节点，那么可能会违背“从root到叶子节点黑色节点路径长度一样”的规则 // 所以需要进行修正，注意，是用替换节点来修正(可能违背红黑规则) // 此时replacement已经替换了p，直接从replacement开始修正 if (p.color == BLACK) fixAfterDeletion(replacement); // 如果没有后继节点，且没有父节点，说明自己是孤家寡人 } else if (p.parent == null) { root = null; } else { // 没有后继节点，但是自己是黑色，也同样需要进行修正 if (p.color == BLACK) fixAfterDeletion(p); // 如果存在父节点，清空父节点的左/右节点信息 if (p.parent != null) { if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; } }} fixAfterDeletion 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 修正节点信息// todo 好吧，这里实在是没看懂.....后面有机会再补全吧...private void fixAfterDeletion(Entry&lt;K,V&gt; x) { // 非root节点并且是黑色节点 while (x != root &amp;&amp; colorOf(x) == BLACK) { // 如果是左节点 if (x == leftOf(parentOf(x))) { Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); // 兄弟节点是红色的 // 违背了规则，变色，旋转 if (colorOf(sib) == RED) { setColor(sib, BLACK); setColor(parentOf(x), RED); rotateLeft(parentOf(x)); sib = rightOf(parentOf(x)); } // 如果调整后的兄弟节点左右都为黑色，则将其变色为红色 if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) { setColor(sib, RED); x = parentOf(x); } else { if (colorOf(rightOf(sib)) == BLACK) { setColor(leftOf(sib), BLACK); setColor(sib, RED); rotateRight(sib); sib = rightOf(parentOf(x)); } setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; } } else { // symmetric Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); if (colorOf(sib) == RED) { setColor(sib, BLACK); setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); } if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) { setColor(sib, RED); x = parentOf(x); } else { if (colorOf(leftOf(sib)) == BLACK) { setColor(rightOf(sib), BLACK); setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); } setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; } } } setColor(x, BLACK);}","link":"/2020/12/11/Java%E5%AE%B9%E5%99%A8%E4%B9%8BMap-JDK1-6/"}],"tags":[{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Paxos","slug":"Paxos","link":"/tags/Paxos/"},{"name":"分布式一致性","slug":"分布式一致性","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"LockSupport","slug":"LockSupport","link":"/tags/LockSupport/"},{"name":"Concurrent","slug":"Concurrent","link":"/tags/Concurrent/"},{"name":"TimeUnit","slug":"TimeUnit","link":"/tags/TimeUnit/"},{"name":"Frontend","slug":"Frontend","link":"/tags/Frontend/"},{"name":"axios","slug":"axios","link":"/tags/axios/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"Spring Starter","slug":"Spring-Starter","link":"/tags/Spring-Starter/"},{"name":"自动装配","slug":"自动装配","link":"/tags/%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/"},{"name":"红黑树","slug":"红黑树","link":"/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"分布式锁","slug":"分布式锁","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"跳跃表","slug":"跳跃表","link":"/tags/%E8%B7%B3%E8%B7%83%E8%A1%A8/"},{"name":"驾照","slug":"驾照","link":"/tags/%E9%A9%BE%E7%85%A7/"},{"name":"Atomic","slug":"Atomic","link":"/tags/Atomic/"},{"name":"CAS","slug":"CAS","link":"/tags/CAS/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"Bulk","slug":"Bulk","link":"/tags/Bulk/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"ReentrantLock","slug":"ReentrantLock","link":"/tags/ReentrantLock/"},{"name":"CountdownLatch","slug":"CountdownLatch","link":"/tags/CountdownLatch/"},{"name":"Semaphore","slug":"Semaphore","link":"/tags/Semaphore/"},{"name":"CyclicBarrier","slug":"CyclicBarrier","link":"/tags/CyclicBarrier/"},{"name":"Collection","slug":"Collection","link":"/tags/Collection/"},{"name":"Map","slug":"Map","link":"/tags/Map/"},{"name":"HashMap","slug":"HashMap","link":"/tags/HashMap/"},{"name":"LinkedHashMap","slug":"LinkedHashMap","link":"/tags/LinkedHashMap/"},{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","link":"/tags/ConcurrentHashMap/"},{"name":"TreeMap","slug":"TreeMap","link":"/tags/TreeMap/"}],"categories":[{"name":"容器","slug":"容器","link":"/categories/%E5%AE%B9%E5%99%A8/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Frontend","slug":"Frontend","link":"/categories/Frontend/"},{"name":"Concurrent","slug":"Java/Concurrent","link":"/categories/Java/Concurrent/"},{"name":"Collections","slug":"Java/Collections","link":"/categories/Java/Collections/"},{"name":"杂谈","slug":"杂谈","link":"/categories/%E6%9D%82%E8%B0%88/"},{"name":"SpringBoot","slug":"Java/SpringBoot","link":"/categories/Java/SpringBoot/"},{"name":"生活","slug":"杂谈/生活","link":"/categories/%E6%9D%82%E8%B0%88/%E7%94%9F%E6%B4%BB/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/categories/Elasticsearch/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"Map","slug":"Java/Collections/Map","link":"/categories/Java/Collections/Map/"}]}